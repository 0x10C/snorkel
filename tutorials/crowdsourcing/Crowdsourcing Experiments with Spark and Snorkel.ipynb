{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Environment and Spark SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Snorkel Crowdsourcing Demo\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Crowdsourcing Data\n",
    "raw_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-non-agg-DFE.csv\")\n",
    "gold_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-evaluated-agg-DFE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------+---------+-------+------+-----+--------------------+--------+--------------------+\n",
      "|_unit_id_|  channel| trust|worker_id|country|region| city|             emotion|tweet_id|          tweet_body|\n",
      "+---------+---------+------+---------+-------+------+-----+--------------------+--------+--------------------+\n",
      "|314960382|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|82846118|Fire Weather Watc...|\n",
      "|314960385|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|82510997|Passing out now. ...|\n",
      "|314960391|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Negative|83271279|\"RT @mention: \"\"T...|\n",
      "|314960396|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|80058872|It is hot out her...|\n",
      "|314960400|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|80058809|I can't find a wa...|\n",
      "|314960401|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|79188429|Record LOW humidi...|\n",
      "|314960404|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|82838136|@mention oh nice!...|\n",
      "|314960405|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|82513588|@mention no, norm...|\n",
      "|314960406|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|84321017|@mention Is any p...|\n",
      "|314960407|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|82680080|@mention cherry s...|\n",
      "|314960413|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Negative|82510259|In Florida, the h...|\n",
      "|314960416|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|83258314|@mention yeah, i'...|\n",
      "|314960422|clixsense|0.4541| 18034918|    IND|     7|Delhi|Tweet not related...|80052652|For details about...|\n",
      "|314960426|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|79189357|\"Nothing says \"\"H...|\n",
      "|314960430|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|83257167|Severe Thundersto...|\n",
      "|314960432|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Negative|84312699|Tornado season re...|\n",
      "|314960433|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|79187315|@mention @mention...|\n",
      "|314960434|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Negative|84034743| It's fuckin hot out|\n",
      "|314960435|clixsense|0.4541| 18034918|    IND|     7|Delhi|Neutral / author ...|84319723|After being told ...|\n",
      "|314960436|clixsense|0.4541| 18034918|    IND|     7|Delhi|            Positive|83259244|Sunshine parks an...|\n",
      "+---------+---------+------+---------+-------+------+-----+--------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_crowd_answers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store worker features\n",
    "field = [StructField(\"worker_id\",StringType(), True),StructField(\"feature\", StringType(), True)]\n",
    "schema = StructType(field)\n",
    "worker_features = spark.createDataFrame(sc.emptyRDD(), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract country feature\n",
    "countryView = raw_crowd_answers.select(\"worker_id\",\"country\").distinct()\n",
    "name = 'country'\n",
    "countryUDF = UserDefinedFunction(lambda x: 'country='+x if x else \"NULL\", StringType())\n",
    "countryFeatures = countryView.select(*[countryUDF(column).alias('feature') if column == name else column for column in countryView.columns])\n",
    "worker_features = worker_features.unionAll(countryFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract channel feature\n",
    "channelView = raw_crowd_answers.select(\"worker_id\",\"channel\").distinct()\n",
    "name = 'channel'\n",
    "channelUDF = UserDefinedFunction(lambda x: 'channel='+x if x else \"NULL\", StringType())\n",
    "channelFeatures = channelView.select(*[channelUDF(column).alias('feature') if column == name else column for column in channelView.columns])\n",
    "worker_features = worker_features.unionAll(channelFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract city feature\n",
    "cityView = raw_crowd_answers.select(\"worker_id\",\"city\").distinct()\n",
    "name = 'city'\n",
    "cityUDF = UserDefinedFunction(lambda x: 'city='+x if x else \"NULL\", StringType())\n",
    "cityFeatures = cityView.select(*[cityUDF(column).alias('feature') if column == name else column for column in cityView.columns])\n",
    "worker_features = worker_features.unionAll(cityFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract worker_id canonical feature\n",
    "workerIDView = raw_crowd_answers.select(\"worker_id\",\"worker_id\").distinct()\n",
    "name = 'worker_id'\n",
    "workerIDUDF = UserDefinedFunction(lambda x: 'worker_id='+x if x else \"NULL\", StringType())\n",
    "workerIDFeatures = workerIDView.select(*[workerIDUDF(column).alias('feature') if column == name else column for column in workerIDView.columns])\n",
    "worker_features = worker_features.unionAll(workerIDFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract ground truth per tweet_id\n",
    "gold_crowd_answers.createOrReplaceTempView(\"gold_crowd_answers\")\n",
    "gold_answers = spark.sql(\"SELECT tweet_id, sentiment FROM gold_crowd_answers WHERE correct_category ='Yes'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract raw tweets\n",
    "tweet_body = gold_crowd_answers.select(\"tweet_id\", \"tweet_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract worker votes\n",
    "worker_votes = raw_crowd_answers.selectExpr(\"worker_id\", \"tweet_id\", \"emotion as sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data as parquet files\n",
    "worker_features.write.parquet(\"data/worker_features.parquet\",mode=\"overwrite\")\n",
    "gold_answers.write.parquet(\"data/gold_answers.parquet\",mode=\"overwrite\")\n",
    "tweet_body.write.parquet(\"data/tweet_body.parquet\",mode=\"overwrite\")\n",
    "worker_votes.write.parquet(\"data/worker_votes.parquet\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate labeling matrix\n",
    "taskLabels = [False]\n",
    "taskLabels.extend([str(i.sentiment) for i in worker_votes.select(\"sentiment\").distinct().collect()])\n",
    "taskLabelsMap = {}\n",
    "for i in range(len(taskLabels)):\n",
    "    taskLabelsMap[taskLabels[i]] = i\n",
    "    \n",
    "    \n",
    "# Task map\n",
    "task2CandMap = {}\n",
    "cid = 0\n",
    "cand2TaskMap = []\n",
    "for task in worker_votes.select(\"tweet_id\").distinct().orderBy(\"tweet_id\").collect():\n",
    "    task2CandMap[task.tweet_id] = cid\n",
    "    cand2TaskMap.append(task.tweet_id)\n",
    "    cid += 1\n",
    "    \n",
    "# Workers map\n",
    "worker2LFMap = {}\n",
    "lfid = 0\n",
    "lf2WorkerMap = []\n",
    "for worker in worker_votes.select(\"worker_id\").distinct().orderBy(\"worker_id\").collect():\n",
    "    worker2LFMap[worker.worker_id] = lfid\n",
    "    lf2WorkerMap.append(worker.worker_id)\n",
    "    lfid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False: 0, 'Positive': 3, 'Negative': 4, \"I can't tell\": 2, 'Neutral / author is just sharing information': 5, 'Tweet not related to weather condition': 1}\n"
     ]
    }
   ],
   "source": [
    "tasks = worker_votes.select(\"tweet_id\").distinct().count()\n",
    "workers = worker_votes.select(\"worker_id\").distinct().count()\n",
    "print taskLabelsMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create labeling matrix\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "L = sparse.lil_matrix((tasks, workers), dtype=np.int64)\n",
    "for observation in worker_votes.select(\"worker_id\", \"tweet_id\", \"sentiment\").collect():\n",
    "    task = task2CandMap[observation.tweet_id]\n",
    "    worker = worker2LFMap[observation.worker_id]\n",
    "    label = taskLabelsMap[observation.sentiment]\n",
    "    L[task, worker] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing init:\n",
      "Inferred cardinality: 5\n"
     ]
    }
   ],
   "source": [
    "# Train generative model\n",
    "from snorkel.learning.gen_learning import GenerativeModel, DEP_EXCLUSIVE, DEP_REINFORCING, DEP_FIXING, DEP_SIMILAR\n",
    "\n",
    "# Init priors\n",
    "LF_acc_priors = [0.7]*workers\n",
    "\n",
    "print(\"Testing init:\")\n",
    "gen_model = GenerativeModel(lf_propensity=False)\n",
    "gen_model.train(\n",
    "    L,\n",
    "    reg_type=2,\n",
    "    reg_param=0.1,\n",
    "    epochs=10\n",
    ")\n",
    "stats = gen_model.learned_lf_stats()\n",
    "accs = stats[\"Accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MAP assignment for each task\n",
    "task_marginals = gen_model.marginals(L)\n",
    "task_map_assignment = np.argmax(task_marginals, axis=1)\n",
    "inferredLabels = {}\n",
    "for i in range(len(task_map_assignment)):\n",
    "    inferredLabels[cand2TaskMap[i]] =  taskLabels[task_map_assignment[i]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.980846774194\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "total = float(gold_answers.count())\n",
    "for trueLabel in gold_answers.select(\"tweet_id\",\"sentiment\").collect():\n",
    "    if trueLabel.sentiment != inferredLabels[trueLabel.tweet_id]:\n",
    "        errors += 1\n",
    "print 'Accuracy = ', (total-errors)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurized_worker_votes = worker_votes.join(worker_features, worker_features.worker_id == worker_votes.worker_id).select(worker_votes.worker_id, worker_votes.tweet_id, worker_votes.sentiment, worker_features.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-----------+\n",
      "|worker_id|tweet_id|           sentiment|    feature|\n",
      "+---------+--------+--------------------+-----------+\n",
      "| 20095709|82675151|Neutral / author ...|country=USA|\n",
      "| 20095709|79188846|Neutral / author ...|country=USA|\n",
      "| 20095709|82682363|Neutral / author ...|country=USA|\n",
      "| 20095709|79194027|Neutral / author ...|country=USA|\n",
      "| 20095709|82844564|            Positive|country=USA|\n",
      "| 20095709|82850000|            Negative|country=USA|\n",
      "| 20095709|80058539|            Positive|country=USA|\n",
      "| 20095709|80053247|Tweet not related...|country=USA|\n",
      "| 20095709|82516074|        I can't tell|country=USA|\n",
      "| 20095709|82841589|Tweet not related...|country=USA|\n",
      "| 20095709|84308263|            Negative|country=USA|\n",
      "| 20095709|82677176|Tweet not related...|country=USA|\n",
      "| 20095709|84048359|            Positive|country=USA|\n",
      "| 20095709|82514466|Neutral / author ...|country=USA|\n",
      "| 20095709|82674290|Neutral / author ...|country=USA|\n",
      "| 20095709|83255088|            Positive|country=USA|\n",
      "| 20095709|82848964|Tweet not related...|country=USA|\n",
      "| 20095709|84030148|Tweet not related...|country=USA|\n",
      "| 20095709|82844765|            Negative|country=USA|\n",
      "| 20095709|81213874|Tweet not related...|country=USA|\n",
      "+---------+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized_worker_votes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate labeling matrix\n",
    "taskLabels = [False]\n",
    "taskLabels.extend([str(i.sentiment) for i in featurized_worker_votes.select(\"sentiment\").distinct().collect()])\n",
    "taskLabelsMap = {}\n",
    "for i in range(len(taskLabels)):\n",
    "    taskLabelsMap[taskLabels[i]] = i\n",
    "    \n",
    "    \n",
    "# Task map\n",
    "task2CandMap = {}\n",
    "cid = 0\n",
    "cand2TaskMap = []\n",
    "for task in featurized_worker_votes.select(\"tweet_id\").distinct().orderBy(\"tweet_id\").collect():\n",
    "    task2CandMap[task.tweet_id] = cid\n",
    "    cand2TaskMap.append(task.tweet_id)\n",
    "    cid += 1\n",
    "    \n",
    "# Workers map\n",
    "worker2LFMap = {}\n",
    "lfid = 0\n",
    "lf2WorkerMap = []\n",
    "lfFeatures = []\n",
    "for worker in featurized_worker_votes.select(\"worker_id\",\"feature\").distinct().orderBy(\"worker_id\",\"feature\").collect():\n",
    "    worker2LFMap[worker.worker_id+\"_\"+worker.feature] = lfid\n",
    "    lf2WorkerMap.append(worker.worker_id+\"_\"+worker.feature)\n",
    "    lfFeatures.append(worker.feature)\n",
    "    lfid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks = featurized_worker_votes.select(\"tweet_id\").distinct().count()\n",
    "LFs = featurized_worker_votes.select(\"worker_id\",\"feature\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create labeling matrix\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "L = sparse.lil_matrix((tasks, LFs), dtype=np.int64)\n",
    "for observation in featurized_worker_votes.select(\"worker_id\", \"feature\", \"tweet_id\", \"sentiment\").collect():\n",
    "    task = task2CandMap[observation.tweet_id]\n",
    "    lfid = worker2LFMap[observation.worker_id+\"_\"+observation.feature]\n",
    "    label = taskLabelsMap[observation.sentiment]\n",
    "    L[task, lfid] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing init:\n",
      "Inferred cardinality: 5\n"
     ]
    }
   ],
   "source": [
    "# Train generative model\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from snorkel.learning.gen_learning import FeaturizedGenerativeModel, DEP_EXCLUSIVE, DEP_REINFORCING, DEP_FIXING, DEP_SIMILAR\n",
    "\n",
    "# Init priors\n",
    "LF_acc_priors = [0.7]*LFs\n",
    "\n",
    "print(\"Testing init:\")\n",
    "gen_model = FeaturizedGenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L,\n",
    "    LF_acc_features=lfFeatures,\n",
    "    reg_type=2,\n",
    "    reg_param=0.01,\n",
    "    epochs=10\n",
    ")\n",
    "stats = gen_model.learned_lf_stats()\n",
    "accs = stats[\"Accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MAP assignment for each task\n",
    "task_marginals = gen_model.marginals(L)\n",
    "task_map_assignment = np.argmax(task_marginals, axis=1)\n",
    "inferredLabels = {}\n",
    "for i in range(len(task_map_assignment)):\n",
    "    inferredLabels[cand2TaskMap[i]] =  taskLabels[task_map_assignment[i]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.975806451613\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "total = float(gold_answers.count())\n",
    "for trueLabel in gold_answers.select(\"tweet_id\",\"sentiment\").collect():\n",
    "    if trueLabel.sentiment != inferredLabels[trueLabel.tweet_id]:\n",
    "        errors += 1\n",
    "print 'Accuracy = ', (total-errors)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
