{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolving Conflicts in Crowdsourced Data with Snorkel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will walk through the process of using `Snorkel` to resolve conflicts in crowdsourced answers for a sentiment analysis task. The following tutorial is broken up into four parts, each covering a step in the pipeline:\n",
    "1. Preprocessing\n",
    "2. Construction of a Snorkel Labeling Matrix\n",
    "3. Conflict Resolution\n",
    "4. Evaluation\n",
    "\n",
    "In this notebook, we preprocess the data collected by the crowd contributors using [Spark SQL and Dataframes](https://spark.apache.org/docs/latest/sql-programming-guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Sentiment Analysis of Tweets\n",
    "\n",
    "In this tutorial we focus on the [Weather sentiment](https://www.crowdflower.com/data/weather-sentiment/) task from [Crowdflower](https://www.crowdflower.com/).\n",
    "\n",
    "In this task, contributors were asked to grade the sentiment of a particular tweet relating to the weather. The catch is that 20 contributors graded each tweet. We then ran an additional job (the one below) where we asked 10 contributors to grade the original sentiment evaluation.\n",
    "\n",
    "In this task, contributors were asked to grade the sentiment of a particular tweet relating to the weather. Contributors could choose among the following categories:\n",
    "1. Positive\n",
    "2. Negative\n",
    "3. I can't tell\n",
    "4. Neutral / author is just sharing information\n",
    "5. Tweet not related to weather condition\n",
    "\n",
    "The catch is that 20 contributors graded each tweet. Thus, in many cases contributors assigned conflicting sentiment labels to the same tweet. \n",
    "\n",
    "\n",
    "The task comes with two data files (to be found in the `data` directory of the tutorial:\n",
    "1. [weather-non-agg-DFE.csv](data/weather-non-agg-DFE.csv) contains the raw contributor answers for each of the 1,000 tweets.\n",
    "2. [weather-evaluated-agg-DFE.csv](data/weather-evaluated-agg-DFE.csv) contains gold sentiment labels by trusted workers for each of the 1,000 tweets.\n",
    "\n",
    "**GOAL:** The goal of this tutorial is to demonstrate how `Snorkel` can be used to accurately infer a single sentiment label for each tweet, thus, denoising the collected contributor answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Preprocessing - Data Loading with Spark SQL and Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize a `SparkSession`, which manages a connection to a local Spark master which allows us to preprocess the raw data and prepare convert them to the necessary `Snorkel` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Environment and Spark SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Snorkel Crowdsourcing Demo\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the raw data for our crowdsourcing task (stored in a local csv file) into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _unit_id_: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- trust: string (nullable = true)\n",
      " |-- worker_id: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- emotion: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Crowdsourcing Data\n",
    "raw_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-non-agg-DFE.csv\")\n",
    "raw_crowd_answers.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, contributors can provide conflicting labels for the same tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|worker_id|             emotion|          tweet_body|\n",
      "+---------+--------------------+--------------------+\n",
      "| 14806909|Neutral / author ...|I dunno which ass...|\n",
      "|  7450342|Neutral / author ...|I dunno which ass...|\n",
      "|  6737418|            Negative|I dunno which ass...|\n",
      "| 18381123|Neutral / author ...|I dunno which ass...|\n",
      "| 10752241|            Positive|I dunno which ass...|\n",
      "| 14584835|            Negative|I dunno which ass...|\n",
      "|  6346694|Neutral / author ...|I dunno which ass...|\n",
      "| 19028457|            Positive|I dunno which ass...|\n",
      "| 17475684|            Negative|I dunno which ass...|\n",
      "|  6498214|        I can't tell|I dunno which ass...|\n",
      "| 16498372|Tweet not related...|I dunno which ass...|\n",
      "|  7012325|            Positive|I dunno which ass...|\n",
      "|  9333400|            Negative|I dunno which ass...|\n",
      "| 10379699|            Positive|I dunno which ass...|\n",
      "| 14298198|            Positive|I dunno which ass...|\n",
      "| 20043586|            Negative|I dunno which ass...|\n",
      "|  9289735|        I can't tell|I dunno which ass...|\n",
      "| 10235355|            Negative|I dunno which ass...|\n",
      "| 16738677|            Negative|I dunno which ass...|\n",
      "| 15846764|            Negative|I dunno which ass...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_crowd_answers.select(\"worker_id\", \"emotion\", \"tweet_body\").orderBy(\"tweet_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Construction of a Snorkel Labeling Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now demonstrate how to convert the raw crowd data stored in a Dataframe to the input assumed by `Snorkel`. \n",
    "\n",
    "### A recap of Snorkel's labeling matrix\n",
    "`Snorkel` is a system for rapidly creating, modeling, and managing training data. It is built around the new data programming paradigm, in which the developer focuses on writing a set of labeling functions, which are just scripts that programmatically label data. The resulting labels are noisy, but `Snorkel` automatically models this process—learning, essentially, which labeling functions are more accurate than others—and then uses this to train an end model (for example, a deep neural network in TensorFlow).\n",
    "\n",
    "The key input in `Snorkel's` programing model corresponds to a **labeling matrix**. The rows of the labeling matrix correspond to objects for which we require to obtain labels, and the columns to labeling functions that assign labels to these objects. Different labeling functions can provide conflicting assignments for the same object. `Snorkel` leverages the agreement rates across labeling functions to automatically infer the accuracy of each function. The infered labeling function accuracies can then be used to estimate the most probable label assignment for each object.\n",
    "\n",
    "### Labeling matrices for crowdsourcing\n",
    "There is a one-to-one correspondance between the task of resolving conflicting answers by crowd contributors and `Snorkel's` core task. Each crowdsourcing task corresponds to an object (a row in the labeling matrix) and each worker to a different labeling function that assigns labels to a subset of objects.\n",
    "\n",
    "Below we demonstrate how to map the raw crowdsourced data to a labeling matrix and how to use `Snorkel` to resolve disagreements across contributors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perform a selection over the dataframe containing the raw crowdsourced data to obtain the labels assigned to different tasks by different workers. We refer to the result of this selection as `worker_votes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------------------+\n",
      "| task_id|worker_id|               label|\n",
      "+--------+---------+--------------------+\n",
      "|82846118| 18034918|Neutral / author ...|\n",
      "|82510997| 18034918|            Positive|\n",
      "|83271279| 18034918|            Negative|\n",
      "|80058872| 18034918|            Positive|\n",
      "|80058809| 18034918|Neutral / author ...|\n",
      "|79188429| 18034918|Neutral / author ...|\n",
      "|82838136| 18034918|            Positive|\n",
      "|82513588| 18034918|            Positive|\n",
      "|84321017| 18034918|Neutral / author ...|\n",
      "|82680080| 18034918|            Positive|\n",
      "|82510259| 18034918|            Negative|\n",
      "|83258314| 18034918|Neutral / author ...|\n",
      "|80052652| 18034918|Tweet not related...|\n",
      "|79189357| 18034918|            Positive|\n",
      "|83257167| 18034918|Neutral / author ...|\n",
      "|84312699| 18034918|            Negative|\n",
      "|79187315| 18034918|Neutral / author ...|\n",
      "|84034743| 18034918|            Negative|\n",
      "|84319723| 18034918|Neutral / author ...|\n",
      "|83259244| 18034918|            Positive|\n",
      "+--------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract worker votes\n",
    "worker_labels = raw_crowd_answers.selectExpr(\"tweet_id as task_id\", \"worker_id\", \"emotion as label\")\n",
    "worker_labels.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we populate the labeling matrix to be used as input for `Snorkel` we generate a series of maps that:\n",
    "\n",
    "1. Map each `task_id` to a unique Object id represented as an integer.\n",
    "2. Map each `worker_id` to a unique Labeling Function (LF) id represented as an integer.\n",
    "3. Map each possible label from the active domain of the crowdsourced tasks to a unique integer key in 1..D. The value of 0 is reserved to denote that a worker (labeling function) abstains from assigning a label for a task (object).\n",
    "\n",
    "We will later use these maps to populate the entries of the actual labeling matrix, which corresponds to a sparse numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate task to object map\n",
    "task2ObjMap = {}\n",
    "oid = 0\n",
    "obj2TaskMap = []\n",
    "for task in worker_labels.select(\"task_id\").distinct().orderBy(\"task_id\").collect():\n",
    "    task2ObjMap[task.task_id] = oid\n",
    "    obj2TaskMap.append(task.task_id)\n",
    "    oid += 1\n",
    "\n",
    "# Generate workers map\n",
    "worker2LFMap = {}\n",
    "lfid = 0\n",
    "lf2WorkerMap = []\n",
    "for worker in worker_labels.select(\"worker_id\").distinct().orderBy(\"worker_id\").collect():\n",
    "    worker2LFMap[worker.worker_id] = lfid\n",
    "    lf2WorkerMap.append(worker.worker_id)\n",
    "    lfid += 1\n",
    "    \n",
    "# Generate label map\n",
    "\n",
    "# The special class label False corresponds to the label key 0 \n",
    "# which means that a worker (labeling function) abstains from\n",
    "# providing a label for a task (object).\n",
    "taskLabels = [False] \n",
    "taskLabels.extend([str(i.label) for i in worker_labels.select(\"label\").distinct().collect()])\n",
    "taskLabelsMap = {}\n",
    "for i in range(len(taskLabels)):\n",
    "    taskLabelsMap[taskLabels[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False <=> 0\n",
      "Positive <=> 3\n",
      "Negative <=> 4\n",
      "I can't tell <=> 2\n",
      "Neutral / author is just sharing information <=> 5\n",
      "Tweet not related to weather condition <=> 1\n"
     ]
    }
   ],
   "source": [
    "# Inspect the domain map for possible labels\n",
    "for label in taskLabelsMap:\n",
    "    print str(label) + \" <=> \"+ str(taskLabelsMap[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now iterate over the entries of the `worker_labels` dataframe and use the above maps to populate the labeling matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The labeling matrix is represented\n",
    "# as a sparse scipy array\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Initialize dimensions of labeling matrix\n",
    "objects = worker_labels.select(\"task_id\").distinct().count()\n",
    "LFs = worker_labels.select(\"worker_id\").distinct().count()\n",
    "\n",
    "# Initialize empty labeling matrix\n",
    "L = sparse.lil_matrix((objects, LFs), dtype=np.int64)\n",
    "\n",
    "# Iterate over crowdsourced labels and populate labeling matrix\n",
    "for assigned_label in worker_labels.select(\"worker_id\", \"task_id\", \"label\").collect():\n",
    "    oid = task2ObjMap[assigned_label.task_id]\n",
    "    LFid = worker2LFMap[assigned_label.worker_id]\n",
    "    label = taskLabelsMap[assigned_label.label]\n",
    "    L[oid, LFid] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Conflict Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have converted the raw crowdsourced data into a labeling matrix that can be provided as input to `Snorkel`. We will now show how to:\n",
    "\n",
    "1. Use `Snorkel's` generative model to learn the accuracy of each crowd contributor.\n",
    "2. Use the learned model to estimate a marginal distribution over the domain of possible labels for each task.\n",
    "3. Use the estimated marginal distribution to obtain the maximum a posteriori probability estimate for the label that each task takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and training a Snorkel generative model\n",
    "\n",
    "First we import and initialize `Snorkel's` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from snorkel.learning.gen_learning import GenerativeModel\n",
    "\n",
    "# Initialize Snorkel's generative model for\n",
    "# learning the different worker accuracies.\n",
    "gen_model = GenerativeModel(lf_propensity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train `Snorkel's` generative model by passing as input the labeling matrix that corresponds to the crowdsourced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 5\n"
     ]
    }
   ],
   "source": [
    "# Train the generative model\n",
    "gen_model.train(\n",
    "    L,\n",
    "    reg_type=2,\n",
    "    reg_param=0.01,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering the marginal distribution\n",
    "The following command uses the labeling matrix and the learned generative model to estimate the marginal distribution over the domain of possible labels for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_marginals = gen_model.marginals(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering the MAP assignment for each task\n",
    "Each task corresponds to an indipendent random variable. Thus, we can simply associate each task with the most probably label based on the estimated marginal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get MAP assignment for each task\n",
    "task_map_assignment = np.argmax(task_marginals, axis=1)\n",
    "inferedLabels = {}\n",
    "for i in range(len(task_map_assignment)):\n",
    "    inferedLabels[obj2TaskMap[i]] =  taskLabels[task_map_assignment[i]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Evaluation\n",
    "\n",
    "We now evaluate the accuracy of `Snorkel's` model at identifying the correct label for each task by fusing the labels provided by differnet crowd contributors. For this we compare the MAP label assigned to tasks against the provided groundtruth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract ground truth per tweet_id\n",
    "gold_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-evaluated-agg-DFE.csv\")\n",
    "gold_crowd_answers.createOrReplaceTempView(\"gold_crowd_answers\")\n",
    "gold_answers = spark.sql(\"SELECT tweet_id, sentiment, tweet_body FROM gold_crowd_answers WHERE correct_category ='Yes' and correct_category_conf = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Error ***\n",
      "Original tweet: BLOG: Another Day, Another Round Of Thunderstorms {link}\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: RT @mention: It'll be sunny again by time you land RT @mention: Every time I think about going back to Portland it starts ra ...\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: #sunshine\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Positive\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: This hot, dry, & windy weather is going to turn the #canola fast. Keep a close eye on it if you plan on swathing or pushing. #okanola\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: @mention It's supposed to go up to 70 today. Sunshine early. A slight chance for a shower or t-storm later. Going to my Aunt's house later.\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Positive\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: @mention not in sunny dover! haha\n",
      "Groundtruth label: Positive\n",
      "Snorkel label: Neutral / author is just sharing information\n",
      "\n",
      "\n",
      "Overall accuracy of Snorkels model =  0.990506329114\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "total = float(gold_answers.count())\n",
    "for trueLabel in gold_answers.select(\"tweet_id\",\"sentiment\",\"tweet_body\").collect():\n",
    "    if trueLabel.sentiment != inferedLabels[trueLabel.tweet_id]:\n",
    "        errors += 1\n",
    "        print '*** Error ***'\n",
    "        print 'Original tweet: '+trueLabel.tweet_body\n",
    "        print 'Groundtruth label: '+trueLabel.sentiment\n",
    "        print 'Snorkel label: '+inferedLabels[trueLabel.tweet_id]\n",
    "        print '\\n'\n",
    "print 'Overall accuracy of Snorkel''s model = ', (total-errors)/total"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
