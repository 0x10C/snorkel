{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Crowdsourced Sentiment Analysis with Snorkel - Training an ML Model with Snorkel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Part I](Crowdsourced_Sentiment_Analysis_Part1.ipynb) of the tutorial we saw how `Snorkel's` generative model can be used to resolve conflicts in crowdsourced answers for a sentiment analysis task. In this second part, we will show how the the output of `Snorkel's` generative model can be used to provide the necessary labeled data for training a Logistic Regression model that takes as input a tweet and predicts the associated sentiment. The following tutorial is broken up into four parts, each covering a step in the pipeline:\n",
    "1. Load files from Part I\n",
    "2. Train Snorkel's generative model\n",
    "3. Load and featurize the tweet bodies\n",
    "4. Train a Logistic regression model with Snorkel\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Files from Part I\n",
    "\n",
    "We first load certain dataframes and pickled files from Part I. These files are required in the subsequent steps. For more details on how the files were generated please check [Part I](Crowdsourced_Sentiment_Analysis_Part1.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Environment and Spark SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Snorkel Crowdsourcing Demo\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataframes from parquet files\n",
    "worker_labels = spark.read.parquet(\"data/worker_labels.parquet\")\n",
    "gold_answers = spark.read.parquet(\"data/gold_answers.parquet\")\n",
    "\n",
    "# Load maps\n",
    "import pickle\n",
    "task2ObjMap = pickle.load( open( \"data/task2ObjMap.pkl\", \"rb\" ) )\n",
    "obj2TaskMap = pickle.load( open( \"data/obj2TaskMap.pkl\", \"rb\" ) )\n",
    "worker2LFMap = pickle.load( open( \"data/worker2LFMap.pkl\", \"rb\" ) )\n",
    "lf2WorkerMap = pickle.load( open( \"data/lf2WorkerMap.pkl\", \"rb\" ) )\n",
    "taskLabels = pickle.load( open( \"data/taskLabels.pkl\", \"rb\" ) )\n",
    "taskLabelsMap = pickle.load( open( \"data/taskLabelsMap.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train Snorkel's Generative Model\n",
    "\n",
    "We now generate the labeling matrix for Snorkel and train the corresponding generative model. Details on these steps are provided in [Part I](Crowdsourced_Sentiment_Analysis_Part2.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The labeling matrix is represented\n",
    "# as a sparse scipy array\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Initialize dimensions of labeling matrix\n",
    "objects = worker_labels.select(\"task_id\").distinct().count()\n",
    "LFs = worker_labels.select(\"worker_id\").distinct().count()\n",
    "\n",
    "# Initialize empty labeling matrix\n",
    "L = sparse.lil_matrix((objects, LFs), dtype=np.int64)\n",
    "\n",
    "# Iterate over crowdsourced labels and populate labeling matrix\n",
    "for assigned_label in worker_labels.select(\"worker_id\", \"task_id\", \"label\").collect():\n",
    "    oid = task2ObjMap[assigned_label.task_id]\n",
    "    LFid = worker2LFMap[assigned_label.worker_id]\n",
    "    label = taskLabelsMap[assigned_label.label]\n",
    "    L[oid, LFid] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from snorkel.learning.gen_learning import GenerativeModel\n",
    "\n",
    "# Initialize Snorkel's generative model for\n",
    "# learning the different worker accuracies.\n",
    "gen_model = GenerativeModel(lf_propensity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 5\n"
     ]
    }
   ],
   "source": [
    "# Train the generative model\n",
    "gen_model.train(\n",
    "    L,\n",
    "    reg_type=2,\n",
    "    reg_param=0.01,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Featurize Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command uses the labeling matrix and the learned generative model to estimate the marginal distribution over the domain of possible labels for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load tweet bodies in a dataframe\n",
    "raw_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-non-agg-DFE.csv\")\n",
    "tweet_bodies = raw_crowd_answers.select(\"tweet_id\", \"tweet_body\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Featurize each tweet\n",
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "%time F_train = featurizer.apply(split=0)\n",
    "F_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train a Logistic Regression Model with Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain marginals for tweets from generative model\n",
    "train_marginals = gen_model.marginals(L)\n",
    "\n",
    "# Import logistic regression model\n",
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "# Init model\n",
    "disc_model_sparse = SparseLogisticRegression()\n",
    "\n",
    "# Train model\n",
    "disc_model_sparse.train(F_train, train_marginals, n_epochs=20, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation\n",
    "\n",
    "We now evaluate the accuracy of `Snorkel's` model at identifying the correct label for each task by fusing the labels provided by differnet crowd contributors. For this we compare the MAP label assigned to tasks against the provided groundtruth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract ground truth per tweet_id\n",
    "gold_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-evaluated-agg-DFE.csv\")\n",
    "gold_crowd_answers.createOrReplaceTempView(\"gold_crowd_answers\")\n",
    "gold_answers = spark.sql(\"SELECT tweet_id, sentiment, tweet_body FROM gold_crowd_answers WHERE correct_category ='Yes' and correct_category_conf = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Error ***\n",
      "Original tweet: BLOG: Another Day, Another Round Of Thunderstorms {link}\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: RT @mention: It'll be sunny again by time you land RT @mention: Every time I think about going back to Portland it starts ra ...\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: #sunshine\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Positive\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: This hot, dry, & windy weather is going to turn the #canola fast. Keep a close eye on it if you plan on swathing or pushing. #okanola\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Negative\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: @mention It's supposed to go up to 70 today. Sunshine early. A slight chance for a shower or t-storm later. Going to my Aunt's house later.\n",
      "Groundtruth label: Neutral / author is just sharing information\n",
      "Snorkel label: Positive\n",
      "\n",
      "\n",
      "*** Error ***\n",
      "Original tweet: @mention not in sunny dover! haha\n",
      "Groundtruth label: Positive\n",
      "Snorkel label: Neutral / author is just sharing information\n",
      "\n",
      "\n",
      "Overall accuracy of Snorkels model =  0.990506329114\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "total = float(gold_answers.count())\n",
    "for trueLabel in gold_answers.select(\"tweet_id\",\"sentiment\",\"tweet_body\").collect():\n",
    "    if trueLabel.sentiment != inferedLabels[trueLabel.tweet_id]:\n",
    "        errors += 1\n",
    "        print '*** Error ***'\n",
    "        print 'Original tweet: '+trueLabel.tweet_body\n",
    "        print 'Groundtruth label: '+trueLabel.sentiment\n",
    "        print 'Snorkel label: '+inferedLabels[trueLabel.tweet_id]\n",
    "        print '\\n'\n",
    "print 'Overall accuracy of Snorkel''s model = ', (total-errors)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
