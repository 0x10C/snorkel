{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Crowdsourced Sentiment Analysis with Snorkel - Resolving Conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the tutorial, we will walk through the process of using `Snorkel` to resolve conflicts in crowdsourced answers for a sentiment analysis task. The following tutorial is broken up into four core parts and a bonus part. Each part covers a step in the pipeline:\n",
    "1. Preprocessing\n",
    "2. Construction of a Snorkel Labeling Matrix\n",
    "3. Conflict Resolution\n",
    "4. Evaluation\n",
    "5. Bonus: Comparison against Majority Vote\n",
    "\n",
    "In this notebook, we preprocess the data collected by the crowd contributors using [Spark SQL and Dataframes](https://spark.apache.org/docs/latest/sql-programming-guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Sentiment Analysis of Tweets\n",
    "\n",
    "In this tutorial we focus on the [Weather sentiment](https://www.crowdflower.com/data/weather-sentiment/) task from [Crowdflower](https://www.crowdflower.com/).\n",
    "\n",
    "In this task, contributors were asked to grade the sentiment of a particular tweet relating to the weather. The catch is that 20 contributors graded each tweet. We then ran an additional job (the one below) where we asked 10 contributors to grade the original sentiment evaluation.\n",
    "\n",
    "In this task, contributors were asked to grade the sentiment of a particular tweet relating to the weather. Contributors could choose among the following categories:\n",
    "1. Positive\n",
    "2. Negative\n",
    "3. I can't tell\n",
    "4. Neutral / author is just sharing information\n",
    "5. Tweet not related to weather condition\n",
    "\n",
    "The catch is that 20 contributors graded each tweet. Thus, in many cases contributors assigned conflicting sentiment labels to the same tweet. \n",
    "\n",
    "\n",
    "The task comes with two data files (to be found in the `data` directory of the tutorial:\n",
    "1. [weather-non-agg-DFE.csv](data/weather-non-agg-DFE.csv) contains the raw contributor answers for each of the 1,000 tweets.\n",
    "2. [weather-evaluated-agg-DFE.csv](data/weather-evaluated-agg-DFE.csv) contains gold sentiment labels by trusted workers for each of the 1,000 tweets.\n",
    "\n",
    "**GOAL:** The goal of this tutorial is to demonstrate how `Snorkel` can be used to accurately infer a single sentiment label for each tweet, thus, denoising the collected contributor answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Preprocessing - Data Loading with Spark SQL and Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize a `SparkSession`, which manages a connection to a local Spark master which allows us to preprocess the raw data and prepare convert them to the necessary `Snorkel` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Environment and Spark SQL\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Snorkel Crowdsourcing Demo\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the raw data for our crowdsourcing task (stored in a local csv file) into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _unit_id_: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- trust: string (nullable = true)\n",
      " |-- worker_id: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- emotion: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- tweet_body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Raw Crowdsourcing Data\n",
    "raw_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-non-agg-DFE.csv\")\n",
    "raw_crowd_answers.printSchema()\n",
    "\n",
    "# Load Groundtruth Crowdsourcing Data\n",
    "gold_crowd_answers = spark.read.format(\"csv\").option(\"header\", \"true\").csv(\"data/weather-evaluated-agg-DFE.csv\")\n",
    "gold_crowd_answers.createOrReplaceTempView(\"gold_crowd_answers\")\n",
    "gold_answers = spark.sql(\"SELECT tweet_id, sentiment, tweet_body FROM gold_crowd_answers WHERE correct_category ='Yes' and correct_category_conf = 1\").orderBy(\"tweet_id\")\n",
    "\n",
    "# Keep Only the Tweets with Available Groundtruth\n",
    "candidate_labeled_tweets = raw_crowd_answers.join(gold_answers, raw_crowd_answers.tweet_id == gold_answers.tweet_id).select(raw_crowd_answers.tweet_id,raw_crowd_answers.tweet_body,raw_crowd_answers.worker_id,raw_crowd_answers.emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, contributors can provide conflicting labels for the same tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|worker_id|             emotion|          tweet_body|\n",
      "+---------+--------------------+--------------------+\n",
      "|  6498214|        I can't tell|I dunno which ass...|\n",
      "|  7450342|Neutral / author ...|I dunno which ass...|\n",
      "| 10752241|            Positive|I dunno which ass...|\n",
      "| 10235355|            Negative|I dunno which ass...|\n",
      "| 17475684|            Negative|I dunno which ass...|\n",
      "|  6346694|Neutral / author ...|I dunno which ass...|\n",
      "| 14806909|Neutral / author ...|I dunno which ass...|\n",
      "| 19028457|            Positive|I dunno which ass...|\n",
      "|  6737418|            Negative|I dunno which ass...|\n",
      "| 14584835|            Negative|I dunno which ass...|\n",
      "| 18381123|Neutral / author ...|I dunno which ass...|\n",
      "| 16498372|Tweet not related...|I dunno which ass...|\n",
      "|  7012325|            Positive|I dunno which ass...|\n",
      "|  9333400|            Negative|I dunno which ass...|\n",
      "| 10379699|            Positive|I dunno which ass...|\n",
      "| 14298198|            Positive|I dunno which ass...|\n",
      "| 20043586|            Negative|I dunno which ass...|\n",
      "|  9289735|        I can't tell|I dunno which ass...|\n",
      "| 16738677|            Negative|I dunno which ass...|\n",
      "| 15846764|            Negative|I dunno which ass...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_labeled_tweets.select(\"worker_id\", \"emotion\", \"tweet_body\").orderBy(\"tweet_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Snorkel Candidates\n",
    "\n",
    "We'll start by generating a set of Snorkel `Candidate` objects representing the tweets. `Candidate` objects in Snorkel just represent the objects we wish to classify. All `Candidate` objects point to one or more `Context` objects; in this case, our candidates will each point to a single `Context` object representing the raw text of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "# We create a Candidate subclass, Tweet, which has one argument--\n",
    "# tweet_body, representing the raw text of the tweet-- and can take\n",
    "# on one of the values in `taskLabels`\n",
    "values = map(\n",
    "    lambda r: r.emotion,\n",
    "    candidate_labeled_tweets.select(\"emotion\").distinct().collect()\n",
    ")\n",
    "Tweet = candidate_subclass('Tweet', ['tweet'], values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import RawText, Context, Candidate\n",
    "\n",
    "# Make sure DB is cleared\n",
    "session.query(Context).delete()\n",
    "session.query(Candidate).delete()\n",
    "\n",
    "# Now we create the candidates with a simple loop\n",
    "tweet_bodies = candidate_labeled_tweets \\\n",
    "    .select(\"tweet_id\", \"tweet_body\") \\\n",
    "    .orderBy(\"tweet_id\") \\\n",
    "    .distinct()\n",
    "\n",
    "# Generate and store the tweet candidates to be classified\n",
    "# Note: We split the tweets in two sets: one for which the crowd \n",
    "# labels are not available to Snorkel (test, 10%) and one for which we assume\n",
    "# crowd labels are obtained (to be used for training, 90%)\n",
    "total_tweets = tweet_bodies.count()\n",
    "test_split = total_tweets*0.1\n",
    "for i, t in enumerate(tweet_bodies.collect()):\n",
    "    split = 1 if i <= test_split else 0\n",
    "    raw_text = RawText(stable_id=t.tweet_id, name=t.tweet_id, text=t.tweet_body)\n",
    "    tweet = Tweet(tweet=raw_text, split=split)\n",
    "    session.add(tweet)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Worker Labels\n",
    "\n",
    "Note: this is not the most efficient way to do this, but is a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%%\n",
      "\n",
      "CPU times: user 5.61 s, sys: 567 ms, total: 6.17 s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<568x102 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 11360 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "# Extract worker votes\n",
    "worker_labels = candidate_labeled_tweets.select(\"tweet_id\", \"worker_id\", \"emotion\")\n",
    "\n",
    "# Create a label generator\n",
    "def worker_label_generator(t):\n",
    "    \"\"\"A generator over the different (worker_id, label_id) pairs for a Tweet.\"\"\"\n",
    "    labels = worker_labels \\\n",
    "        .select(\"worker_id\", \"emotion\") \\\n",
    "        .filter(\"tweet_id == \" + str(t.tweet.name)) \\\n",
    "        .collect()\n",
    "    for row in labels:\n",
    "        yield row.worker_id, row.emotion\n",
    "\n",
    "labeler = LabelAnnotator(label_generator=worker_label_generator)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(Tweet).filter(Tweet.split == 0).order_by(Tweet.id).all()\n",
    "\n",
    "# Generate and store the golden labels for each tweet candidate.\n",
    "# The labels are split into two lists, one for training data and one for testing data. \n",
    "# The raw groundtruth labels are stored with respect to their unique id (from 1-5).\n",
    "candidate_labels = {}\n",
    "\n",
    "# Iterate over splits\n",
    "for split in range(2):\n",
    "    # Init candidate labels\n",
    "    candidate_labels[split] = []\n",
    "    # Get candidates\n",
    "    cands = session.query(Tweet).filter(Tweet.split == split).order_by(Tweet.id).all()\n",
    "    # Iterate over candidates    \n",
    "    for c in cands:\n",
    "        # Get candidate tweet_it\n",
    "        cand_tweet_id = c.tweet.name\n",
    "        # Get candidate numberic label\n",
    "        raw_label = gold_answers.select(\"sentiment\").filter(\"tweet_id == \"+str(cand_tweet_id)).collect()[0].sentiment\n",
    "        # Add offset to start enumeration from one\n",
    "        numeric_label = values.index(raw_label) + 1\n",
    "        # Store label\n",
    "        candidate_labels[split].append(numeric_label)\n",
    "         \n",
    "# Split candidate labels            \n",
    "train_cand_labels = candidate_labels[0]\n",
    "test_cand_labels = candidate_labels[1]\n",
    "\n",
    "print len(train_cand_labels)\n",
    "print len(test_cand_labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
