{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Extracting Maximum Storage Temperatures for Transistors from PDF Datasheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will walk through the process of using `Fonduer` to extract relations from [**richly formatted** data](https://hazyresearch.github.io/snorkel/blog/fonduer.html), where information is conveyed via combinations of textual, structural, tabular, and visual expressions, as seen in webpages, business reports, product specifications, and scientific literature.\n",
    "\n",
    "In this tutorial, we use `Fonduer` to identify mentions of the maximum storage temperature of transistors (e.g. `150Â°C`) in a corpus of transistor datasheets from [Digikey.com](https://www.digikey.com/products/en/discrete-semiconductor-products/transistors-bipolar-bjt-single/276).\n",
    "\n",
    "The tutorial is broken into several parts, each covering a Phase of the `Fonduer` pipeline (as outlined in the [paper](https://arxiv.org/abs/1703.05028)), and the iterative KBC process:\n",
    "\n",
    "1. KBC Initialization\n",
    "2. Candidate Generation and Multimodal Featurization\n",
    "3. Probabilistic Relation Classification\n",
    "4. Error Analysis and Iterative KBC\n",
    "\n",
    "In addition, we show how users can iteratively improve labeling functions to improve relation extraction quality.\n",
    "\n",
    "# Phase 1: KBC Initialization\n",
    "\n",
    "In this first phase of `Fonduer`'s pipeline, `Fonduer` uses a user specified _schema_ to initialize a relational database where the output KB will be stored. Furthermore, `Fonduer` iterates over its input _corpus_ and transforms each document into a unified data model, which captures the variability and multimodality of richly formatted data. This unified data model then servers as an intermediate representation used in the rest of the phases.\n",
    "\n",
    "This preprocessed data is saved to a database. Connection strings can be specified by setting the `SNORKELDB` environment variable. If no database is specified, then SQLite at `./snorkel.db` is created by default. However, to enabled parallel execution, we use PostgreSQL throughout this tutorial.\n",
    "\n",
    "We initialize several variables for convenience that define what the database should be called and what level of parallelization the `Fonduer` pipeline will be run with. In the code below, we use PostgreSQL as our database backend. \n",
    "\n",
    "Before you continue, please make sure that you have PostgreSQL installed and have created a new database named `stg_temp_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PARALLEL = 4 # assuming a quad-core machine\n",
    "ATTRIBUTE = \"stg_temp_max\"\n",
    "\n",
    "os.environ['SNORKELDBNAME'] = ATTRIBUTE\n",
    "os.environ['SNORKELDB'] = 'postgres://localhost:5432/' + os.environ['SNORKELDBNAME']\n",
    "        \n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Defining a Candidate Schema\n",
    "\n",
    "We first initialize a `SnorkelSession`, which manages the connection to the database automatically, and enables us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the _schema_ of the relation we want to extract. This must be a subclass of Candidate, and we define it using a helper function. Here, we define a binary relation which connects two Span objects of text. This is what creates the relation's database table if it does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 1.2 Parsing and Transforming the Input Documents into Unified Data Models\n",
    "\n",
    "Next, we load the corpus of datasheets and transform them into the unified data model. Each datasheet has a PDF and HTML representation. Both representations are used in conjunction to create a robust unified data model with textual, structural, tabular, and visual modality information. Note that since each document is independent of each other, we can parse the documents in parallel. Note that parallel execution will not work with SQLite, the default database engine. We depend on PostgreSQL for this functionality.\n",
    "\n",
    "### Configuring an `HTMLPreprocessor`\n",
    "We start by setting the paths to where our documents are stored, and defining a `HTMLPreprocessor` to read in the documents found in the specified paths. `max_docs` specified the number of documents to parse. For the sake of this tutorial, we only look at 100 documents.\n",
    "\n",
    "**Note that you need to have run `download_data.sh` before executing these next steps or you won't have the documents needed for the tutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLPreprocessor, OmniParser\n",
    "\n",
    "docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/data/html/'\n",
    "pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/data/pdf/'\n",
    "\n",
    "max_docs = 20 if 'CI' in os.environ else float('inf')\n",
    "doc_preprocessor = HTMLPreprocessor(docs_path, max_docs=max_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring an `OmniParser`\n",
    "Next, we configure an `OmniParser`, which serves as our `CorpusParser` for PDF documents. We use [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) as a preprocessing tool to split our documents into phrases and tokens, and to provide annotations such as part-of-speech tags and dependency parse structures for these phrases. In addition, we can specify which modality information to include in the unified data model for each document. Below, we enable all modality information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 7.91 s, sys: 156 ms, total: 8.06 s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "corpus_parser = OmniParser(structural=True, lingual=True, visual=True, pdf_path=pdf_path)\n",
    "%time corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which `Fonduer` uses) to check how many documents and phrases (sentences) were parsed, or even check how many phrases and tables are contained in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 100\n",
      "Phrases: 43672\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Phrase\n",
    "\n",
    "print \"Documents:\", session.query(Document).count()\n",
    "print \"Phrases:\", session.query(Phrase).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dividing the Corpus into Test and Train\n",
    "\n",
    "We'll split the documents 80/10/10 into train/dev/test splits. Note that here we do this in a non-random order to preverse the consistency in the tutorial, and we reference the splits by 0/1/2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Infineon-BC817KSERIES_BC818KSERIES-DS-v01_01-en',\n",
      " u'MicrosemiCorporation_2N2484UB',\n",
      " u'INFNS19372-1',\n",
      " u'2N4123-D',\n",
      " u'LITES00690-1',\n",
      " u'MOTOS04796-1',\n",
      " u'BC182-D',\n",
      " u'MMBT3904',\n",
      " u'FairchildSemiconductor_KSC2310YTA',\n",
      " u'DiodesIncorporated_FZT651TC',\n",
      " u'FAIRS19194-1',\n",
      " u'FAIRS25065-1',\n",
      " u'PHGLS20267-1',\n",
      " u'KECCS03676-1',\n",
      " u'BC818-40LT1-D',\n",
      " u'DISES00490-1',\n",
      " u'KECCS05435-1',\n",
      " u'LTSCS02920-1',\n",
      " u'CSEMS05382-1',\n",
      " u'DISES00616-1',\n",
      " u'LITES00686-1',\n",
      " u'CSEMS02742-1',\n",
      " u'2N3906-D',\n",
      " u'CSEMS03485-1',\n",
      " u'BC182',\n",
      " u'ONSemiconductor_MMBT6521LT1',\n",
      " u'DiodesIncorporated_ZTX953STZ',\n",
      " u'LTSCS02912-1',\n",
      " u'CentralSemiconductorCorp_CMPT5401ETR',\n",
      " u'CentralSemiconductorCorp_CXT4033TR',\n",
      " u'MCCCS09741-1',\n",
      " u'DISES00242-1',\n",
      " u'LITES00424-1',\n",
      " u'AUKCS04635-1',\n",
      " u'MINDS00015-1',\n",
      " u'2N6427',\n",
      " u'MicroCommercialCo_TIP29ABP',\n",
      " u'MOTOS03160-1',\n",
      " u'DISES00645-1',\n",
      " u'BC546',\n",
      " u'BC337',\n",
      " u'MicroCommercialCo_2N3904AP',\n",
      " u'2N4124',\n",
      " u'Infineon-BC857SERIES_BC858SERIES_BC859SERIES_BC860SERIES-DS-v01_01-en',\n",
      " u'DISES00192-1',\n",
      " u'2N6426-D',\n",
      " u'BC818',\n",
      " u'BC546A_Series_B14-521026',\n",
      " u'DiodesIncorporated_FCX491ATA',\n",
      " u'BC547',\n",
      " u'DiodesIncorporated_ZTX688BSTZ',\n",
      " u'DIODS00215-1',\n",
      " u'DIODS13249-1',\n",
      " u'BournsInc_BD246BS',\n",
      " u'CentralSemiconductorCorp_CENU45',\n",
      " u'DiodesIncorporated_ZXT690BKTC',\n",
      " u'CentralSemiconductorCorp_2N4013',\n",
      " u'ONSMS04099-1',\n",
      " u'LITES00689-1',\n",
      " u'DISES00023-1',\n",
      " u'MMMCS17742-1',\n",
      " u'2N3906',\n",
      " u'JCSTS01155-1',\n",
      " u'LTSCS02910-1',\n",
      " u'MOTOS04676-1',\n",
      " u'112823',\n",
      " u'PHGLS19500-1',\n",
      " u'NXPUSAInc_PBSS5360PASX',\n",
      " u'DiodesIncorporated_ZTX789ASTZ',\n",
      " u'BournsInc_TIP152S',\n",
      " u'MOTOS03189-1',\n",
      " u'DISES00189-1',\n",
      " u'MCCCS08610-1',\n",
      " u'DiodesIncorporated_2DD26527',\n",
      " u'MCCCS08984-1',\n",
      " u'BC546-BC548C(TO-92)',\n",
      " u'MCCCS09540-1',\n",
      " u'MCCCS08818-1',\n",
      " u'BC337-D',\n",
      " u'CSEMS05383-1']\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "splits = (0.8, 0.9)\n",
    "data = [(doc.name, doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if i < splits[0] * ld:\n",
    "        train_docs.add(doc)\n",
    "    elif i < splits[1] * ld:\n",
    "        dev_docs.add(doc)\n",
    "    else:\n",
    "        test_docs.add(doc)\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs])\n",
    "# pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Candidate Extraction & Multimodal Featurization\n",
    "Given the unified data model from Phase 1, `Fonduer` extracts relation candidates based on user-provided **matchers** and **throttlers**. Then, `Fonduer` leverages the multimodality information captured in the unified data model to provide multimodal features for each candidate.\n",
    "\n",
    "## 2.1 Candidate Extraction\n",
    "\n",
    "The next step is to extract **candidates** from our corpus. A `candidate` is the object for which we want to make predictions. In this case, the candidates are pairs of transistor part numbers and their corresponding maximum storage temperatures as found in their datasheets. Our task is to predict which pairs are true in the associated document.\n",
    "\n",
    "To do so, we write **matchers** to define which spans of text in the corpus are instances of each entity. Matchers can leverage a variety of information from regular expressions, to dictionaries, to user-defined functions. Furthermore, different techniques can be combined to form higher quality matchers. In general, matchers should seek to be as precise as possible while maintaining complete recall.\n",
    "\n",
    "In our case, we need to write a matcher that defines a transistor part number and a matcher to define a valid temperature value.\n",
    "\n",
    "### Writing a simple temperature matcher\n",
    "\n",
    "Our maximum storage temperature matcher can be a very simple regular expression since we know that we are looking for integers, and by inspecting a portion of our corpus, we see that maximum storage temperatures fall within a fairly narrow range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import *\n",
    "\n",
    "attr_matcher = RegexMatchSpan(rgx=r'(?:[1][5-9]|20)[05]', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing an advanced transistor part matcher\n",
    "\n",
    "In contrast, transistor part numbers are complex expressions. Here, we show how transistor part numbers can leverage [naming conventions](https://en.wikipedia.org/wiki/Transistor#Part_numbering_standards.2Fspecifications) as regular expressions, and use a dictionary of known part numbers, and use user-defined functions together. First, we create a regular expression matcher for standard transistor naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Transistor Naming Conventions as Regular Expressions ###\n",
    "eeca_rgx = '([ABC][A-Z][WXYZ]?[0-9]{3,5}(?:[A-Z]){0,5}[0-9]?[A-Z]?(?:-[A-Z0-9]{1,7})?(?:[-][A-Z0-9]{1,2})?(?:\\/DG)?)'\n",
    "jedec_rgx = '(2N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jis_rgx = '(2S[ABCDEFGHJKMQRSTVZ]{1}[\\d]{2,4})'\n",
    "others_rgx = '((?:NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|ZXT|TIS|TIPL|DTC|MMBT|SMMBT|PZT|FZT|STD|BUV|PBSS|KSC|CXT|FCX|CMPT){1}[\\d]{2,4}[A-Z]{0,5}(?:-[A-Z0-9]{0,6})?(?:[-][A-Z0-9]{0,1})?)'\n",
    "\n",
    "part_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "part_rgx_matcher = RegexMatchSpan(rgx=part_rgx, longest_match_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create a matcher from a dictionary of known part numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_digikey_parts_set(path):\n",
    "    \"\"\"\n",
    "    Reads in the digikey part dictionary and yeilds each part.\n",
    "    \"\"\"\n",
    "    all_parts = set()\n",
    "    with open(path, \"r\") as csvinput:\n",
    "        reader = csv.reader(csvinput)\n",
    "        for line in reader:\n",
    "            (part, url) = line\n",
    "            all_parts.add(part)\n",
    "    return all_parts\n",
    "            \n",
    "### Dictionary of known transistor parts ###\n",
    "dict_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/data/digikey_part_dictionary.csv'\n",
    "part_dict_matcher = DictionaryMatch(d=get_digikey_parts_set(dict_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use user-defined functions to further improve our matchers. For example, here we use patterns in the document filenames as a signal for whether a span of text in a document is a valid transistor part number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_prefix_length_diff(str1, str2):\n",
    "    for i in range(min(len(str1), len(str2))):\n",
    "        if str1[i] != str2[i]:\n",
    "            return min(len(str1), len(str2)) - i\n",
    "    return 0\n",
    "\n",
    "def part_file_name_conditions(attr):\n",
    "    file_name = attr.sentence.document.name\n",
    "    if len(file_name.split('_')) != 2: return False\n",
    "    if attr.get_span()[0] == '-': return False\n",
    "    name = attr.get_span().replace('-', '')\n",
    "    return any(char.isdigit() for char in name) and any(char.isalpha() for char in name) and common_prefix_length_diff(file_name.split('_')[1], name) <= 2\n",
    "\n",
    "add_rgx = '^[A-Z0-9\\-]{5,15}$'\n",
    "\n",
    "part_file_name_lambda_matcher = LambdaFunctionMatch(func=part_file_name_conditions)\n",
    "part_file_name_matcher = Intersect(RegexMatchSpan(rgx=add_rgx, longest_match_only=True), part_file_name_lambda_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can union all of these matchers together to form our final part matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_matcher = Union(part_rgx_matcher, part_dict_matcher, part_file_name_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two matchers define each entity in our relation schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a relation's `ContextSpaces`\n",
    "\n",
    "Next, in order to define the \"space\" of all candidates that are even considered from the document, we need to define a `ContextSpace` for each component of the relation we wish to extract.\n",
    "\n",
    "In the case of transistor part numbers, the `ContextSpace` can be quite complex due to the need to handle implicit part numbers that are implied in text like \"BC546A/B/C...BC548A/B/C\", which refers to 9 unique part numbers. In addition, to handle these, we consider all n-grams up to 3 words long.\n",
    "\n",
    "In contrast, the `ContextSpace` for temperature values is simpler: we only need to process different unicode representations of a (`-`), and don't need to look at more than two works at a time.\n",
    "\n",
    "When no special preproessing like this is needed, we could have used the default `OmniNgrams` class provided by `snorkel.candidates`. For example, if we were looking to match polarities, which only take the form of \"NPN\" or \"PNP\", we could've used `attr_ngrams = OmniNgrams(n_max=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hardware_spaces import OmniNgramsPart, OmniNgramsTemp\n",
    "    \n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=None, n_max=3)\n",
    "attr_ngrams = OmniNgramsTemp(n_max=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining candidate `Throttlers`\n",
    "\n",
    "Next, we need to define **throttlers**, which allow us to further prune excess candidates and avoid unnecessarily materializing invalid candidates. Trottlers, like matchers, act as hard filters, and should be created to have high precision while maintaining complete recall, if possible.\n",
    "\n",
    "Here, we create a throttler that discards candidates if they are in the same table, but the part and storage temperature are not vertically or horizontally aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "import re\n",
    "\n",
    "def stg_temp_throttler((part, attr)):\n",
    "    if same_table((part, attr)):\n",
    "        return (is_horz_aligned((part, attr)) or is_vert_aligned((part, attr)))\n",
    "    return True\n",
    "\n",
    "throttler = stg_temp_throttler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the `CandidateExtractor`\n",
    "\n",
    "Now, we have all the component necessary to perform candidate extraction. We have defined the \"space\" of things to consider for each candidate, provided matchers that signal when a valid mention is seen, and a throttler to prunes away excess candidates. We now can define the `CandidateExtractor` with the contexts to extract from, the matchers, and the throttler to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "CPU times: user 1min 9s, sys: 4.91 s, total: 1min 14s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "\n",
    "candidate_extractor = CandidateExtractor(Part_Attr, \n",
    "                        [part_ngrams, attr_ngrams], \n",
    "                        [part_matcher, attr_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "%time candidate_extractor.apply(train_docs, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train/dev/test as splits 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 32095\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(Part_Attr).filter(Part_Attr.split == 0).all()\n",
    "print \"Number of candidates:\", len(train_cands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating for development and test splits\n",
    "Finally, we rerun the same operation for the other two document divisions: dev and test. For each, we simply load the `Corpus` object and run them through the `CandidateExtractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "Number of candidates: 3248\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "Number of candidates: 1875\n",
      "CPU times: user 13.2 s, sys: 676 ms, total: 13.8 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, docs in enumerate([dev_docs, test_docs]):\n",
    "    candidate_extractor.apply(docs, split=i+1)\n",
    "    print \"Number of candidates:\", session.query(Part_Attr).filter(Part_Attr.split == i+1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Multimodal Featurization\n",
    "Unlike dealing with plain unstructured text, `Fonduer` deals with richly formatted data, and consequently featurizes each candidate with a baseline library of multimodal features. \n",
    "\n",
    "### Featurize with `Fonduer`'s optimized Postgres Feature Annotator\n",
    "We now annotate the candidates in our training, dev, and test sets with features. The `BatchFeatureAnnotator` provided by `Fonduer` allows this to be done in parallel to improve performance.\n",
    "\n",
    "`featurizer.apply` takes three important arguments.\n",
    "* `split` defines which candidate set wer are dealing with. For example, `split=0` is the training set.\n",
    "* `replace_key_set` determine whether or not replace, or reinitialize, the set of features to apply to candidates. That is, when `replace_key_set` is true, key set of features will be replaced with the key set of the features found in the split that is being processed.\n",
    "* `parallelism` determines how many processes to run in parallel.\n",
    "\n",
    "Notices that `replace_key_set=True` only for the first call to `featurizer.apply`, while the other calls have this parameter set to `False`. This is because we want to have the set of features we label candidates with defined by the features found in the set of training documents only. If a later call to `featurizer.apply` replaced the key set, then only the features of that particular split would be considered later in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_feature to postgres\n",
      "COPY 32095\n",
      "\n",
      "CPU times: user 34.5 s, sys: 664 ms, total: 35.2 s\n",
      "Wall time: 9min 17s\n",
      "(32095, 24710)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_feature_updates to postgres\n",
      "COPY 3248\n",
      "\n",
      "CPU times: user 2.6 s, sys: 252 ms, total: 2.85 s\n",
      "Wall time: 53.5 s\n",
      "(3248, 24710)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_feature_updates to postgres\n",
      "COPY 1875\n",
      "\n",
      "CPU times: user 2.31 s, sys: 236 ms, total: 2.55 s\n",
      "Wall time: 30.9 s\n",
      "(1875, 24710)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.async_annotations import BatchFeatureAnnotator\n",
    "\n",
    "featurizer = BatchFeatureAnnotator(Part_Attr)\n",
    "%time F_train = featurizer.apply(split=0, replace_key_set=True, parallelism=PARALLEL)\n",
    "print F_train.shape\n",
    "%time F_dev = featurizer.apply(split=1, replace_key_set=False, parallelism=PARALLEL)\n",
    "print F_dev.shape\n",
    "%time F_test = featurizer.apply(split=2, replace_key_set=False, parallelism=PARALLEL)\n",
    "print F_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this phase, `Fonduer` has generated the set of candidates and the feature matrix. Note that Phase 1 and 2 are relatively static and typically are only executed once during the KBC process.\n",
    "\n",
    "# Phase 3: Probabilistic Relation Classification\n",
    "In this phase, `Fonduer` applies user-defined **labeling functions**, which express various heuristics, patterns, and [weak supervision](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html) strategies to label our data, to each of the candidates to create a label matrix that is used by our data programming engine.\n",
    "\n",
    "In the wild, hand-labeled training data is rare and expensive. A common scenario is to have access to tons of unlabeled training data, and have some idea of how to label them programmatically. For example:\n",
    "* We may be able to think of text patterns that would indicate a part and polarity mention are related, for example the word \"temperature\" appearing between them.\n",
    "* We may have access to an external knowledge base that lists some pairs of parts and polarities, and can use these to noisily label some of our mention pairs.\n",
    "Our labeling functions will capture these types of strategies. We know that these labeling functions will not be perfect, and some may be quite low-quality, so we will model their accuracies with a generative model, which `Fonduer` will help us easily apply.\n",
    "\n",
    "Using data programming, we can then train machine learning models to learn which features are the most important in classifying candidates.\n",
    "\n",
    "### Loading Gold Data\n",
    "For convenience in error analysis and evaluation, we have already annotated the dev and test set for this tutorial, and we'll now load it using an externally-defined helper function.\n",
    "\n",
    "Loading and saving external \"gold\" labels can be a bit messy, but is often a critical part of development, especially when gold labels are expensive and/or time-consuming to obtain. Snorkel stores all labels that are manually annotated in a **stable** format (called StableLabels), which is somewhat independent from the rest of Snorkel's data model, does not get deleted when you delete the candidates, corpus, or any other objects, and can be recovered even if the rest of the data changes or is deleted.\n",
    "\n",
    "Our general procedure with external labels is to load them into the `StableLabel` table, then use `Fonduer`'s helpers to load them into the main data model from there. If interested in example implementation details, please see the script we now load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 37218 candidate labels\n",
      "[========================================] 100%\n",
      "AnnotatorLabels created: 37218\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/data/hardware_tutorial_gold.csv'\n",
    "load_hardware_labels(session, Part_Attr, gold_file, ATTRIBUTE ,annotator_name='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Labeling Functions\n",
    "\n",
    "In `Fonduer`, our primary interface through which we provide training signal to the end extraction model we are training is by writing labeling functions (**LFs**) (as opposed to hand-labeling massive training sets).\n",
    "\n",
    "A labeling function isn't anything special. It's just a Python function that accepts a `Candidate` as the input argument and returns `1` if it says the Candidate should be marked as true, `-1` if it says the `Candidate` should be marked as false, and `0` if it doesn't know how to vote and abstains. In practice, many labeling functions are unipolar: it labels only 1s and 0s, or it labels only -1s and 0s.\n",
    "\n",
    "Recall that our goal is to ultimately train a high-performance classification model that predicts which of our Candidates are true mentions of maximum storage temperature relations. It turns out that we can do this by writing potentially low-quality labeling functions!\n",
    "\n",
    "With `Fonduer`, labeling functions can be written using intuitive patterns discovered by inspecting the target corpus. A library of labeling function helpers can be found in `snorke.contrib.fonduer.lf_helpers`. \n",
    "\n",
    "For example, inspecting several document may reveal that storage temperatures are typically listed inside a table where the row header contains the word \"storage\". This intuitive pattern can be directly expressed as a labeling function. Similarly, the word \"temperature\" is an obvious positive signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.lf_helpers import *\n",
    "import re\n",
    "\n",
    "def LF_storage_row(c):\n",
    "    return 1 if 'storage' in get_row_ngrams(c.attr) else 0\n",
    "\n",
    "def LF_temperature_row(c):\n",
    "    return 1 if 'temperature' in get_row_ngrams(c.attr) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We express several of these simple patterns below as a set of labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_operating_row(c):\n",
    "    return 1 if 'operating' in get_row_ngrams(c.attr) else 0\n",
    "\n",
    "def LF_tstg_row(c):\n",
    "    return 1 if overlap(\n",
    "        ['tstg','stg','ts'], \n",
    "        list(get_row_ngrams(c.attr))) else 0\n",
    "\n",
    "\n",
    "def LF_to_left(c):\n",
    "    return 1 if 'to' in get_left_ngrams(c.attr, window=2) else 0\n",
    "\n",
    "def LF_negative_number_left(c):\n",
    "    return 1 if any([re.match(r'-\\s*\\d+', ngram) for ngram in get_left_ngrams(c.attr, window=4)]) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we collect all of the labeling function we would like to use into a single list, which is provided as input to the `LabelAnnotator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg_temp_lfs = [\n",
    "    LF_storage_row,\n",
    "    LF_operating_row,\n",
    "    LF_temperature_row,\n",
    "    LF_tstg_row,\n",
    "    LF_to_left,\n",
    "    LF_negative_number_left\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Labeling Functions\n",
    "\n",
    "Next, we need to actually run the LFs over all of our training candidates, producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database. We'll do this using the `LabelAnnotator` class, a `UDF` which we will again run with `UDFRunner`. Note that this will delete any existing `Labels` and `LabelKeys` for this candidate set. Also note that we are using `Fonduer`'s optimized batch label annotator, which runs in parallel and depends on having Postgres as the backend database. \n",
    "\n",
    "By default, `labeler.apply` will drop the existing table of labeling functions and the label values for each candidate. However, this behavior can be controlled by three parameters to the function to imperove iteration performance and reduce redundant computation:\n",
    "- `split` defines which set to operate on (e.g. train, dev, or test)\n",
    "- `clear` can be `True` or `False`, and is `True` by default. When set to `False`, the labeling functioni table is not dropped, and the behavior of `labeler.apply` is defined by the following two parameters.\n",
    "- `update_keys` can be `True` or `False`. When `True`, the keys (which are each labeling function) are updated according to the set of labeling functions provided to the function. This should be set to `True` if new labeling functions are added. When `False`, no new LFs are evaluated and the keys of existing LFs remain the same.\n",
    "- `update_values` can be `True` or `False`. This defines how to resolve conflicts. When `True`, the values assigned to each candiate is updated to the new values when in conflict. This should be set to `True` if labeling function logic is edited, even though the name of the labeling function remains the same. When `False`, the existing labels assigned to each candidate are used, and newly computed labels are ignored.\n",
    "- `parallelism` is the amount of parallelism to use when labeling.\n",
    "\n",
    "With this in mind, we set `clear=True` when we first apply our labeling functions, and this ensures that the table is created and intialized with proper keys and values.\n",
    "\n",
    "In future iterations, we would typically set `clear=False, update_keys=True, update_values=True` so that we can simple update the set of LFs and their values without recreating the entire table. We will see how this is used later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_label to postgres\n",
      "COPY 32095\n",
      "\n",
      "CPU times: user 1.32 s, sys: 224 ms, total: 1.54 s\n",
      "Wall time: 3min 13s\n",
      "(32095, 6)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.fonduer.async_annotations import BatchLabelAnnotator\n",
    "\n",
    "labeler = BatchLabelAnnotator(Part_Attr, lfs = stg_temp_lfs)\n",
    "%time L_train = labeler.apply(split=0, clear=True, parallelism=PARALLEL)\n",
    "print L_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the scipy.sparse.csr_matrix class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part_Attr(Span(\"BC817K-40\", sentence=84332, chars=[0,8], words=[0,0]), ImplicitSpan(\"170\", sentence=84520, words=[0,0], position=[0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.get_candidate(session, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view statistics about the resulting label matrix.\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for.\n",
    "\n",
    "In addition, because we have already loaded the gold labels, we can view the emperical accuracy of these labeling functions when compared to our gold labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_operating_row</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>733</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tstg_row</th>\n",
       "      <td>1</td>\n",
       "      <td>0.061256</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1438</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_negative_number_left</th>\n",
       "      <td>2</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.064029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1570</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_left</th>\n",
       "      <td>3</td>\n",
       "      <td>0.086462</td>\n",
       "      <td>0.065462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1419</td>\n",
       "      <td>1356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_temperature_row</th>\n",
       "      <td>4</td>\n",
       "      <td>0.092881</td>\n",
       "      <td>0.072379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2465</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_storage_row</th>\n",
       "      <td>5</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts    TP    FP  FN  TN  \\\n",
       "LF_operating_row         0  0.033494  0.033494        0.0   733   342   0   0   \n",
       "LF_tstg_row              1  0.061256  0.061069        0.0  1438   528   0   0   \n",
       "LF_negative_number_left  2  0.064995  0.064029        0.0  1570   516   0   0   \n",
       "LF_to_left               3  0.086462  0.065462        0.0  1419  1356   0   0   \n",
       "LF_temperature_row       4  0.092881  0.072379        0.0  2465   516   0   0   \n",
       "LF_storage_row           5  0.063374  0.063374        0.0  1511   523   0   0   \n",
       "\n",
       "                         Empirical Acc.  \n",
       "LF_operating_row               0.681860  \n",
       "LF_tstg_row                    0.731434  \n",
       "LF_negative_number_left        0.752637  \n",
       "LF_to_left                     0.511351  \n",
       "LF_temperature_row             0.826904  \n",
       "LF_storage_row                 0.742871  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "%time L_train.lf_stats(L_gold_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Generative Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwhsiao/repos/snorkel/.virtualenv/local/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 35s, sys: 168 ms, total: 4min 35s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=500, decay=0.9, step_size=0.001/L_train.shape[0], reg_param=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates to get the noise-aware training label set. We'll refer to these as the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the distribution of the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe98a123810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the learned accuracy parameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72163977,  0.71009437,  0.71274458,  0.73344195,  0.7128958 ,\n",
       "        0.72224832])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Using the Model to Iterate on Labeling Functions\n",
    "\n",
    "Now that we have learned the generative model, we can stop here and use this to potentially debug and/or improve our labeling function set. First, we apply the LFs to our development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "Copying part_attr_label_updates to postgres\n",
      "COPY 3248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we get the score of the generative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.142\n",
      "Neg. class accuracy: 0.99\n",
      "Precision            0.944\n",
      "Recall               0.142\n",
      "F1                   0.247\n",
      "----------------------------------------\n",
      "TP: 255 | FP: 15 | TN: 1436 | FN: 1542\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "tp, fp, tn, fn = gen_model.score(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view statistics about the labeling function's learned accuracy and compare them to the emperical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_operating_row</th>\n",
       "      <td>0</td>\n",
       "      <td>0.028325</td>\n",
       "      <td>0.028325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967391</td>\n",
       "      <td>0.721640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tstg_row</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054495</td>\n",
       "      <td>0.054495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.710094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_negative_number_left</th>\n",
       "      <td>2</td>\n",
       "      <td>0.064655</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.712745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_to_left</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.733442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_temperature_row</th>\n",
       "      <td>4</td>\n",
       "      <td>0.080665</td>\n",
       "      <td>0.062192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950382</td>\n",
       "      <td>0.712896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_storage_row</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.722248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts   TP  FP  FN  TN  \\\n",
       "LF_operating_row         0  0.028325  0.028325        0.0   89   3   0   0   \n",
       "LF_tstg_row              1  0.054495  0.054495        0.0  170   7   0   0   \n",
       "LF_negative_number_left  2  0.064655  0.063424        0.0  198  12   0   0   \n",
       "LF_to_left               3  0.048645  0.048645        0.0  154   4   0   0   \n",
       "LF_temperature_row       4  0.080665  0.062192        0.0  249  13   0   0   \n",
       "LF_storage_row           5  0.043103  0.043103        0.0  133   7   0   0   \n",
       "\n",
       "                         Empirical Acc.  Learned Acc.  \n",
       "LF_operating_row               0.967391      0.721640  \n",
       "LF_tstg_row                    0.960452      0.710094  \n",
       "LF_negative_number_left        0.942857      0.712745  \n",
       "LF_to_left                     0.974684      0.733442  \n",
       "LF_temperature_row             0.950382      0.712896  \n",
       "LF_storage_row                 0.950000      0.722248  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(L_gold_dev, gen_model.weights.lf_accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Generative Model Performance\n",
    "\n",
    "At this point, we should be getting an F1 score of around 0.6 to 0.7 on the development set, which is pretty good! However, we should be very careful in interpreting this. Since we developed our labeling functions using this development set as a guide, and our generative model is composed of these labeling functions, we expect it to score very well here!\n",
    "\n",
    "In fact, it is probably somewhat overfit to this set. However this is fine, since in the next, we'll train a more powerful end extraction model which will generalize beyond the development set, and which we will evaluate on a blind test set (i.e. one we never looked at during development).\n",
    "\n",
    "\n",
    "### Training the Discriminative Model\n",
    "\n",
    "Now, we'll use the noisy training labels we generated in the last part to train our end extraction model. For this tutorial, we will be training a simple - but fairly effective - logistic regression model.\n",
    "\n",
    "We use the training marginals to train a discriminative model that classifies each Candidate as a true or false mention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLR] lr=0.001 l1=0.0 l2=0.0\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=4117  #epochs=200  batch size=100\n",
      "[SparseLR] Epoch 0 (0.90s)\tAvg. loss=0.276521\tNNZ=24710\n",
      "[SparseLR] Epoch 5 (5.48s)\tAvg. loss=0.150392\tNNZ=24710\n",
      "[SparseLR] Epoch 10 (9.83s)\tAvg. loss=0.146465\tNNZ=24710\n",
      "[SparseLR] Epoch 15 (14.46s)\tAvg. loss=0.145288\tNNZ=24710\n",
      "[SparseLR] Epoch 20 (18.78s)\tAvg. loss=0.144761\tNNZ=24710\n",
      "[SparseLR] Epoch 25 (23.35s)\tAvg. loss=0.144479\tNNZ=24710\n",
      "[SparseLR] Epoch 30 (28.27s)\tAvg. loss=0.144314\tNNZ=24710\n",
      "[SparseLR] Epoch 35 (32.60s)\tAvg. loss=0.144238\tNNZ=24710\n",
      "[SparseLR] Epoch 40 (37.02s)\tAvg. loss=0.144132\tNNZ=24710\n",
      "[SparseLR] Epoch 45 (41.60s)\tAvg. loss=0.144100\tNNZ=24710\n",
      "[SparseLR] Epoch 50 (46.44s)\tAvg. loss=0.144041\tNNZ=24710\n",
      "[SparseLR] Epoch 55 (51.26s)\tAvg. loss=0.144035\tNNZ=24710\n",
      "[SparseLR] Epoch 60 (55.82s)\tAvg. loss=0.143992\tNNZ=24710\n",
      "[SparseLR] Epoch 65 (60.77s)\tAvg. loss=0.144002\tNNZ=24710\n",
      "[SparseLR] Epoch 70 (64.96s)\tAvg. loss=0.143983\tNNZ=24710\n",
      "[SparseLR] Epoch 75 (69.40s)\tAvg. loss=0.143986\tNNZ=24710\n",
      "[SparseLR] Epoch 80 (73.48s)\tAvg. loss=0.143953\tNNZ=24710\n",
      "[SparseLR] Epoch 85 (77.97s)\tAvg. loss=0.143983\tNNZ=24710\n",
      "[SparseLR] Epoch 90 (82.19s)\tAvg. loss=0.143964\tNNZ=24710\n",
      "[SparseLR] Epoch 95 (86.66s)\tAvg. loss=0.143978\tNNZ=24710\n",
      "[SparseLR] Epoch 100 (91.03s)\tAvg. loss=0.143949\tNNZ=24710\n",
      "[SparseLR] Epoch 105 (96.36s)\tAvg. loss=0.143994\tNNZ=24710\n",
      "[SparseLR] Epoch 110 (100.46s)\tAvg. loss=0.143942\tNNZ=24710\n",
      "[SparseLR] Epoch 115 (105.03s)\tAvg. loss=0.143984\tNNZ=24710\n",
      "[SparseLR] Epoch 120 (109.63s)\tAvg. loss=0.144020\tNNZ=24710\n",
      "[SparseLR] Epoch 125 (114.91s)\tAvg. loss=0.144013\tNNZ=24710\n",
      "[SparseLR] Epoch 130 (119.11s)\tAvg. loss=0.143983\tNNZ=24710\n",
      "[SparseLR] Epoch 135 (123.74s)\tAvg. loss=0.144021\tNNZ=24710\n",
      "[SparseLR] Epoch 140 (128.01s)\tAvg. loss=0.143966\tNNZ=24710\n",
      "[SparseLR] Epoch 145 (132.41s)\tAvg. loss=0.143987\tNNZ=24710\n",
      "[SparseLR] Epoch 150 (137.52s)\tAvg. loss=0.143978\tNNZ=24710\n",
      "[SparseLR] Epoch 155 (141.87s)\tAvg. loss=0.143999\tNNZ=24710\n",
      "[SparseLR] Epoch 160 (146.20s)\tAvg. loss=0.143951\tNNZ=24710\n",
      "[SparseLR] Epoch 165 (150.71s)\tAvg. loss=0.144004\tNNZ=24710\n",
      "[SparseLR] Epoch 170 (154.96s)\tAvg. loss=0.144016\tNNZ=24710\n",
      "[SparseLR] Epoch 175 (159.32s)\tAvg. loss=0.144013\tNNZ=24710\n",
      "[SparseLR] Epoch 180 (163.74s)\tAvg. loss=0.143972\tNNZ=24710\n",
      "[SparseLR] Epoch 185 (168.87s)\tAvg. loss=0.144018\tNNZ=24710\n",
      "[SparseLR] Epoch 190 (173.13s)\tAvg. loss=0.143960\tNNZ=24710\n",
      "[SparseLR] Epoch 195 (177.73s)\tAvg. loss=0.143988\tNNZ=24710\n",
      "[SparseLR] Epoch 199 (181.82s)\tAvg. loss=0.143988\tNNZ=24710\n",
      "[SparseLR] Training done (181.82s)\n",
      "CPU times: user 3min 31s, sys: 2.49 s, total: 3min 34s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the Test Set\n",
    "In this final section, we'll get the score we've been after: the performance of the extraction model on the blind test set (split 2). First, we load the test set labels and gold candidates from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now, we score using the discriminitive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.276\n",
      "Recall               1.0\n",
      "F1                   0.433\n",
      "----------------------------------------\n",
      "TP: 518 | FP: 1357 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.343\n",
      "Corpus Recall    1.0\n",
      "Corpus F1        0.511\n",
      "----------------------------------------\n",
      "TP: 83 | FP: 159 | FN: 0\n",
      "========================================\n",
      "\n",
      "CPU times: user 3.81 s, sys: 176 ms, total: 3.98 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "import cPickle as pickle\n",
    "pickle_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/hardware/data/parts_by_doc_dict.pkl'\n",
    "with open(pickle_file, 'r') as f:\n",
    "    parts_by_doc = pickle.load(f)\n",
    "\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, test_docs, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4:  Error Analysis & Iterative KBC\n",
    "\n",
    "During the development process, we can iteratively improve the quality of our labeling functions through error analysis, without executing the full pipeline as in previous techniques. \n",
    "\n",
    "You may have noticed that our final score is about 42 F1 points. To remedy this and improve our quality, we can perform error analysis to understand what kinds of patterns we may have missed, or what issues exist with our labeling functions. Then, we can edit our set of labeling functions and rerun Phase 3, Probabilistic Relation Classification. \n",
    "\n",
    "## Error Analysis\n",
    "For example, notice that our `entity_level_f1` returns `TP`, `FP`, `FN` sets. We can also see that our recall is high, but we have low precision, so let's look at our false positivies, `FP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'BC546-D', u'BC546', u'180'),\n",
       " (u'BC546-D', u'BC546', u'200'),\n",
       " (u'BC546-D', u'BC546B', u'180'),\n",
       " (u'BC546-D', u'BC546B', u'200'),\n",
       " (u'BC546-D', u'BC546BG', u'180'),\n",
       " (u'BC546-D', u'BC546BG', u'200'),\n",
       " (u'BC546-D', u'BC546BRL1', u'180'),\n",
       " (u'BC546-D', u'BC546BRL1', u'200'),\n",
       " (u'BC546-D', u'BC546BRL1G', u'180'),\n",
       " (u'BC546-D', u'BC546BRL1G', u'200'),\n",
       " (u'BC546-D', u'BC546BZL1G', u'180'),\n",
       " (u'BC546-D', u'BC546BZL1G', u'200'),\n",
       " (u'BC546-D', u'BC547', u'180'),\n",
       " (u'BC546-D', u'BC547', u'200'),\n",
       " (u'BC546-D', u'BC547A', u'180'),\n",
       " (u'BC546-D', u'BC547A', u'200'),\n",
       " (u'BC546-D', u'BC547ARL', u'180'),\n",
       " (u'BC546-D', u'BC547ARL', u'200'),\n",
       " (u'BC546-D', u'BC547ARLG', u'180'),\n",
       " (u'BC546-D', u'BC547ARLG', u'200'),\n",
       " (u'BC546-D', u'BC547AZL1G', u'180'),\n",
       " (u'BC546-D', u'BC547AZL1G', u'200'),\n",
       " (u'BC546-D', u'BC547B', u'180'),\n",
       " (u'BC546-D', u'BC547B', u'200'),\n",
       " (u'BC546-D', u'BC547BG', u'180'),\n",
       " (u'BC546-D', u'BC547BG', u'200'),\n",
       " (u'BC546-D', u'BC547BRL1G', u'180'),\n",
       " (u'BC546-D', u'BC547BRL1G', u'200'),\n",
       " (u'BC546-D', u'BC547BZL1G', u'180'),\n",
       " (u'BC546-D', u'BC547BZL1G', u'200'),\n",
       " (u'BC546-D', u'BC547C', u'180'),\n",
       " (u'BC546-D', u'BC547C', u'200'),\n",
       " (u'BC546-D', u'BC547CG', u'180'),\n",
       " (u'BC546-D', u'BC547CG', u'200'),\n",
       " (u'BC546-D', u'BC547CZL1G', u'180'),\n",
       " (u'BC546-D', u'BC547CZL1G', u'200'),\n",
       " (u'BC546-D', u'BC548', u'180'),\n",
       " (u'BC546-D', u'BC548', u'200'),\n",
       " (u'BC546-D', u'BC548B', u'180'),\n",
       " (u'BC546-D', u'BC548B', u'200'),\n",
       " (u'BC546-D', u'BC548BG', u'180'),\n",
       " (u'BC546-D', u'BC548BG', u'200'),\n",
       " (u'BC546-D', u'BC548BRL1G', u'180'),\n",
       " (u'BC546-D', u'BC548BRL1G', u'200'),\n",
       " (u'BC546-D', u'BC548BZL1G', u'180'),\n",
       " (u'BC546-D', u'BC548BZL1G', u'200'),\n",
       " (u'BC546-D', u'BC548C', u'180'),\n",
       " (u'BC546-D', u'BC548C', u'200'),\n",
       " (u'BC546-D', u'BC548CG', u'180'),\n",
       " (u'BC546-D', u'BC548CG', u'200'),\n",
       " (u'BC546-D', u'BC548CZL1G', u'180'),\n",
       " (u'BC546-D', u'BC548CZL1G', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC546', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC546A', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC546B', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC546C', u'150'),\n",
       " (u'BC546_DIOTEC', u'BC546C', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC547', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC547A', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC547B', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC547C', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC548', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC548A', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC548B', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC548C', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC549', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC549A', u'150'),\n",
       " (u'BC546_DIOTEC', u'BC549A', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC549B', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC549C', u'200'),\n",
       " (u'BC546_DIOTEC', u'BC557', u'150'),\n",
       " (u'BC546_DIOTEC', u'BC557', u'200'),\n",
       " (u'BC550', u'BC546', u'200'),\n",
       " (u'BC550', u'BC546A', u'200'),\n",
       " (u'BC550', u'BC546B', u'200'),\n",
       " (u'BC550', u'BC546C', u'200'),\n",
       " (u'BC550', u'BC547', u'200'),\n",
       " (u'BC550', u'BC547A', u'200'),\n",
       " (u'BC550', u'BC547B', u'200'),\n",
       " (u'BC550', u'BC547C', u'200'),\n",
       " (u'BC550', u'BC548', u'200'),\n",
       " (u'BC550', u'BC548A', u'200'),\n",
       " (u'BC550', u'BC548B', u'200'),\n",
       " (u'BC550', u'BC548C', u'200'),\n",
       " (u'BC550', u'BC549', u'200'),\n",
       " (u'BC550', u'BC549A', u'200'),\n",
       " (u'BC550', u'BC549B', u'200'),\n",
       " (u'BC550', u'BC549C', u'200'),\n",
       " (u'BC550', u'BC550', u'200'),\n",
       " (u'BC550', u'BC550A', u'200'),\n",
       " (u'BC550', u'BC550B', u'200'),\n",
       " (u'BC550', u'BC550C', u'200'),\n",
       " (u'BC550', u'BC556', u'150'),\n",
       " (u'BC550', u'BC556', u'200'),\n",
       " (u'BC550', u'BC560', u'150'),\n",
       " (u'BC550', u'BC560', u'200'),\n",
       " (u'DTC114W', u'DTC114W', u'180'),\n",
       " (u'DTC114W', u'DTC114W', u'200'),\n",
       " (u'DTC114W', u'DTC114WE', u'180'),\n",
       " (u'DTC114W', u'DTC114WE', u'200'),\n",
       " (u'DTC114W', u'DTC114WKA', u'180'),\n",
       " (u'DTC114W', u'DTC114WKA', u'200'),\n",
       " (u'DTC114W', u'DTC114WUA', u'180'),\n",
       " (u'DTC114W', u'DTC114WUA', u'200'),\n",
       " (u'RECTS01214-1', u'DTC114ECA-1', u'150'),\n",
       " (u'RECTS01214-1', u'DTC114ECA-1', u'200'),\n",
       " (u'RECTS01214-1', u'DTC114EUA', u'200'),\n",
       " (u'RECTS01242-1', u'BC857BLT1', u'150'),\n",
       " (u'RECTS01325-1', u'DTC114YCA-1', u'150'),\n",
       " (u'RECTS01325-1', u'DTC114YCA-1', u'200'),\n",
       " (u'RECTS01325-1', u'DTC114YUA', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904-E', u'150'),\n",
       " (u'UTCLS01324-1', u'MMBT3904-E', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904G-AE3-R', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904G-AL3-R', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904L-AE3-R', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3904L-AL3-R', u'200'),\n",
       " (u'UTCLS01324-1', u'MMBT3906', u'150'),\n",
       " (u'UTCLS01324-1', u'MMBT3906', u'200'),\n",
       " (u'VSMIS00373-1', u'BC327', u'150'),\n",
       " (u'VSMIS00373-1', u'BC327', u'160'),\n",
       " (u'VSMIS00373-1', u'BC327', u'170'),\n",
       " (u'VSMIS00373-1', u'BC327', u'200'),\n",
       " (u'VSMIS00373-1', u'BC328', u'150'),\n",
       " (u'VSMIS00373-1', u'BC328', u'160'),\n",
       " (u'VSMIS00373-1', u'BC328', u'170'),\n",
       " (u'VSMIS00373-1', u'BC328', u'200'),\n",
       " (u'VSMIS00373-1', u'BC337', u'160'),\n",
       " (u'VSMIS00373-1', u'BC337', u'170'),\n",
       " (u'VSMIS00373-1', u'BC337', u'200'),\n",
       " (u'VSMIS00373-1', u'BC337-16', u'160'),\n",
       " (u'VSMIS00373-1', u'BC337-16', u'170'),\n",
       " (u'VSMIS00373-1', u'BC337-16', u'200'),\n",
       " (u'VSMIS00373-1', u'BC337-25', u'160'),\n",
       " (u'VSMIS00373-1', u'BC337-25', u'170'),\n",
       " (u'VSMIS00373-1', u'BC337-25', u'200'),\n",
       " (u'VSMIS00373-1', u'BC337-40', u'160'),\n",
       " (u'VSMIS00373-1', u'BC337-40', u'170'),\n",
       " (u'VSMIS00373-1', u'BC337-40', u'200'),\n",
       " (u'VSMIS00373-1', u'BC338', u'160'),\n",
       " (u'VSMIS00373-1', u'BC338', u'170'),\n",
       " (u'VSMIS00373-1', u'BC338', u'200'),\n",
       " (u'VSMIS00373-1', u'BC338-16', u'160'),\n",
       " (u'VSMIS00373-1', u'BC338-16', u'170'),\n",
       " (u'VSMIS00373-1', u'BC338-16', u'200'),\n",
       " (u'VSMIS00373-1', u'BC338-25', u'160'),\n",
       " (u'VSMIS00373-1', u'BC338-25', u'170'),\n",
       " (u'VSMIS00373-1', u'BC338-25', u'200'),\n",
       " (u'VSMIS00373-1', u'BC338-40', u'160'),\n",
       " (u'VSMIS00373-1', u'BC338-40', u'170'),\n",
       " (u'VSMIS00373-1', u'BC338-40', u'200'),\n",
       " (u'WEITS00252-1', u'BC807-1', u'150'),\n",
       " (u'WEITS00252-1', u'BC807-1', u'160'),\n",
       " (u'WEITS00252-1', u'BC807-16', u'160'),\n",
       " (u'WEITS00252-1', u'BC807-17', u'150'),\n",
       " (u'WEITS00252-1', u'BC807-17', u'160'),\n",
       " (u'WEITS00252-1', u'BC807-25', u'160'),\n",
       " (u'WEITS00252-1', u'BC807-40', u'160')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are actually only a few documents that are causing us problems. In particular, we see that `PNJIS01593-1` is giving us many false positives. So, let's inspect one of those candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.fonduer.visualizer import *\n",
    "from hardware_utils import entity_to_candidates\n",
    "vis = Visualizer(pdf_path)\n",
    "\n",
    "# Get a list of candidates that match the FN[10] entity\n",
    "if 'CI' not in os.environ:\n",
    "    test_cands = session.query(Part_Attr).filter(Part_Attr.split == 2).all()\n",
    "    fp_cands = entity_to_candidates(FP[10], test_cands)\n",
    "    # Display a candidate\n",
    "    vis.display_candidates([fp_cands[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the candidates are boxed in blue. We see that the `200` falls within the range of numbers that our matcher for storage temperature allows to match. By inspecting candidates like this, or just by examining the problematic PDFs directly, we can notice some patterns that we can exploit as new labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'CI' not in os.environ:\n",
    "    # Get a list of candidates that match the FN[10] entity\n",
    "    test_cands = session.query(Part_Attr).filter(Part_Attr.split == 2).all()\n",
    "    fp_cands = entity_to_candidates(FP[40], test_cands)\n",
    "\n",
    "    # # Display this candidate\n",
    "    vis.display_candidates([fp_cands[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively Improving Labeling Functions\n",
    "\n",
    "From this error analysis, we may notice two important things. First, our original set of labeling functions had no labeling functions that labeled candidates a negative. This resulted in most skewing the models to accept most candidates, and hurt our precision. Second, we have now noticed that we need to focus on negatively labeling numbers that pass through our storage temperature matchers, but are not related to storage temperature.\n",
    "\n",
    "Below are a set of negative labeling functions that capture some of these patterns. For example, we label candidates an negative if the number is aligned with attributes that are not related to storage temperature, if a candidate represents a typical value, rather than a maximum value, if a temperature value is found outside of a table, and other intuitive patterns we noticed when carefully inspecting our false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_test_condition_aligned(c):\n",
    "    return -1 if overlap(\n",
    "        ['test', 'condition'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_collector_aligned(c):\n",
    "    return -1 if overlap(\n",
    "        ['collector', 'collector-current', 'collector-base', 'collector-emitter'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_current_aligned(c):\n",
    "    ngrams = get_aligned_ngrams(c.attr)\n",
    "    return -1 if overlap(\n",
    "        ['current', 'dc', 'ic'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_voltage_row_temp(c):\n",
    "    ngrams = get_aligned_ngrams(c.attr)\n",
    "    return -1 if overlap(\n",
    "        ['voltage', 'cbo', 'ceo', 'ebo', 'v'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_voltage_row_part(c):\n",
    "    ngrams = get_aligned_ngrams(c.part)\n",
    "    return -1 if overlap(\n",
    "        ['voltage', 'cbo', 'ceo', 'ebo', 'v'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_typ_row(c):\n",
    "    return -1 if overlap(\n",
    "        ['typ', 'typ.'],\n",
    "        list(get_row_ngrams(c.attr))) else 0\n",
    "\n",
    "def LF_complement_left_row(c):\n",
    "    return -1 if (\n",
    "        overlap(['complement','complementary'], \n",
    "        chain.from_iterable([get_row_ngrams(c.part), get_left_ngrams(c.part, window=10)]))) else 0\n",
    "\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.attr, attrib=\"ner_tags\")).count('number')\n",
    "    return -1 if num_numbers >= 3 else 0\n",
    "\n",
    "def LF_temp_on_high_page_num(c):\n",
    "    return -1 if c.attr.get_attrib_tokens('page')[0] > 2 else 0\n",
    "\n",
    "def LF_temp_outside_table(c):\n",
    "    return -1 if not c.attr.is_tabular() is None else 0\n",
    "\n",
    "def LF_not_temp_relevant(c):\n",
    "    return -1 if not overlap(\n",
    "        ['storage','temperature','tstg','stg', 'ts'],\n",
    "        list(get_aligned_ngrams(c.attr))) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then, we can add these to our list of labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg_temp_lfs_2 = [LF_test_condition_aligned,\n",
    "                 LF_collector_aligned,\n",
    "                 LF_current_aligned,\n",
    "                 LF_voltage_row_temp,\n",
    "                 LF_voltage_row_part,\n",
    "                 LF_typ_row,\n",
    "                 LF_complement_left_row,\n",
    "                 LF_too_many_numbers_row,\n",
    "                 LF_temp_on_high_page_num,\n",
    "                 LF_temp_outside_table,\n",
    "                 LF_not_temp_relevant\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And rerun labeling. Importantly, this time we set `clear=False`, `update_keys=True` and `update_values=True` to reflect the fact that we are adding new labeling functions, but do not want to throw away the computations already performed in the previous iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n",
      "Copying part_attr_label_updates to postgres\n",
      "COPY 32095\n",
      "\n",
      "CPU times: user 2.07 s, sys: 256 ms, total: 2.32 s\n",
      "Wall time: 8min 6s\n",
      "(32095, 17)\n"
     ]
    }
   ],
   "source": [
    "labeler = BatchLabelAnnotator(Part_Attr, lfs = stg_temp_lfs_2)\n",
    "%time L_train = labeler.apply(split=0, clear=False, update_keys=True, update_values=True, parallelism=PARALLEL)\n",
    "print L_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can rerun probablistic relation classification, the same way we did above. We start with the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 48s, sys: 68 ms, total: 10min 48s\n",
      "Wall time: 10min 48s\n"
     ]
    }
   ],
   "source": [
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=500, decay=0.9, step_size=0.001/L_train.shape[0], reg_param=0)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we rerun the discriminitive model and see that our score has improved significantly to about 80 F1 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLR] lr=0.001 l1=0.0 l2=0.0\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=32095  #epochs=200  batch size=100\n",
      "[SparseLR] Epoch 0 (6.05s)\tAvg. loss=0.101316\tNNZ=24710\n",
      "[SparseLR] Epoch 5 (36.82s)\tAvg. loss=0.039647\tNNZ=24710\n",
      "[SparseLR] Epoch 10 (67.99s)\tAvg. loss=0.039237\tNNZ=24710\n",
      "[SparseLR] Epoch 15 (99.23s)\tAvg. loss=0.039116\tNNZ=24710\n",
      "[SparseLR] Epoch 20 (130.82s)\tAvg. loss=0.039126\tNNZ=24710\n",
      "[SparseLR] Epoch 25 (162.53s)\tAvg. loss=0.039103\tNNZ=24710\n",
      "[SparseLR] Epoch 30 (194.31s)\tAvg. loss=0.039104\tNNZ=24710\n",
      "[SparseLR] Epoch 35 (226.41s)\tAvg. loss=0.039059\tNNZ=24710\n",
      "[SparseLR] Epoch 40 (258.73s)\tAvg. loss=0.039068\tNNZ=24710\n",
      "[SparseLR] Epoch 45 (291.26s)\tAvg. loss=0.039105\tNNZ=24710\n",
      "[SparseLR] Epoch 50 (323.37s)\tAvg. loss=0.039107\tNNZ=24710\n",
      "[SparseLR] Epoch 55 (355.80s)\tAvg. loss=0.039158\tNNZ=24710\n",
      "[SparseLR] Epoch 60 (387.98s)\tAvg. loss=0.039072\tNNZ=24710\n",
      "[SparseLR] Epoch 65 (419.73s)\tAvg. loss=0.039073\tNNZ=24710\n",
      "[SparseLR] Epoch 70 (451.72s)\tAvg. loss=0.039122\tNNZ=24710\n",
      "[SparseLR] Epoch 75 (483.74s)\tAvg. loss=0.039067\tNNZ=24710\n",
      "[SparseLR] Epoch 80 (515.75s)\tAvg. loss=0.039082\tNNZ=24710\n",
      "[SparseLR] Epoch 85 (547.93s)\tAvg. loss=0.039064\tNNZ=24710\n",
      "[SparseLR] Epoch 90 (580.04s)\tAvg. loss=0.039137\tNNZ=24710\n",
      "[SparseLR] Epoch 95 (612.34s)\tAvg. loss=0.039127\tNNZ=24710\n",
      "[SparseLR] Epoch 100 (644.32s)\tAvg. loss=0.039066\tNNZ=24710\n",
      "[SparseLR] Epoch 105 (678.34s)\tAvg. loss=0.039102\tNNZ=24710\n",
      "[SparseLR] Epoch 110 (714.74s)\tAvg. loss=0.039108\tNNZ=24710\n",
      "[SparseLR] Epoch 115 (752.62s)\tAvg. loss=0.039094\tNNZ=24710\n",
      "[SparseLR] Epoch 120 (788.98s)\tAvg. loss=0.039112\tNNZ=24710\n",
      "[SparseLR] Epoch 125 (824.57s)\tAvg. loss=0.039105\tNNZ=24710\n",
      "[SparseLR] Epoch 130 (858.09s)\tAvg. loss=0.039093\tNNZ=24710\n",
      "[SparseLR] Epoch 135 (892.78s)\tAvg. loss=0.039067\tNNZ=24710\n",
      "[SparseLR] Epoch 140 (930.18s)\tAvg. loss=0.039115\tNNZ=24710\n",
      "[SparseLR] Epoch 145 (964.28s)\tAvg. loss=0.039098\tNNZ=24710\n",
      "[SparseLR] Epoch 150 (997.75s)\tAvg. loss=0.039089\tNNZ=24710\n",
      "[SparseLR] Epoch 155 (1033.33s)\tAvg. loss=0.039088\tNNZ=24710\n",
      "[SparseLR] Epoch 160 (1067.70s)\tAvg. loss=0.039096\tNNZ=24710\n",
      "[SparseLR] Epoch 165 (1103.14s)\tAvg. loss=0.039094\tNNZ=24710\n",
      "[SparseLR] Epoch 170 (1135.94s)\tAvg. loss=0.039140\tNNZ=24710\n",
      "[SparseLR] Epoch 175 (1167.68s)\tAvg. loss=0.039083\tNNZ=24710\n",
      "[SparseLR] Epoch 180 (1200.32s)\tAvg. loss=0.039064\tNNZ=24710\n",
      "[SparseLR] Epoch 185 (1233.91s)\tAvg. loss=0.039094\tNNZ=24710\n",
      "[SparseLR] Epoch 190 (1267.66s)\tAvg. loss=0.039100\tNNZ=24710\n",
      "[SparseLR] Epoch 195 (1303.28s)\tAvg. loss=0.039088\tNNZ=24710\n",
      "[SparseLR] Epoch 199 (1328.26s)\tAvg. loss=0.039143\tNNZ=24710\n",
      "[SparseLR] Training done (1328.26s)\n",
      "CPU times: user 25min 56s, sys: 16.7 s, total: 26min 13s\n",
      "Wall time: 22min 8s\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.263\n",
      "Neg. class accuracy: 0.99\n",
      "Precision            0.913\n",
      "Recall               0.263\n",
      "F1                   0.408\n",
      "----------------------------------------\n",
      "TP: 136 | FP: 13 | TN: 1344 | FN: 382\n",
      "========================================\n",
      "\n",
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.855\n",
      "Corpus Recall    0.783\n",
      "Corpus F1        0.818\n",
      "----------------------------------------\n",
      "TP: 65 | FP: 11 | FN: 18\n",
      "========================================\n",
      "\n",
      "CPU times: user 144 ms, sys: 12 ms, total: 156 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=200, lr=0.001)\n",
    "tp, fp, tn, fn = disc_model.score(session, F_test, L_gold_test)\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, test_docs, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these new LFs, we've significantly improved precision and lowered our number of false positives for an F1 score of about 80."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
