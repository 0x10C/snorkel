{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARDWARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "To change attributes:\n",
    "1) Change ATTRIBUTE and you're good to go\n",
    "\"\"\"\n",
    "ATTRIBUTE = 'polarity'\n",
    "COUNTER = '_new'\n",
    "PARALLEL = 1\n",
    "PARALLEL_F = 1\n",
    "PARALLEL_EXTRACTION = 1\n",
    "TRAIN_SIZE = 5\n",
    "DEV_SIZE = 5\n",
    "TEST_SIZE = 5\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "os.environ['SNORKELDB'] = 'postgres://localhost:5432'# + os.environ['SNORKELDBNAME']\n",
    "        \n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/')\n",
    "snorkel_postgres = os.environ['SNORKELDB'].startswith('postgres')\n",
    "print snorkel_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "SNORKELDB = postgres://localhost:5432\n",
      "SNORKELDBNAME = polarity_new2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "#     os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "    print os.system(\"dropdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print os.system(\"createdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print \"SNORKELDB = %s\" % os.environ['SNORKELDB']\n",
    "    print \"SNORKELDBNAME = %s\" % os.environ['SNORKELDBNAME']\n",
    "else:\n",
    "    try:\n",
    "        os.remove('snorkel.db')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "from fonduer import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_parser import HTMLParser, AsyncOmniParser\n",
    "    from fonduer.models import Document, Sentence\n",
    "    print \"Starting async parse...\"\n",
    "    \n",
    "    doc_preprocessor = HTMLParser()\n",
    "    corpus_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True)\n",
    "    # PARSE TRAIN\n",
    "    corpus_name = 'Hardware Train'\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/train_digikey/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/train_digikey/pdf/'\n",
    "\n",
    "    %time corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, \\\n",
    "                                max_docs=TRAIN_SIZE, parallel=PARALLEL)\n",
    "    session.commit()\n",
    "    print \"Documents:\", session.query(Document).count()\n",
    "    print \"Sentences:\", session.query(Sentence).count()\n",
    "# #     print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "#     session.commit()\n",
    "#     # PARSE DEV\n",
    "#     corpus_name = 'Hardware Dev'\n",
    "#     docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/html/'\n",
    "#     pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/pdf/'\n",
    "    \n",
    "#     %time corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, \\\n",
    "#                                 max_docs=DEV_SIZE, parallel=PARALLEL)\n",
    "# #     print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "#     session.commit()\n",
    "#     if TEST_SIZE:\n",
    "#         # PARSE TEST\n",
    "#         corpus_name = 'Hardware Test'\n",
    "#         docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/test/html/'\n",
    "#         pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/test/pdf/'\n",
    "        \n",
    "#         %time corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, \\\n",
    "#                                     max_docs=TEST_SIZE, parallel=PARALLEL)\n",
    "# #         print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "#         session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async parse...\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "Documents: 10\n",
      "Phrases: 1348\n"
     ]
    }
   ],
   "source": [
    "# from fonduer.async_parser import HTMLParser, AsyncOmniParser\n",
    "from fonduer.parser import HTMLPreprocessor, OmniParser\n",
    "from fonduer.models import Document, Phrase\n",
    "print \"Starting async parse...\"\n",
    "\n",
    "\n",
    "# docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/train_digikey/html/'\n",
    "# pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/train_digikey/pdf/'\n",
    "docs_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/html/'\n",
    "pdf_path = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/pdf/'\n",
    "\n",
    "doc_preprocessor = HTMLPreprocessor(docs_path, max_docs=10)\n",
    "\n",
    "# corpus_parser = OmniParser(blacklist=['style'], flatten=['span','br'], tabular=True, lingual=True, visual=True, pdf_path=pdf_path)\n",
    "corpus_parser = OmniParser(structural=True, lingual=True, visual=True, blacklist=['style'], flatten=['span','br'], pdf_path=pdf_path)\n",
    "corpus_parser.apply(doc_preprocessor, parallelism=4)\n",
    "\n",
    "# corpus_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "#                                  tabular=True, lingual=True,\n",
    "#                                  visual=True)\n",
    "\n",
    "# %time corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, \\\n",
    "#                             max_docs=TRAIN_SIZE, parallel=PARALLEL)\n",
    "# session.commit()\n",
    "print \"Documents:\", session.query(Document).count()\n",
    "print \"Phrases:\", session.query(Phrase).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 144 6\n",
      "1 124 2\n",
      "2 123 2\n",
      "3 153 4\n",
      "4 109 2\n",
      "5 150 4\n",
      "6 193 1\n",
      "7 95 3\n",
      "8 127 2\n",
      "9 130 3\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(docs):\n",
    "    print i, len(d.phrases), len(d.tables)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0 188 5\n",
    "1 198 4\n",
    "2 159 4\n",
    "3 213 4\n",
    "4 190 5\n",
    "5 193 5\n",
    "6 198 4\n",
    "7 195 4\n",
    "8 178 4\n",
    "9 202 4\n",
    "10 220 4\n",
    "11 185 5\n",
    "12 241 4\n",
    "13 209 4\n",
    "14 294 6\n",
    "15 295 6\n",
    "16 295 6\n",
    "17 297 6\n",
    "18 228 5\n",
    "19 302 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC182 [54] [71]\n",
      "Zetex - BC81840 Silicon planar medium power transistor datasheet [13, 65, 49, 13, 13, 13, 13, 13, 23] [22, 73, 64, 22, 22, 22, 22, 22, 32]\n",
      "DISES00645-1 [209] [217]\n",
      "BC856/857/858/859/860 PNP Epitaxial Silicon Transistor [71, 179, 124, 265, 265, 265, 265] [223, 188, 140, 279, 279, 279, 279]\n",
      "BC546/7/8 [32] [49]\n",
      "DTC114YE(SOT-523). [125, 172, 300, 183, 252] [143, 182, 314, 193, 261]\n",
      "MCCCS09741-1 [113] [161]\n",
      "2N3904 MMBT3904 PZT3904 - NPN General-Purpose Amplifier [61, 61, 61, 61, 61, 61, 61] [427, 427, 427, 427, 427, 427, 427]\n",
      "DTC114ECA-1. [121, 276] [140, 286]\n",
      "Microsoft Word - MMBT3904-E. [96, 61, 61, 96, 61] [119, 86, 86, 119, 86]\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(docs):\n",
    "    print d.phrases[0].text, d.phrases[0].top, d.phrases[0].bottom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2N3715 [522] [529]\n",
    "NPN High Power Silicon Transistor 2N5152 & 2N5154 Series 4-15-14_MMIC-Microstrip Pin Diodes.qxd [93, 93, 93, 93, 93, 116, 116, 116, 144, 93, 166, 93] [113, 113, 113, 113, 113, 129, 129, 129, 157, 113, 175, 113]\n",
    "NPN Power Silicon Transistor 2N5339 Series [51, 51, 51, 51, 73, 121] [70, 70, 70, 70, 86, 133]\n",
    "NPN High Power Silicon Transistor 2N6283 & 2N6284 Series [63, 63, 63, 86, 86, 114, 114, 114, 86] [83, 83, 83, 106, 106, 127, 127, 127, 106]\n",
    "metelics-sales@aeroflex.com [661] [676]\n",
    "VEBO [289] [300]\n",
    "Maximum Ratings [230, 230] [243, 243]\n",
    "Vdc [258] [266]\n",
    "Lawrence, MA 01840 [531, 531, 531, 531] [539, 539, 539, 539]\n",
    "Features [144] [157]\n",
    "Vdc [205] [213]\n",
    "PNP High Power Silicon Transistor 2N5679 & 2N5680 Series [72, 152, 72, 72, 72, 93, 93, 93, 164] [90, 161, 90, 90, 90, 106, 106, 106, 173]\n",
    "Features [98] [111]\n",
    "NPN High Power Silicon Transistor 2N6676 & 2N6678 Series [55, 55, 55, 55, 55, 78, 78, 78, 98] [75, 75, 75, 75, 75, 91, 91, 91, 111]\n",
    "0 [687] [694]\n",
    "BBD240.fm [172] [186]\n",
    "TIS631AA [490] [496]\n",
    "BBD242.fm [172] [186]\n",
    "70 [519] [526]\n",
    "BBD244.fm [172] [186]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0 188 5\n",
    "1 198 4\n",
    "2 159 4\n",
    "3 213 4\n",
    "4 190 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1348L"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fonduer.models import Document, Phrase\n",
    "\n",
    "\n",
    "session.query(Phrase).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import candidate_subclass\n",
    "\n",
    "Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using combined matcher.\n"
     ]
    }
   ],
   "source": [
    "from hardware_matchers import get_matcher\n",
    "\n",
    "dict_path = os.environ['SNORKELHOME'] +\\\n",
    "    '/tutorials/fonduer/tables/data/hardware/gold_raw/digikey_part_dictionary.csv'\n",
    "part_matcher = get_matcher('part', dict_path)\n",
    "attr_matcher = get_matcher(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_spaces import get_space\n",
    "    \n",
    "part_ngrams = get_space('part')\n",
    "attr_ngrams = get_space(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Candidate Throttler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function polarity_throttler at 0x7fbf8ef8c668>\n"
     ]
    }
   ],
   "source": [
    "from hardware_throttlers import get_throttler\n",
    "\n",
    "throttler = get_throttler(ATTRIBUTE)\n",
    "# throttler = None\n",
    "print throttler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "CPU times: user 1.46 s, sys: 12 ms, total: 1.47 s\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.candidates import CandidateExtractor\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from fonduer.async_candidates import parallel_extract\n",
    "\n",
    "candidate_extractor = CandidateExtractor(Part_Attr, \n",
    "                        [part_ngrams, attr_ngrams], \n",
    "                        [part_matcher, attr_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "%time candidate_extractor.apply(docs, split=0)\n",
    "\n",
    "# corpus_names = ['Hardware Train', 'Hardware Dev']\n",
    "# if TEST_SIZE:\n",
    "#     corpus_names.append('Hardware Test')\n",
    "# for corpus_name in corpus_names:\n",
    "#     corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "#     print \"Extracting Candidates from %s\" % corpus\n",
    "#     %time candidates = parallel_extract(session, candidate_extractor, corpus, \\\n",
    "#                                         corpus_name + ' Candidates', \\\n",
    "#                                         parallel=PARALLEL_EXTRACTION)\n",
    "#     session.add(candidates)\n",
    "#     print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 407\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(Part_Attr).filter(Part_Attr.split == 0).all()\n",
    "print \"Number of candidates:\", len(train_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_Attr(Span(\"BC182\", sentence=948, chars=[0,4], words=[0,0]), Span(\"NPN\", sentence=951, chars=[0,2], words=[0,0]))\n",
      "BC182, BC182B\n",
      "NPN Silicon\n"
     ]
    }
   ],
   "source": [
    "print train_cands[0]\n",
    "print train_cands[0][0].sentence.text\n",
    "print train_cands[0][1].sentence.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.models import Corpus\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "\n",
    "# # parts_by_doc = get_gold_parts_by_doc()\n",
    "# parts_by_doc = get_manual_parts_by_doc(corpus.documents.all())\n",
    "# # parts_by_doc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cPickle as pickle\n",
    "# pickle_file = os.environ['SNORKELHOME'] + '/tutorials/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "\n",
    "# with open(pickle_file, 'w') as f:\n",
    "#     pickle.dump(parts_by_doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "with open(pickle_file, 'r') as f:\n",
    "    parts_by_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC182-D\n",
      "DIODS13249-1\n",
      "DISES00645-1\n",
      "FAIRS19194-1\n",
      "KECCS05435-1\n",
      "MCCCS08818-1\n",
      "MCCCS09741-1\n",
      "MMBT3904\n",
      "RECTS01214-1\n",
      "UTCLS01324-1\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(docs):\n",
    "    print d.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.753\n",
      "Corpus Recall    0.973\n",
      "Corpus F1        0.849\n",
      "----------------------------------------\n",
      "TP: 73 | FP: 24 | FN: 2\n",
      "========================================\n",
      "\n",
      "CPU times: user 384 ms, sys: 4 ms, total: 388 ms\n",
      "Wall time: 413 ms\n"
     ]
    }
   ],
   "source": [
    "# from fonduer.models import Corpus, CandidateSet\n",
    "from hardware_utils import entity_level_f1\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "# candidates = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "candidates = train_cands\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + \\\n",
    "    '/tutorials/fonduer/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "%time (ctp, cfp, cfn) = entity_level_f1(candidates, gold_file, ATTRIBUTE, docs, parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from fonduer.models import CandidateSet\n",
    "# from hardware_utils import load_hardware_labels\n",
    "\n",
    "# data_sets = ['Dev']\n",
    "# gold_file = {}\n",
    "# gold_file['Dev'] = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "# if TEST_SIZE:\n",
    "#     data_sets.append('Test')\n",
    "#     gold_file['Test'] = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "# for data_set in data_sets:\n",
    "#     candidate_set_name = 'Hardware %s Candidates' % data_set\n",
    "#     candidates = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name).one()\n",
    "#     label_set_name = 'Hardware %s Candidates -- Gold' % data_set\n",
    "#     annotation_key_name = 'Hardware %s Labels -- Gold' % data_set\n",
    "#     %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "#                            label_set_name, \\\n",
    "#                            annotation_key_name, \\\n",
    "#                            candidates, \\\n",
    "#                            gold_file[data_set], \\\n",
    "#                            ATTRIBUTE)\n",
    "#     candidates_gold = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "#     print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "#         len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CORE_e1_SPAN_TYPE_[EXPLICIT]', 1)\n",
      "('CORE_e1_STARTS_WITH_CAPITAL', 1)\n",
      "('CORE_e1_LENGTH_1', 1)\n",
      "('CORE_e2_SPAN_TYPE_[EXPLICIT]', 1)\n",
      "('CORE_e2_STARTS_WITH_CAPITAL', 1)\n",
      "('CORE_e2_LENGTH_1', 1)\n",
      "(u'DDL_e1_WORD_SEQ_[BC182]', 1)\n",
      "(u'DDL_e1_LEMMA_SEQ_[bc182]', 1)\n",
      "(u'DDL_e1_POS_SEQ_[NN]', 1)\n",
      "(u'DDL_e1_DEP_SEQ_[ROOT]', 1)\n",
      "(u'DDL_e1_W_LEFT_1_[bc182b]', 1)\n",
      "(u'DDL_e1_W_LEFT_POS_1_[NN]', 1)\n",
      "(u'DDL_e1_W_LEFT_2_[, bc182b]', 1)\n",
      "(u'DDL_e1_W_LEFT_POS_2_[, NN]', 1)\n",
      "(u'DDL_e1_W_LEFT_3_[bc182 , bc182b]', 1)\n",
      "(u'DDL_e1_W_LEFT_POS_3_[NN , NN]', 1)\n",
      "(u'DDL_e1_W_RIGHT_1_[,]', 1)\n",
      "(u'DDL_e1_W_RIGHT_POS_1_[,]', 1)\n",
      "(u'DDL_e1_W_RIGHT_2_[, bc182b]', 1)\n",
      "(u'DDL_e1_W_RIGHT_POS_2_[, NN]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_1_R_1_[bc182b]_[,]', 1)\n",
      "(u'DDL_e1_W_POS_L_1_R_1_[NN]_[,]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_1_R_2_[bc182b]_[, bc182b]', 1)\n",
      "(u'DDL_e1_W_POS_L_1_R_2_[NN]_[, NN]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_2_R_1_[, bc182b]_[,]', 1)\n",
      "(u'DDL_e1_W_POS_L_2_R_1_[, NN]_[,]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_2_R_2_[, bc182b]_[, bc182b]', 1)\n",
      "(u'DDL_e1_W_POS_L_2_R_2_[, NN]_[, NN]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_3_R_1_[bc182 , bc182b]_[,]', 1)\n",
      "(u'DDL_e1_W_POS_L_3_R_1_[NN , NN]_[,]', 1)\n",
      "(u'DDL_e1_W_LEMMA_L_3_R_2_[bc182 , bc182b]_[, bc182b]', 1)\n",
      "(u'DDL_e1_W_POS_L_3_R_2_[NN , NN]_[, NN]', 1)\n",
      "(u'DDL_e2_WORD_SEQ_[NPN]', 1)\n",
      "(u'DDL_e2_LEMMA_SEQ_[NPN]', 1)\n",
      "(u'DDL_e2_POS_SEQ_[NNP]', 1)\n",
      "(u'DDL_e2_DEP_SEQ_[compound]', 1)\n",
      "(u'DDL_e2_W_LEFT_1_[Silicon]', 1)\n",
      "(u'DDL_e2_W_LEFT_POS_1_[NNP]', 1)\n",
      "(u'DDL_e2_W_LEFT_2_[NPN Silicon]', 1)\n",
      "(u'DDL_e2_W_LEFT_POS_2_[NNP NNP]', 1)\n",
      "(u'DDL_e2_W_RIGHT_1_[Silicon]', 1)\n",
      "(u'DDL_e2_W_RIGHT_POS_1_[NNP]', 1)\n",
      "(u'DDL_e2_W_LEMMA_L_1_R_1_[Silicon]_[Silicon]', 1)\n",
      "(u'DDL_e2_W_POS_L_1_R_1_[NNP]_[NNP]', 1)\n",
      "(u'DDL_e2_W_LEMMA_L_2_R_1_[NPN Silicon]_[Silicon]', 1)\n",
      "(u'DDL_e2_W_POS_L_2_R_1_[NNP NNP]_[NNP]', 1)\n",
      "('STR_e1_TAG_p', 1)\n",
      "(u'STR_e1_HTML_ATTR_class=s1', 1)\n",
      "(u'STR_e1_HTML_ATTR_style=padding-left: 6pt;text-indent: 0pt;line-height: 22pt;text-align: left;', 1)\n",
      "('STR_e1_PARENT_TAG_body', 1)\n",
      "('STR_e1_FIRST_NODE', 1)\n",
      "('STR_e1_NEXT_SIB_TAG_p', 1)\n",
      "('STR_e1_ANCESTOR_CLASS_[None None s1]', 1)\n",
      "('STR_e1_ANCESTOR_TAG_[html body p]', 1)\n",
      "('STR_e1_ANCESTOR_ID_[None None None]', 1)\n",
      "('STR_e2_TAG_h1', 1)\n",
      "(u'STR_e2_HTML_ATTR_style=padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: left;', 1)\n",
      "('STR_e2_PARENT_TAG_body', 1)\n",
      "('STR_e2_PREV_SIB_TAG_p', 1)\n",
      "('STR_e2_NODE_POS_5', 1)\n",
      "('STR_e2_NEXT_SIB_TAG_p', 1)\n",
      "('STR_e2_ANCESTOR_CLASS_[None None None]', 1)\n",
      "('STR_e2_ANCESTOR_TAG_[html body h1]', 1)\n",
      "('STR_e2_ANCESTOR_ID_[None None None]', 1)\n",
      "(u'STR_COMMON_ANCESTOR_[ html body]', 1)\n",
      "('STR_LOWEST_ANCESTOR_DEPTH_[1]', 1)\n",
      "('VIZ_e1_PAGE_[1]', 1)\n",
      "(u'VIZ_e2_ALIGNED_LEFT_transistor', 1)\n",
      "(u'VIZ_e2_ALIGNED_LEFT_amplifier', 1)\n",
      "(u'VIZ_e2_ALIGNED_transistor', 1)\n",
      "(u'VIZ_e2_ALIGNED_amplifier', 1)\n",
      "('VIZ_e2_PAGE_[1]', 1)\n",
      "('VIZ_SAME_PAGE', 1)\n",
      "('VIZ_VERT_ALIGNED', 1)\n",
      "('VIZ_VERT_ALIGNED_LEFT', 1)\n"
     ]
    }
   ],
   "source": [
    "from fonduer.features.features import get_all_feats\n",
    "for f in get_all_feats(candidates[0]):\n",
    "    print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Part_Attr\n"
     ]
    }
   ],
   "source": [
    "session.query(Part_Attr).filter(Part_Attr.split == 0).count()\n",
    "print isinstance(Part_Attr, type)\n",
    "print Part_Attr.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract with optimized postgres batch extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_feature to postgres\n",
      "COPY 407\n",
      "\n",
      "CPU times: user 244 ms, sys: 100 ms, total: 344 ms\n",
      "Wall time: 6.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<407x2325 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 39278 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fonduer.async_annotations import BatchFeatureAnnotator\n",
    "\n",
    "featurizer = BatchFeatureAnnotator(Part_Attr)\n",
    "%time F_train = featurizer.apply(split=0, parallelism=4)\n",
    "F_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract with default Snorkel extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 8.11 s, sys: 632 ms, total: 8.74 s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<407x2325 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 39278 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from fonduer.async_annotations import \n",
    "from fonduer.annotations import FeatureAnnotator\n",
    "from fonduer.features.features import get_all_feats\n",
    "\n",
    "featurizer = FeatureAnnotator(f=get_all_feats)\n",
    "%time F_train = featurizer.apply(split=0, parallelism=4)\n",
    "F_train\n",
    "#print docs[0]\n",
    "#print session.query(Part_Attr).filter(Part_Attr.split == 0).filter(Part_Attr.part.sentence.document_id==531).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Train Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "test  = get_ORM_instance(CandidateSet, session, 'Hardware Test Candidates')\n",
    "\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_annotations import annotate\n",
    "    print \"Starting async featurization...\"\n",
    "    %time F_train = annotate(train, parallel=PARALLEL_F, dynamic_scheduling=False)\n",
    "    %time F_dev   = annotate(dev, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                             keyset = 'Hardware Train Candidates')\n",
    "    if TEST_SIZE:\n",
    "        %time F_test = annotate(test, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                                keyset = 'Hardware Train Candidates')\n",
    "    \n",
    "else:\n",
    "    from fonduer.models import CandidateSet\n",
    "    from fonduer.fast_annotations import FeatureManager\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "\n",
    "    print \"Starting sync featurization...\"\n",
    "    feature_manager = FeatureManager()\n",
    "    %time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "    %time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Train Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Dev Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_lfs import get_lfs\n",
    "\n",
    "LFs = get_lfs(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for lf in LFs:\n",
    "    print lf(candidates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Copying part_attr_label to postgres\n",
      "COPY 407\n",
      "\n",
      "CPU times: user 56 ms, sys: 40 ms, total: 96 ms\n",
      "Wall time: 4.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<407x12 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 997 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fonduer.async_annotations import BatchLabelAnnotator\n",
    "labeler = BatchLabelAnnotator(Part_Attr, lfs = LFs)\n",
    "%time L_train=labeler.apply(split=0, parallelism=4)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.78 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflicts</th>\n",
       "      <th>coverage</th>\n",
       "      <th>j</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_part_complement</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_complement</th>\n",
       "      <td> 0.046683</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td>  1</td>\n",
       "      <td> 0.857494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_transistor_type</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.506142</td>\n",
       "      <td>  2</td>\n",
       "      <td> 0.506143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_many_p_siblings</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  3</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_in_header_tag</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.584767</td>\n",
       "      <td>  4</td>\n",
       "      <td> 0.584767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_right_of_part</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.095823</td>\n",
       "      <td>  5</td>\n",
       "      <td> 0.095823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_replacement_table</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  6</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_both_present</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  7</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_please_to_left</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  8</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_tabular_align</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td>  9</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_vert_align</th>\n",
       "      <td> 0.046683</td>\n",
       "      <td> 0.167076</td>\n",
       "      <td> 10</td>\n",
       "      <td> 0.167076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_horz_align</th>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.095823</td>\n",
       "      <td> 11</td>\n",
       "      <td> 0.095823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                conflicts  coverage   j  overlaps\n",
       "LF_part_complement               0.000000  0.000000   0  0.000000\n",
       "LF_polarity_complement           0.046683  1.000000   1  0.857494\n",
       "LF_polarity_transistor_type      0.000000  0.506142   2  0.506143\n",
       "LF_many_p_siblings               0.000000  0.000000   3  0.000000\n",
       "LF_polarity_in_header_tag        0.000000  0.584767   4  0.584767\n",
       "LF_polarity_right_of_part        0.000000  0.095823   5  0.095823\n",
       "LF_replacement_table             0.000000  0.000000   6  0.000000\n",
       "LF_both_present                  0.000000  0.000000   7  0.000000\n",
       "LF_please_to_left                0.000000  0.000000   8  0.000000\n",
       "LF_polarity_part_tabular_align   0.000000  0.000000   9  0.000000\n",
       "LF_polarity_part_vert_align      0.046683  0.167076  10  0.167076\n",
       "LF_polarity_part_horz_align      0.000000  0.095823  11  0.095823"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train.lf_stats_legacy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "# label_manager = LabelManager()\n",
    "# %time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiao/software/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1318: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.27 s, sys: 16 ms, total: 4.29 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=500, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9JLUOINekhpn0EtS4wx6SWrc/wOBAM0pfcfU+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf63ba0590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52003846,  0.86584998,  0.70185029,  0.5174859 ,  0.73143049,\n",
       "        0.55349053,  0.51577215,  0.52113194,  0.52252852,  0.52219823,\n",
       "        0.54932103,  0.5512824 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import NaiveBayes\n",
    "\n",
    "# gen_model = NaiveBayes()\n",
    "# %time gen_model.train(L_train, n_iter=2000, rate=1e-3, mu=1e-6)\n",
    "# train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LF_replacement_table', 0.080196811906242171),\n",
      " ('LF_many_p_siblings', 1.8647529478426847),\n",
      " ('LF_part_complement', 0.85612435777634732),\n",
      " ('LF_please_to_left', 0.069972126521801833),\n",
      " ('LF_polarity_transistor_type', 1.0018924200883601),\n",
      " ('LF_polarity_part_tabular_align', 0.21478404238605395),\n",
      " ('LF_polarity_part_horz_align', 0.063109534574668988),\n",
      " ('LF_polarity_part_vert_align', 0.084578124571248442),\n",
      " ('LF_polarity_right_of_part', 0.090175155405097504),\n",
      " ('LF_polarity_in_header_tag', 0.088851316939357453),\n",
      " ('LF_polarity_complement', 0.1979277737978711),\n",
      " ('LF_both_present', 0.20585345373413974)]\n",
      "0.0234419762689\n",
      "0.999748248037\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(zip([lf.__name__ for lf in LFs], gen_model.weights.lf_accuracy_log_odds))\n",
    "print min(train_marginals)\n",
    "print max(train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLR] lr=0.001 l1=0.0 l2=0.0\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=407  #epochs=200  batch size=100\n",
      "[SparseLR] Epoch 0 (0.43s)\tAvg. loss=0.639306\tNNZ=2325\n",
      "[SparseLR] Epoch 5 (0.57s)\tAvg. loss=0.219277\tNNZ=2325\n",
      "[SparseLR] Epoch 10 (0.71s)\tAvg. loss=0.126980\tNNZ=2325\n",
      "[SparseLR] Epoch 15 (0.85s)\tAvg. loss=0.091789\tNNZ=2325\n",
      "[SparseLR] Epoch 20 (1.10s)\tAvg. loss=0.073863\tNNZ=2325\n",
      "[SparseLR] Epoch 25 (1.25s)\tAvg. loss=0.063313\tNNZ=2325\n",
      "[SparseLR] Epoch 30 (1.39s)\tAvg. loss=0.056584\tNNZ=2325\n",
      "[SparseLR] Epoch 35 (1.54s)\tAvg. loss=0.052048\tNNZ=2325\n",
      "[SparseLR] Epoch 40 (1.68s)\tAvg. loss=0.048861\tNNZ=2325\n",
      "[SparseLR] Epoch 45 (1.83s)\tAvg. loss=0.046546\tNNZ=2325\n",
      "[SparseLR] Epoch 50 (1.99s)\tAvg. loss=0.044818\tNNZ=2325\n",
      "[SparseLR] Epoch 55 (2.13s)\tAvg. loss=0.043498\tNNZ=2325\n",
      "[SparseLR] Epoch 60 (2.28s)\tAvg. loss=0.042469\tNNZ=2325\n",
      "[SparseLR] Epoch 65 (2.42s)\tAvg. loss=0.041651\tNNZ=2325\n",
      "[SparseLR] Epoch 70 (2.58s)\tAvg. loss=0.040992\tNNZ=2325\n",
      "[SparseLR] Epoch 75 (2.73s)\tAvg. loss=0.040452\tNNZ=2325\n",
      "[SparseLR] Epoch 80 (2.88s)\tAvg. loss=0.040005\tNNZ=2325\n",
      "[SparseLR] Epoch 85 (3.03s)\tAvg. loss=0.039628\tNNZ=2325\n",
      "[SparseLR] Epoch 90 (3.28s)\tAvg. loss=0.039308\tNNZ=2325\n",
      "[SparseLR] Epoch 95 (3.42s)\tAvg. loss=0.039033\tNNZ=2325\n",
      "[SparseLR] Epoch 100 (3.57s)\tAvg. loss=0.038795\tNNZ=2325\n",
      "[SparseLR] Epoch 105 (3.71s)\tAvg. loss=0.038587\tNNZ=2325\n",
      "[SparseLR] Epoch 110 (3.89s)\tAvg. loss=0.038403\tNNZ=2325\n",
      "[SparseLR] Epoch 115 (4.09s)\tAvg. loss=0.038240\tNNZ=2325\n",
      "[SparseLR] Epoch 120 (4.24s)\tAvg. loss=0.038095\tNNZ=2325\n",
      "[SparseLR] Epoch 125 (4.38s)\tAvg. loss=0.037964\tNNZ=2325\n",
      "[SparseLR] Epoch 130 (4.54s)\tAvg. loss=0.037847\tNNZ=2325\n",
      "[SparseLR] Epoch 135 (4.73s)\tAvg. loss=0.037741\tNNZ=2325\n",
      "[SparseLR] Epoch 140 (4.89s)\tAvg. loss=0.037644\tNNZ=2325\n",
      "[SparseLR] Epoch 145 (5.03s)\tAvg. loss=0.037557\tNNZ=2325\n",
      "[SparseLR] Epoch 150 (5.19s)\tAvg. loss=0.037477\tNNZ=2325\n",
      "[SparseLR] Epoch 155 (5.33s)\tAvg. loss=0.037404\tNNZ=2325\n",
      "[SparseLR] Epoch 160 (5.48s)\tAvg. loss=0.037337\tNNZ=2325\n",
      "[SparseLR] Epoch 165 (5.74s)\tAvg. loss=0.037276\tNNZ=2325\n",
      "[SparseLR] Epoch 170 (5.89s)\tAvg. loss=0.037220\tNNZ=2325\n",
      "[SparseLR] Epoch 175 (6.05s)\tAvg. loss=0.037169\tNNZ=2325\n",
      "[SparseLR] Epoch 180 (6.19s)\tAvg. loss=0.037121\tNNZ=2325\n",
      "[SparseLR] Epoch 185 (6.34s)\tAvg. loss=0.037078\tNNZ=2325\n",
      "[SparseLR] Epoch 190 (6.49s)\tAvg. loss=0.037037\tNNZ=2325\n",
      "[SparseLR] Epoch 195 (6.64s)\tAvg. loss=0.037001\tNNZ=2325\n",
      "[SparseLR] Epoch 199 (6.75s)\tAvg. loss=0.036973\tNNZ=2325\n",
      "[SparseLR] Training done (6.75s)\n",
      "CPU times: user 7.99 s, sys: 252 ms, total: 8.24 s\n",
      "Wall time: 6.96 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=200, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import LogReg\n",
    "\n",
    "# disc_model = LogReg()\n",
    "# %time disc_model.train(F_train, train_marginals, n_iter=10000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Dev Labels -- Gold')\n",
    "L_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(session, F_dev, L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import Corpus\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Dev').one()\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=None)\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from fonduer.models import Corpus\n",
    "\n",
    "parts_by_doc = get_gold_parts_by_doc()\n",
    "(TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TEST_SIZE:\n",
    "    from fonduer.annotations import LabelManager\n",
    "    label_manager = LabelManager()\n",
    "    L_test = label_manager.load(session, test, 'Hardware Test Labels -- Gold')\n",
    "    L_test.shape\n",
    "    \n",
    "    tp, fp, tn, fn = disc_model.score(session, F_test, L_test, b=0.91)\n",
    "    \n",
    "    from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "    from fonduer.models import Corpus\n",
    "\n",
    "    corpus = get_ORM_instance(Corpus, session, 'Hardware Test')\n",
    "\n",
    "    # parts_by_doc_test = get_manual_parts_by_doc(corpus.documents.all())\n",
    "    # parts_by_doc_test = None\n",
    "    import cPickle as pickle\n",
    "    pickle_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/sandbox/parts_by_doc_test.pkl'\n",
    "    with open(pickle_file, 'r') as f:\n",
    "        parts_by_doc_test = pickle.load(f)\n",
    "\n",
    "    from hardware_utils import entity_level_f1\n",
    "\n",
    "    gold_file = os.environ['SNORKELHOME'] + '/tutorials/fonduer/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus)\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
