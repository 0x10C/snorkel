{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDiveLite (DDL) Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, re, cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw input -> Sentences\n",
    "\n",
    "As a first stage we load a set of documents as raw strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = list(DocParser('raw/').parseDocs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retinal degeneration 6 (rd6): a new mouse model for human retinitis punctata albescens.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(docs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform these document strings to a _list of lists_ of DDL `Sentence` objects.  We use the `SentenceParser.parse` method to parse the documents, which by default does a variety of NLP pre-processing as well.  Since parsing / preprocessing (above) is probably the slowest part of the process, we'll save the processed `Sentence` objects to disk as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# load previously processed Sentence objects if exists\n",
    "sents_pickle_file = 'saved_sents.pkl'\n",
    "import os.path\n",
    "if os.path.exists(sents_pickle_file):\n",
    "    import cPickle\n",
    "    sents = cPickle.load(open(sents_pickle_file, 'rb'))\n",
    "else:\n",
    "    # or process\n",
    "    parser = SentenceParser()\n",
    "    sents = [list(parser.parse(doc)) for doc in docs[:20]]\n",
    "    cPickle.dump(sents, open(sents_pickle_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(words=['HFE', 'gene', 'mutation', ',', 'C282Y', 'causing', 'hereditary', 'hemochromatosis', 'in', 'Caucasian', 'is', 'extremely', 'rare', 'in', 'Korean', 'population', '.'], lemmas=['hfe', 'gene', 'mutation', ',', 'c282y', 'cause', 'hereditary', 'hemochromatosis', 'in', 'Caucasian', 'be', 'extremely', 'rare', 'in', 'korean', 'population', '.'], poses=['NN', 'NN', 'NN', ',', 'NN', 'VBG', 'JJ', 'NN', 'IN', 'NNP', 'VBZ', 'RB', 'JJ', 'IN', 'JJ', 'NN', '.'], dep_parents=[3, 3, 13, 3, 3, 5, 8, 6, 10, 6, 13, 13, 0, 16, 16, 13, 13], dep_labels=['compound', 'compound', 'nsubj', 'punct', 'appos', 'acl', 'amod', 'dobj', 'case', 'nmod', 'cop', 'advmod', 'ROOT', 'case', 'amod', 'nmod', 'punct']),\n",
       " Sentence(words=['Hereditary', 'hemochromatosis', '-LRB-', 'HFE', '-RRB-', ',', 'which', 'affects', '1', 'in', '400', 'and', 'has', 'an', 'estimated', 'carrier', 'frequency', 'of', '1', 'in', '10', 'individuals', 'in', 'Western', 'population', ',', 'results', 'in', 'multiple', 'organ', 'damage', 'caused', 'by', 'iron', 'deposition', ',', 'and', 'is', 'treatable', 'if', 'detected', 'early', '.'], lemmas=['hereditary', 'hemochromatosis', '-lrb-', 'hfe', '-rrb-', ',', 'which', 'affect', '1', 'in', '400', 'and', 'have', 'a', 'estimate', 'carrier', 'frequency', 'of', '1', 'in', '10', 'individual', 'in', 'western', 'population', ',', 'result', 'in', 'multiple', 'organ', 'damage', 'cause', 'by', 'iron', 'deposition', ',', 'and', 'be', 'treatable', 'if', 'detect', 'early', '.'], poses=['JJ', 'NN', '-LRB-', 'NN', '-RRB-', ',', 'WDT', 'VBZ', 'CD', 'IN', 'CD', 'CC', 'VBZ', 'DT', 'VBN', 'NN', 'NN', 'IN', 'CD', 'IN', 'CD', 'NNS', 'IN', 'JJ', 'NN', ',', 'VBZ', 'IN', 'JJ', 'NN', 'NN', 'VBN', 'IN', 'NN', 'NN', ',', 'CC', 'VBZ', 'JJ', 'IN', 'VBN', 'RB', '.'], dep_parents=[2, 27, 4, 2, 4, 2, 8, 2, 8, 11, 9, 8, 8, 17, 17, 17, 13, 19, 17, 22, 22, 17, 25, 25, 22, 2, 0, 31, 31, 31, 27, 31, 35, 35, 32, 27, 27, 39, 27, 41, 39, 41, 27], dep_labels=['amod', 'nsubj', 'punct', 'appos', 'punct', 'punct', 'nsubj', 'acl:relcl', 'dobj', 'case', 'nmod', 'cc', 'conj', 'det', 'amod', 'compound', 'dobj', 'case', 'nmod', 'case', 'nummod', 'nmod', 'case', 'amod', 'nmod', 'punct', 'ROOT', 'case', 'amod', 'compound', 'nmod', 'acl', 'case', 'compound', 'nmod', 'punct', 'cc', 'cop', 'conj', 'mark', 'advcl', 'advmod', 'punct']),\n",
       " Sentence(words=['C282Y', 'mutation', 'in', 'HFE', 'gene', 'has', 'been', 'known', 'to', 'be', 'responsible', 'for', 'the', 'most', 'hereditary', 'hemochromatosis', 'cases', 'and', '5-10', '%', 'of', 'white', 'subjects', 'are', 'heterozygous', 'for', 'this', 'mutation', '.'], lemmas=['c282y', 'mutation', 'in', 'hfe', 'gene', 'have', 'be', 'know', 'to', 'be', 'responsible', 'for', 'the', 'most', 'hereditary', 'hemochromatosis', 'case', 'and', '5-10', '%', 'of', 'white', 'subject', 'be', 'heterozygous', 'for', 'this', 'mutation', '.'], poses=['NN', 'NN', 'IN', 'NN', 'NN', 'VBZ', 'VBN', 'VBN', 'TO', 'VB', 'JJ', 'IN', 'DT', 'RBS', 'JJ', 'NN', 'NNS', 'CC', 'CD', 'NN', 'IN', 'JJ', 'NNS', 'VBP', 'JJ', 'IN', 'DT', 'NN', '.'], dep_parents=[2, 8, 5, 5, 2, 8, 8, 25, 11, 11, 8, 17, 17, 15, 17, 17, 11, 17, 20, 17, 23, 23, 20, 25, 0, 28, 28, 25, 25], dep_labels=['compound', 'nsubjpass', 'case', 'compound', 'nmod', 'aux', 'auxpass', 'csubj', 'mark', 'cop', 'xcomp', 'case', 'det', 'advmod', 'amod', 'compound', 'nmod', 'cc', 'nummod', 'conj', 'case', 'amod', 'nmod', 'cop', 'ROOT', 'case', 'det', 'nmod', 'punct']),\n",
       " Sentence(words=['However', ',', 'the', 'prevalence', 'of', 'hemochromatosis', 'in', 'the', 'Asian', 'population', 'was', 'reported', 'to', 'be', 'very', 'low', 'and', 'ethnic', 'heterogeneity', 'has', 'been', 'suspected', '.'], lemmas=['however', ',', 'the', 'prevalence', 'of', 'hemochromatosis', 'in', 'the', 'asian', 'population', 'be', 'report', 'to', 'be', 'very', 'low', 'and', 'ethnic', 'heterogeneity', 'have', 'be', 'suspect', '.'], poses=['RB', ',', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', 'VBD', 'VBN', 'TO', 'VB', 'RB', 'JJ', 'CC', 'JJ', 'NN', 'VBZ', 'VBN', 'VBN', '.'], dep_parents=[12, 12, 4, 12, 6, 4, 10, 10, 10, 4, 12, 0, 16, 16, 16, 12, 16, 16, 22, 22, 22, 16, 12], dep_labels=['advmod', 'punct', 'det', 'nsubjpass', 'case', 'nmod', 'case', 'det', 'amod', 'nmod', 'auxpass', 'ROOT', 'mark', 'cop', 'advmod', 'xcomp', 'cc', 'conj', 'nsubjpass', 'aux', 'auxpass', 'dep', 'punct']),\n",
       " Sentence(words=['The', 'aim', 'of', 'our', 'study', 'was', 'to', 'determine', 'the', 'prevalence', 'of', 'heterozygosity', 'and', 'homozygosity', 'for', 'the', 'C282Y', 'HFE', 'gene', 'mutations', 'in', '502', 'unrelated', 'Koreans', '.'], lemmas=['the', 'aim', 'of', 'we', 'study', 'be', 'to', 'determine', 'the', 'prevalence', 'of', 'heterozygosity', 'and', 'homozygosity', 'for', 'the', 'c282y', 'hfe', 'gene', 'mutation', 'in', '502', 'unrelated', 'Koreans', '.'], poses=['DT', 'NN', 'IN', 'PRP$', 'NN', 'VBD', 'TO', 'VB', 'DT', 'NN', 'IN', 'NN', 'CC', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'NNS', 'IN', 'CD', 'JJ', 'NNPS', '.'], dep_parents=[2, 6, 5, 5, 2, 0, 8, 6, 10, 8, 12, 10, 12, 12, 20, 20, 20, 20, 20, 10, 24, 24, 24, 20, 6], dep_labels=['det', 'nsubj', 'case', 'nmod:poss', 'nmod', 'ROOT', 'mark', 'xcomp', 'det', 'dobj', 'case', 'nmod', 'cc', 'conj', 'case', 'det', 'compound', 'compound', 'compound', 'nmod', 'case', 'nummod', 'amod', 'nmod', 'punct']),\n",
       " Sentence(words=['Results', 'revealed', 'that', 'none', 'of', 'them', 'had', 'the', 'mutant', 'gene', ',', 'suggesting', 'a', 'significant', 'ethnic', 'difference', 'when', 'compared', 'with', 'Caucasians', '.'], lemmas=['result', 'reveal', 'that', 'none', 'of', 'they', 'have', 'the', 'mutant', 'gene', ',', 'suggest', 'a', 'significant', 'ethnic', 'difference', 'when', 'compare', 'with', 'Caucasians', '.'], poses=['NNS', 'VBD', 'IN', 'NN', 'IN', 'PRP', 'VBD', 'DT', 'JJ', 'NN', ',', 'VBG', 'DT', 'JJ', 'JJ', 'NN', 'WRB', 'VBN', 'IN', 'NNPS', '.'], dep_parents=[2, 0, 7, 7, 6, 4, 2, 10, 10, 7, 7, 7, 16, 16, 16, 12, 18, 16, 20, 18, 2], dep_labels=['nsubj', 'ROOT', 'mark', 'nsubj', 'case', 'nmod', 'ccomp', 'det', 'amod', 'dobj', 'punct', 'advcl', 'det', 'amod', 'amod', 'dobj', 'advmod', 'acl', 'case', 'nmod', 'punct']),\n",
       " Sentence(words=['Our', 'study', 'excluded', 'underlying', 'possibility', 'of', 'hereditary', 'hemochromatosis', 'in', 'Korean', 'which', 'could', 'mimic', 'the', 'findings', 'of', 'alcoholic', 'liver', 'disease', 'with', 'iron', 'overload', 'or', 'liver', 'cirrhosis', 'with', 'chronic', 'hepatitis', 'C.'], lemmas=['we', 'study', 'exclude', 'underlie', 'possibility', 'of', 'hereditary', 'hemochromatosis', 'in', 'korean', 'which', 'could', 'mimic', 'the', 'finding', 'of', 'alcoholic', 'liver', 'disease', 'with', 'iron', 'overload', 'or', 'liver', 'cirrhosis', 'with', 'chronic', 'hepatitis', 'c.'], poses=['PRP$', 'NN', 'VBN', 'VBG', 'NN', 'IN', 'JJ', 'NN', 'IN', 'JJ', 'WDT', 'MD', 'VB', 'DT', 'NNS', 'IN', 'JJ', 'NN', 'NN', 'IN', 'NN', 'NN', 'CC', 'NN', 'NN', 'IN', 'JJ', 'NN', 'NN'], dep_parents=[2, 3, 0, 5, 3, 8, 8, 5, 10, 8, 13, 13, 8, 15, 13, 19, 19, 19, 15, 22, 22, 19, 22, 25, 22, 28, 28, 22, 28], dep_labels=['nmod:poss', 'nsubj', 'ROOT', 'amod', 'dobj', 'case', 'amod', 'nmod', 'case', 'nmod', 'nsubj', 'aux', 'acl:relcl', 'det', 'dobj', 'case', 'amod', 'compound', 'nmod', 'case', 'compound', 'nmod', 'cc', 'compound', 'conj', 'case', 'amod', 'nmod', 'nummod'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll pick a _random_ sentence to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(words=['Although', 'the', 'BMPR-II', 'tail', 'is', 'not', 'involved', 'in', 'BMP', 'signaling', 'via', 'Smad', 'proteins', ',', 'mutations', 'truncating', 'this', 'domain', 'are', 'present', 'in', 'patients', 'with', 'primary', 'pulmonary', 'hypertension', '-LRB-', 'PPH', '-RRB-', '.'], lemmas=['although', 'the', 'bmpr-ii', 'tail', 'be', 'not', 'involve', 'in', 'bmp', 'signaling', 'via', 'smad', 'protein', ',', 'mutation', 'truncating', 'this', 'domain', 'be', 'present', 'in', 'patient', 'with', 'primary', 'pulmonary', 'hypertension', '-lrb-', 'pph', '-rrb-', '.'], poses=['IN', 'DT', 'NN', 'NN', 'VBZ', 'RB', 'VBN', 'IN', 'NN', 'NN', 'IN', 'NN', 'NNS', ',', 'NNS', 'JJ', 'DT', 'NN', 'VBP', 'JJ', 'IN', 'NNS', 'IN', 'JJ', 'JJ', 'NN', '-LRB-', 'NN', '-RRB-', '.'], dep_parents=[7, 4, 4, 7, 7, 7, 20, 10, 10, 7, 13, 13, 7, 20, 18, 18, 18, 20, 20, 0, 22, 20, 26, 26, 26, 22, 28, 26, 28, 20], dep_labels=['mark', 'det', 'compound', 'nsubjpass', 'auxpass', 'neg', 'advcl', 'case', 'compound', 'nmod', 'case', 'compound', 'nmod', 'punct', 'compound', 'amod', 'det', 'nsubj', 'cop', 'ROOT', 'case', 'nmod', 'case', 'amod', 'amod', 'nmod', 'punct', 'appos', 'punct', 'punct'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sents[15][4]; sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Extraction\n",
    "\n",
    "First, we load a dictionary of gene and phenotype names- these are the entities that we want to extract relations over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 3, genes)\n",
    "\n",
    "# Schema is: HPO_ID | NAME | TYPE (exact, lemma)\n",
    "phenos = [line.rstrip().split('\\t')[1] for line in open('dicts/pheno_terms.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the type of relation we want to look for.  To do this, we'll define a DDL `Relations` operator, which is built from two `Entity`-type operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rels = Relations(\n",
    "    DictionaryMatch('G', genes, ignore_case=False),\n",
    "    DictionaryMatch('P', phenos), \n",
    "    [sent])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render a visualization of the relations / their contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-939589882699480993\"></div>\n",
       "<div id=\"raw-seq-939589882699480993\">\n",
       "<span class=\"word-939589882699480993-0\">Although</span> <span class=\"word-939589882699480993-1\">the</span> <span class=\"word-939589882699480993-2\">BMPR-II</span> <span class=\"word-939589882699480993-3\">tail</span> <span class=\"word-939589882699480993-4\">is</span> <span class=\"word-939589882699480993-5\">not</span> <span class=\"word-939589882699480993-6\">involved</span> <span class=\"word-939589882699480993-7\">in</span> <span class=\"word-939589882699480993-8\">BMP</span> <span class=\"word-939589882699480993-9\">signaling</span> <span class=\"word-939589882699480993-10\">via</span> <span class=\"word-939589882699480993-11\">Smad</span> <span class=\"word-939589882699480993-12\">proteins</span> <span class=\"word-939589882699480993-13\">,</span> <span class=\"word-939589882699480993-14\">mutations</span> <span class=\"word-939589882699480993-15\">truncating</span> <span class=\"word-939589882699480993-16\">this</span> <span class=\"word-939589882699480993-17\">domain</span> <span class=\"word-939589882699480993-18\">are</span> <span class=\"word-939589882699480993-19\">present</span> <span class=\"word-939589882699480993-20\">in</span> <span class=\"word-939589882699480993-21\">patients</span> <span class=\"word-939589882699480993-22\">with</span> <span class=\"word-939589882699480993-23\">primary</span> <span class=\"word-939589882699480993-24\">pulmonary</span> <span class=\"word-939589882699480993-25\">hypertension</span> <span class=\"word-939589882699480993-26\">-LRB-</span> <span class=\"word-939589882699480993-27\">PPH</span> <span class=\"word-939589882699480993-28\">-RRB-</span> <span class=\"word-939589882699480993-29\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"939589882699480993\";\n",
       "var root = {\"attrib\": {\"word\": \"present\", \"dep_label\": \"ROOT\", \"pos\": \"JJ\", \"lemma\": \"present\", \"word_idx\": \"19\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"involved\", \"dep_label\": \"advcl\", \"pos\": \"VBN\", \"lemma\": \"involve\", \"word_idx\": \"6\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"Although\", \"dep_label\": \"mark\", \"pos\": \"IN\", \"lemma\": \"although\", \"word_idx\": \"0\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"tail\", \"dep_label\": \"nsubjpass\", \"pos\": \"NN\", \"lemma\": \"tail\", \"word_idx\": \"3\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"4\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMPR-II\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bmpr-ii\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"4\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"not\", \"dep_label\": \"neg\", \"pos\": \"RB\", \"lemma\": \"not\", \"word_idx\": \"5\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"signaling\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"signaling\", \"word_idx\": \"9\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"7\", \"dep_parent\": \"10\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMP\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bmp\", \"word_idx\": \"8\", \"dep_parent\": \"10\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"proteins\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"protein\", \"word_idx\": \"12\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"via\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"via\", \"word_idx\": \"10\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"Smad\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"smad\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"13\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"domain\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"domain\", \"word_idx\": \"17\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"mutations\", \"dep_label\": \"compound\", \"pos\": \"NNS\", \"lemma\": \"mutation\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"word\": \"truncating\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"truncating\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"word\": \"this\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"this\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"are\", \"dep_label\": \"cop\", \"pos\": \"VBP\", \"lemma\": \"be\", \"word_idx\": \"18\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"patients\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"patient\", \"word_idx\": \"21\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"word\": \"hypertension\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"hypertension\", \"word_idx\": \"25\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"22\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"primary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"primary\", \"word_idx\": \"23\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"pulmonary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"pulmonary\", \"word_idx\": \"24\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"PPH\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"pph\", \"word_idx\": \"27\", \"dep_parent\": \"26\"}, \"children\": [{\"attrib\": {\"word\": \"-LRB-\", \"dep_label\": \"punct\", \"pos\": \"-LRB-\", \"lemma\": \"-lrb-\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}, {\"attrib\": {\"word\": \"-RRB-\", \"dep_label\": \"punct\", \"pos\": \"-RRB-\", \"lemma\": \"-rrb-\", \"word_idx\": \"28\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"29\", \"dep_parent\": \"20\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[2], [24, 25]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rels.relations[1].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Supervision\n",
    "\n",
    "We can create **_rule functions_** using a variety of helper attributes and tools both from `ddlite` and `treedlib`.  **These functions must return values $\\in\\{-1,0,1\\}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rule_1(r):\n",
    "    return 1 if 'mutation' in r.lemmas else 0\n",
    "\n",
    "def rule_2(r):\n",
    "    return 1 if re.search(r'{{G}}.*in patients with.*{{P}}', r.tagged_sent) else 0\n",
    "\n",
    "def rule_3(r):\n",
    "    return 1 if len(r.e2_idxs) > 1 else -1\n",
    "\n",
    "rules = [rule_1, rule_2, rule_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [-1.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.apply_rules(rules)\n",
    "rels.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_rule_priority_vote_accuracy([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Feature extraction is push-button, although custom treedlib feature sets can be passed in as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<102x2 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 191 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.extract_features()\n",
    "rels.feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Here we use a very simple method & implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning epoch = 0\n",
      "Learning epoch = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ddlite.py:381: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.log(float(p) / (1-p))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning epoch = 200\n",
      "Learning epoch = 300\n",
      "Learning epoch = 400\n",
      "Learning epoch = 500\n",
      "Learning epoch = 600\n",
      "Learning epoch = 700\n",
      "Learning epoch = 800\n",
      "Learning epoch = 900\n"
     ]
    }
   ],
   "source": [
    "rels.learn_feats_and_weights(sample=True, verbose=True, holdout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_predicted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_classification_accuracy([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Now, let's look at a sample of extractions using [Mindtagger](http://deepdive.stanford.edu/labeling).  We can use a shorthand to create a Mindtagger task and launch it right from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://shin.local:8125/#/mindtagger/f91d864ceee6ad65\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10be40310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.open_mindtagger(num_sample=20, width='100%', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the tags collected using Mindtagger using the following shorthand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'foo': True, u'is_correct': False, u'sent_id': 0},\n",
       " {u'is_correct': True, u'sent_id': 1}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = rels.get_mindtagger_tags(); tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tags, we can get a precision estimate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precision =  50%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = sum(1 for tag in tags if tag[u'is_correct'])\n",
    "\"precision = %3.f%%\" % (100 * num_correct * 1.0 / len(tags))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
