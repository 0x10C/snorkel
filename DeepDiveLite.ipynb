{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDiveLite (DDL) Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, re, cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw input -> Sentences\n",
    "\n",
    "As a first stage we load a set of documents as raw strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = list(DocParser('raw/').parseDocs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Congenital myasthenic syndrome with tubular aggregates caused by GFPT1 mutations'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(docs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform these document strings to a list of DDL `Sentence` objects.  We use the `SentenceParser.parse` method to parse the documents, which by default does a variety of NLP pre-processing as well.  `SentenceParser` is also wrapped in the DocParser, and if we wanted to parse everything, we could use `DocParser.parseDocSentences`. Since parsing / preprocessing (above) is probably the slowest part of the process, we'll just load and parse one example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence(words=['Although', 'the', 'BMPR-II', 'tail', 'is', 'not', 'involved', 'in', 'BMP', 'signaling', 'via', 'Smad', 'proteins', ',', 'mutations', 'truncating', 'this', 'domain', 'are', 'present', 'in', 'patients', 'with', 'primary', 'pulmonary', 'hypertension', '-LRB-', 'PPH', '-RRB-', '.'], lemmas=['although', 'the', 'bmpr-ii', 'tail', 'be', 'not', 'involve', 'in', 'bmp', 'signaling', 'via', 'smad', 'protein', ',', 'mutation', 'truncating', 'this', 'domain', 'be', 'present', 'in', 'patient', 'with', 'primary', 'pulmonary', 'hypertension', '-lrb-', 'pph', '-rrb-', '.'], poses=['IN', 'DT', 'NN', 'NN', 'VBZ', 'RB', 'VBN', 'IN', 'NN', 'NN', 'IN', 'NN', 'NNS', ',', 'NNS', 'JJ', 'DT', 'NN', 'VBP', 'JJ', 'IN', 'NNS', 'IN', 'JJ', 'JJ', 'NN', '-LRB-', 'NN', '-RRB-', '.'], dep_parents=[7, 4, 4, 7, 7, 7, 20, 10, 10, 7, 13, 13, 7, 20, 18, 18, 18, 20, 20, 0, 22, 20, 26, 26, 26, 22, 28, 26, 28, 20], dep_labels=['mark', 'det', 'compound', 'nsubjpass', 'auxpass', 'neg', 'advcl', 'case', 'compound', 'nmod', 'case', 'compound', 'nmod', 'punct', 'compound', 'amod', 'det', 'nsubj', 'cop', 'ROOT', 'case', 'nmod', 'case', 'amod', 'amod', 'nmod', 'punct', 'appos', 'punct', 'punct'], sent_id=4, doc_id=None)\n"
     ]
    }
   ],
   "source": [
    "sp = SentenceParser()\n",
    "for doc in docs:\n",
    "  if 'Although the BMPR-II tail is not involved' in doc:\n",
    "    sents = list(sp.parse(doc))\n",
    "    break\n",
    "\n",
    "sent = sents[4]\n",
    "print sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll pick a _random_ sentence to work with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Extraction\n",
    "\n",
    "First, we load a dictionary of gene and phenotype names- these are the entities that we want to extract relations over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 3, genes)\n",
    "\n",
    "# Schema is: HPO_ID | NAME | TYPE (exact, lemma)\n",
    "phenos = [line.rstrip().split('\\t')[1] for line in open('dicts/pheno_terms.tsv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the type of relation we want to look for.  To do this, we'll define a DDL `Relations` operator, which is built from two `Entity`-type operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rels = Relations(\n",
    "    DictionaryMatch('G', genes, ignore_case=False),\n",
    "    DictionaryMatch('P', phenos), \n",
    "    [sent])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render a visualization of the relations / their contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-939589882699480993\"></div>\n",
       "<div id=\"raw-seq-939589882699480993\">\n",
       "<span class=\"word-939589882699480993-0\">Although</span> <span class=\"word-939589882699480993-1\">the</span> <span class=\"word-939589882699480993-2\">BMPR-II</span> <span class=\"word-939589882699480993-3\">tail</span> <span class=\"word-939589882699480993-4\">is</span> <span class=\"word-939589882699480993-5\">not</span> <span class=\"word-939589882699480993-6\">involved</span> <span class=\"word-939589882699480993-7\">in</span> <span class=\"word-939589882699480993-8\">BMP</span> <span class=\"word-939589882699480993-9\">signaling</span> <span class=\"word-939589882699480993-10\">via</span> <span class=\"word-939589882699480993-11\">Smad</span> <span class=\"word-939589882699480993-12\">proteins</span> <span class=\"word-939589882699480993-13\">,</span> <span class=\"word-939589882699480993-14\">mutations</span> <span class=\"word-939589882699480993-15\">truncating</span> <span class=\"word-939589882699480993-16\">this</span> <span class=\"word-939589882699480993-17\">domain</span> <span class=\"word-939589882699480993-18\">are</span> <span class=\"word-939589882699480993-19\">present</span> <span class=\"word-939589882699480993-20\">in</span> <span class=\"word-939589882699480993-21\">patients</span> <span class=\"word-939589882699480993-22\">with</span> <span class=\"word-939589882699480993-23\">primary</span> <span class=\"word-939589882699480993-24\">pulmonary</span> <span class=\"word-939589882699480993-25\">hypertension</span> <span class=\"word-939589882699480993-26\">-LRB-</span> <span class=\"word-939589882699480993-27\">PPH</span> <span class=\"word-939589882699480993-28\">-RRB-</span> <span class=\"word-939589882699480993-29\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"939589882699480993\";\n",
       "var root = {\"attrib\": {\"word\": \"present\", \"dep_label\": \"ROOT\", \"pos\": \"JJ\", \"lemma\": \"present\", \"word_idx\": \"19\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"involved\", \"dep_label\": \"advcl\", \"pos\": \"VBN\", \"lemma\": \"involve\", \"word_idx\": \"6\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"Although\", \"dep_label\": \"mark\", \"pos\": \"IN\", \"lemma\": \"although\", \"word_idx\": \"0\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"tail\", \"dep_label\": \"nsubjpass\", \"pos\": \"NN\", \"lemma\": \"tail\", \"word_idx\": \"3\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"1\", \"dep_parent\": \"4\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMPR-II\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bmpr-ii\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"is\", \"dep_label\": \"auxpass\", \"pos\": \"VBZ\", \"lemma\": \"be\", \"word_idx\": \"4\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"not\", \"dep_label\": \"neg\", \"pos\": \"RB\", \"lemma\": \"not\", \"word_idx\": \"5\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"signaling\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"signaling\", \"word_idx\": \"9\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"7\", \"dep_parent\": \"10\"}, \"children\": []}, {\"attrib\": {\"word\": \"BMP\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bmp\", \"word_idx\": \"8\", \"dep_parent\": \"10\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"proteins\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"protein\", \"word_idx\": \"12\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"via\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"via\", \"word_idx\": \"10\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"Smad\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"smad\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"13\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"domain\", \"dep_label\": \"nsubj\", \"pos\": \"NN\", \"lemma\": \"domain\", \"word_idx\": \"17\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"mutations\", \"dep_label\": \"compound\", \"pos\": \"NNS\", \"lemma\": \"mutation\", \"word_idx\": \"14\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"word\": \"truncating\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"truncating\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"word\": \"this\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"this\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}]}, {\"attrib\": {\"word\": \"are\", \"dep_label\": \"cop\", \"pos\": \"VBP\", \"lemma\": \"be\", \"word_idx\": \"18\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"patients\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"patient\", \"word_idx\": \"21\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"20\", \"dep_parent\": \"22\"}, \"children\": []}, {\"attrib\": {\"word\": \"hypertension\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"hypertension\", \"word_idx\": \"25\", \"dep_parent\": \"22\"}, \"children\": [{\"attrib\": {\"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"22\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"primary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"primary\", \"word_idx\": \"23\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"pulmonary\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"pulmonary\", \"word_idx\": \"24\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"PPH\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"pph\", \"word_idx\": \"27\", \"dep_parent\": \"26\"}, \"children\": [{\"attrib\": {\"word\": \"-LRB-\", \"dep_label\": \"punct\", \"pos\": \"-LRB-\", \"lemma\": \"-lrb-\", \"word_idx\": \"26\", \"dep_parent\": \"28\"}, \"children\": []}, {\"attrib\": {\"word\": \"-RRB-\", \"dep_label\": \"punct\", \"pos\": \"-RRB-\", \"lemma\": \"-rrb-\", \"word_idx\": \"28\", \"dep_parent\": \"28\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"29\", \"dep_parent\": \"20\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[2], [24, 25]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rels[1].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Supervision\n",
    "\n",
    "We can create **_rule functions_** using a variety of helper attributes and tools both from `ddlite` and `treedlib`.  **These functions must return values $\\in\\{-1,0,1\\}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rule_1(r):\n",
    "    return 1 if 'mutation' in r.lemmas else 0\n",
    "\n",
    "def rule_2(r):\n",
    "    return 1 if re.search(r'{{G}}.*in patients with.*{{P}}', r.tagged_sent) else 0\n",
    "\n",
    "def rule_3(r):\n",
    "    return 1 if len(r.e2_idxs) > 1 else -1\n",
    "\n",
    "rules = [rule_1, rule_2, rule_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x3 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6 stored elements in LInked List format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.apply_rules(rules, clear=True)\n",
    "rels.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_rule_priority_vote_accuracy([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Feature extraction is push-button, although custom treedlib feature sets can be passed in as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x102 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 191 stored elements in LInked List format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.extract_features()\n",
    "rels.feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Here we use a very simple method & implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning epoch =  0\t100\t200\t300\t400\t\n",
      "Learning epoch =  500\t600\t700\t800\t900\t"
     ]
    }
   ],
   "source": [
    "rels.learn_feats_and_weights(sample=False, verbose=True, holdout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_predicted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.get_classification_accuracy([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Now, let's look at a sample of extractions using [Mindtagger](http://deepdive.stanford.edu/labeling).  We can use a shorthand to create a Mindtagger task and launch it right from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://icme-Standard-PC-i440FX-PIIX-1996:8838/#/mindtagger/7014d9841e89859b\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe59d8bd8d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels.open_mindtagger(num_sample=20, width='100%', height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the tags collected using Mindtagger using the following shorthand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'is_correct': False, u'ext_id': 0}, {u'is_correct': True, u'ext_id': 1}]\n"
     ]
    }
   ],
   "source": [
    "tags = rels.get_mindtagger_tags()\n",
    "print tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tags, we can get a precision estimate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precision =  50%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_exts = [tag for tag in tags if u'is_correct' in tag]\n",
    "num_correct = sum(1 for tag in tagged_exts if tag[u'is_correct'])\n",
    "\"precision = %3.f%%\" % (100 * num_correct * 1.0 / len(tagged_exts))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
