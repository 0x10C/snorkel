{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial, Part I: Candidate Extraction\n",
    "\n",
    "In this example, we'll be writing an application to extract **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  At core, we will be constructing a model to classify _candidate chemical-disease (C-D) relation mentions_ as either true or false.  To do this, we first need a set of such candidates- in this notebook, we'll use `DDLite` utilities to extract these candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Corpus\n",
    "\n",
    "First, we will load and pre-process the corpus, storing it for convenience in a `Corpus` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a document parser\n",
    "\n",
    "We'll start by defining a `DocParser` class to read in Pubmed abstracts from [Pubtator]([Pubtator](http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/index.cgi)), where they are stored along with \"gold\" (i.e. hand-annotated by experts) *chemical* and *disease mention* annotations. We'll use the `XMLDocParser` class, which allows us to use [XPath queries](https://en.wikipedia.org/wiki/XPath) to specify the relevant sections of the XML format.\n",
    "\n",
    "_Note that we are newline-concatenating text from the title and abstract together for simplicity, but if we wanted to, we could easily extend the `DocParser` classes to preserve information about document structure._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ddlite_parser import XMLDocParser\n",
    "xml_parser = XMLDocParser(\n",
    "    path='data/CDR_DevelopmentSet.xml',\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a sentence parser\n",
    "\n",
    "Next, we'll use an NLP preprocessing tool to split the `Document` objects into sentences, tokens, and provide annotations--part-of-speech tags, dependency parse structure, lemmatized word forms, etc.--for these sentences.  Here we use the default `SentenceParser` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ddlite_parser import SentenceParser\n",
    "sent_parser = SentenceParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing & loading the corpus\n",
    "\n",
    "Finally, we'll put this all together using a `Corpus` object, which will execute the parsers and store the results as an iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing documents...\n",
      "Parsing sentences...\n"
     ]
    }
   ],
   "source": [
    "from ddlite_parser import Corpus\n",
    "corpus = Corpus(xml_parser, sent_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(id='6794356', file='CDR_DevelopmentSet.xml', text='Tricuspid valve regurgitation and lithium carbonate toxicity in a newborn infant.\\nA newborn with massive tricuspid regurgitation, atrial flutter, congestive heart failure, and a high serum lithium level is described. This is the first patient to initially manifest tricuspid regurgitation and atrial flutter, and the 11th described patient with cardiac disease among infants exposed to lithium compounds in the first trimester of pregnancy. Sixty-three percent of these infants had tricuspid valve involvement. Lithium carbonate may be a factor in the increasing incidence of congenital heart disease when taken during early pregnancy. It also causes neurologic depression, cyanosis, and cardiac arrhythmia when consumed prior to delivery.', attribs={'root': <Element document at 0x10bb0da50>})\n",
      "\n",
      "\n",
      "Sentence(id='6794356-0', words=[u'Tricuspid', u'valve', u'regurgitation', u'and', u'lithium', u'carbonate', u'toxicity', u'in', u'a', u'newborn', u'infant', u'.'], lemmas=[u'tricuspid', u'valve', u'regurgitation', u'and', u'lithium', u'carbonate', u'toxicity', u'in', u'a', u'newborn', u'infant', u'.'], poses=[u'JJ', u'NN', u'NN', u'CC', u'NN', u'NN', u'NN', u'IN', u'DT', u'JJ', u'NN', u'.'], dep_parents=[3, 3, 0, 3, 7, 7, 3, 11, 11, 11, 3, 3], dep_labels=[u'amod', u'compound', u'ROOT', u'cc', u'compound', u'compound', u'conj', u'case', u'det', u'amod', u'nmod', u'punct'], sent_id=0, doc_id='6794356', text=u'Tricuspid valve regurgitation and lithium carbonate toxicity in a newborn infant.', char_offsets=[0, 10, 16, 30, 34, 42, 52, 61, 64, 66, 74, 80], doc_name='CDR_DevelopmentSet.xml')\n"
     ]
    }
   ],
   "source": [
    "for doc, sentences in corpus:\n",
    "    print doc\n",
    "    print \"\\n\"\n",
    "    print sentences[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a basic candidate extractor\n",
    "\n",
    "Next, we'll write a basic function to extract **candidate disease mentions** from the corpus.  For this first attempt, we'll just write a function that checks for matches against a list (or _\"dictionary\"_) of disease phrases, constructed using some pre-compiled ontologies ([UMLS](https://www.nlm.nih.gov/research/umls/), [ORDO](http://www.orphadata.org/cgi-bin/inc/ordo_orphanet.inc.php), [DOID](http://www.obofoundry.org/ontology/doid.html), [NCBI Diseases](http://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/); see `tutorial/data/diseases.py`).\n",
    "\n",
    "We'll do this using a `CandidateSpace` object--which defines the basic candidates we consider, in this case n-grams up to a certain length--and a `Matcher` object, which filters this candidate space down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "from ddlite_candidates import Ngrams\n",
    "from ddlite_matchers import DictionaryMatch\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = Ngrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "matcher = DictionaryMatch(d=diseases, longest_match_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set `longest_match_only=True`, which means we won't consider subsequences of phrases that match our dictionary.\n",
    "\n",
    "The `Ngrams` operator is applied over our `Sentence` objects and returns `Ngram` objects, and the `Matcher` then filters these, so we apply our operators over the corpus (also storing the results in our `Corpus` object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Ngram(\"blood pressure\", id=1969772-5:640-653, chars=[640,653], words=[2,3]),\n",
       " <Ngram(\"anaesthesia\", id=1969772-5:925-935, chars=[925,935], words=[44,44]),\n",
       " <Ngram(\"hypotension\", id=1969772-4:562-572, chars=[562,572], words=[9,9]),\n",
       " <Ngram(\"Mean arterial pressure\", id=1969772-6:938-959, chars=[938,959], words=[0,2]),\n",
       " <Ngram(\"hypotension\", id=1969772-1:129-139, chars=[129,139], words=[7,7])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.extract_candidates(ngrams, matcher)\n",
    "candidates = list(corpus.iter_candidates())\n",
    "candidates[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our candidate recall on gold annotations\n",
    "\n",
    "Next, we'll test our _candidate recall_--in other words, how many of the true disease mentions we picked up in our candidate set--using the gold annotations in our dataset.\n",
    "\n",
    "The XML documents that we loaded using the `XMLDocParser` also contained annotations (this is why we kept the full xml tree using `keep_xml_tree=True`).  We'll load these annotations and map them to `Ngram` objects over our parsed sentences, that way we can easily compare our extracted candidate set with the gold annotations.  The code is fairly simple (see `tutorial/util.py`); note that we filter to only keep _disease_ annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import collect_pubtator_annotations\n",
    "gold = []\n",
    "for doc, sents in corpus:\n",
    "    gold += [a for a in collect_pubtator_annotations(doc, sents) if a.metadata['type'] == 'Disease']\n",
    "gold = frozenset(gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get candidate recall using simple set operations (note that the candidates are identified based on their `id` attribute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate recall = 0.676\n"
     ]
    }
   ],
   "source": [
    "print \"Candidate recall = %0.3f\" % (len(gold.intersection(candidates)) / float(len(gold)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `Viewer` to inspect data\n",
    "\n",
    "We see that our candidate recall is fairly low, considering that the **candidate recall is an upper bound for our total system recall**.  Next, we'll use the `Viewer` object to do error analysis and get ideas of how to build a better candidate extractor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"../viewer/bootstrap/css/bootstrap.min.css\" rel=\"stylesheet\" />\n",
       "<link href=\"../viewer/viewer.css\" type=\"text/css\" rel=\"stylesheet\" />\n",
       "<div id=\"viewer-308\" class=\"viewer-pane panel panel-default\">\n",
       "    <div class=\"panel-heading\">\n",
       "        <h3 class=\"panel-title\">Viewer</h3>\n",
       "        <div id=\"candidate-caption-308\" class=\"candidate-caption\"></div>\n",
       "    </div>\n",
       "    <div class=\"panel-body\">\n",
       "        <ul class=\"list-group\">\n",
       "            <li class=\"list-group-item context-li\" id=\"308-0\" data-nc=\"1\"><div class=\"candidate-data\" id=\"cdata-0-308\" caption=\"CID: 11208990-0:80-90\"></div><span class=\"\">Association of nitric oxide production and apoptosis in a model of experimental </span><span class=\"candidate c-0-308\">nephropathy</span><span class=\"\">.</span></li>\n",
       "<li class=\"list-group-item context-li\" id=\"308-1\" data-nc=\"0\">BACKGROUND: In recent studies increased amounts of nitric oxide (NO) and apoptosis have been implicated in various pathological conditions in the kidney.</li>\n",
       "<li class=\"list-group-item context-li\" id=\"308-2\" data-nc=\"1\"><div class=\"candidate-data\" id=\"cdata-1-308\" caption=\"CID: 11208990-2:341-358\"></div><span class=\"\">We have studied the role of NO and its association with apoptosis in an experimental model of </span><span class=\"candidate c-1-308\">nephrotic syndrome</span><span class=\"\"> induced by a single injection of adriamycin (ADR).</span></li>\n",
       "        </ul>\n",
       "    </div>\n",
       "    <div class=\"panel-footer\">\n",
       "        <div class=\"btn-group\" role=\"group\" aria-label=\"...\">\n",
       "            <button id=\"prev-page-308\" type=\"button\" class=\"btn btn-default\">\n",
       "                <span class=\"glyphicon glyphicon-left-arrow\" aria-hidden=\"true\"></span> Prev. Page (U)\n",
       "            </button>\n",
       "            <button id=\"prev-cand-308\" type=\"button\" class=\"btn btn-default\">\n",
       "                <span class=\"glyphicon glyphicon-down-arrow\" aria-hidden=\"true\"></span> Prev. Cand. (L)\n",
       "            </button>\n",
       "            <button id=\"next-cand-308\" type=\"button\" class=\"btn btn-default\">\n",
       "                <span class=\"glyphicon glyphicon-up-arrow\" aria-hidden=\"true\"></span> Next Cand. (R)\n",
       "            </button>\n",
       "            <button id=\"next-page-308\" type=\"button\" class=\"btn btn-default\">\n",
       "                <span class=\"glyphicon glyphicon-right-arrow\" aria-hidden=\"true\"></span> Next Page (D)\n",
       "            </button>\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {
      "text/html": {
       "isolated": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "$.getScript(\"https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js\", function () {\n",
       "var vid = 308;\n",
       "var cand = -1;\n",
       "\n",
       "// Get the selector for a given candidate by number (w.r.t. to entire page group)\n",
       "function cid(n) {\n",
       "    return \"span.c-\" + n + \"-\" + vid;\n",
       "}\n",
       "\n",
       "// Get the total number of candidates on the page\n",
       "function getNumberOfCandidates() {\n",
       "    var nC = 0;\n",
       "    $(\"li.context-li:visible\").each(function() {\n",
       "        nC += parseInt($(this).attr(\"data-nc\"));\n",
       "    });\n",
       "    return nC;\n",
       "}\n",
       "\n",
       "// Cycle through candidates and highlight, by increment inc\n",
       "function switchCandidate(inc) {\n",
       "    var nC = getNumberOfCandidates();\n",
       "\n",
       "    // Clear highlighting and highlight new candidate\n",
       "    $(\"span.candidate\").removeClass(\"highlight\");\n",
       "    if (cand + inc < 0) {\n",
       "        cand = nC + (cand + inc);\n",
       "    } else if (cand + inc > nC - 1) {\n",
       "        cand = (cand + inc) - nC;\n",
       "    } else {\n",
       "        cand += inc;\n",
       "    }\n",
       "    var c = $(cid(cand));\n",
       "    c.addClass(\"highlight\");\n",
       "\n",
       "    // Fill in caption\n",
       "    $(\"#candidate-caption-\"+vid).html($(\"#cdata-\"+cand+\"-\"+vid).attr(\"caption\"));\n",
       "};\n",
       "\n",
       "$(\"#next-cand-\" + vid).click(function() {\n",
       "    switchCandidate(1);\n",
       "});\n",
       "\n",
       "$(\"#prev-cand-\" + vid).click(function() {\n",
       "    switchCandidate(-1);\n",
       "});\n",
       "\n",
       "// Arrow key functionality\n",
       "$(document).keydown(function(e) {\n",
       "    // TODO: Check for ':focus' to execute; not working with Jupyter nb...\n",
       "    switch(e.which) {\n",
       "        case 37: // Left\n",
       "        switchCandidate(-1);\n",
       "        break;\n",
       "\n",
       "        case 38: // Up\n",
       "        break;\n",
       "\n",
       "        case 39: // Right\n",
       "        switchCandidate(1);\n",
       "        break;\n",
       "\n",
       "        case 40: // Down\n",
       "        break;\n",
       "    }\n",
       "});\n",
       "});\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ddlite_viewer import SentenceViewer\n",
    "sv = SentenceViewer(corpus)\n",
    "sv.render(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO:\n",
    "\n",
    "1. L/R/U/D navigation / pagination capability!\n",
    "    * Pagination: just have an `n_per_page` argument, and render all given data...\n",
    "2. Handle multiple sets of candidates / annotations\n",
    "    * For now: just handle gold annotations in red text...\n",
    "3. Easier way to input custom sets (i.e.: DECOUPLE!)\n",
    "    * Switch some of these generators to lists...\n",
    "    * Have call be `SentenceViewer(contexts=sents, candidate_sets=[(candidates, 'red'), (gold, 'blue')])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `CandidateSpace` and `Matcher`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ddlite_candidates import Ngrams\n",
    "from ddlite_matchers import DictionaryMatch, Union, Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = Ngrams(n_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matcher = DictionaryMatch(d=diseases, longest_match_only=True)\n",
    "matches = []\n",
    "for match in matcher.apply(cs.apply(sents[0])):\n",
    "    matches.append(match)\n",
    "    print match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matcher = DictionaryMatch(d=diseases, longest_match_only=False)\n",
    "for match in matcher.apply(cs.apply(sents[0])):\n",
    "    print match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dA = ['tricuspid valve', 'lithium']\n",
    "dB = ['regurgitation','carbonate']\n",
    "matcher = Concat(DictionaryMatch(d=dA), DictionaryMatch(d=dB))\n",
    "for match in matcher.apply(cs.apply(sent)):\n",
    "    print match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing against gold candidate set\n",
    "\n",
    "#### TODO: DictionaryMatch accepts either list or dict; in latter case, assumes vals are the IDs!\n",
    "\n",
    "#### ALSO: Add estimate_size method to CandidateExtraction operators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
