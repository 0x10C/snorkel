{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging genes with ddlite\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a gene tagger from scratch. Here's why we developed ddlite:\n",
    "\n",
    "* To provide a lighter-weight interface to structured information extraction for new DeepDive users\n",
    "* To help advanced DeepDive rapidly develop and prototype applications and distant supervision rules\n",
    "* To investigate DeepDive's data programming approach to building inference systems\n",
    "\n",
    "This example is centered around the second item. Domain-specific tagging systems take months or years to develop. They use hand-crafted model circuitry and accurate, hand-labeled training data. We're going to try to build a pretty good one in a few minutes with none of those things. The generalized extraction and learning utilities provided by ddlite will allow us to turn a sampling of article abstracts and some basic domain knowledge into an automated tagging system. Specifically, we want an accurate tagger for genes in academic articles. We have comprehensive dictionaries of genes, but applying a simple matching rule might yield a lot of false positives. For example, \"p53\" might get tagged as a gene if it refers to a page number. Our goal is to use distant supervision to improve precision.\n",
    "\n",
    "Here's the pipeline we'll follow:\n",
    "\n",
    "1. Obtain and parse input data (relevant article abstracts from PubMed)\n",
    "2. Extract candidates for tagging\n",
    "3. Generate features\n",
    "4. Write distant supervision rules\n",
    "5. Learn the tagging model\n",
    "\n",
    "Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input data\n",
    "We already downloaded the raw HTML for ??? gene-related article pages from PubMed using the **pubmed_gene_html.py** script. These can be found in the **data** folder. We can use ddlite's **DocParser** to read in the article text. There's a general HTML parser which finds visible text, but we can do better by writing a more specific version to just grab the abstract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutations in BCS1L, a respiratory chain complex III assembly chaperone, constitute a major cause of mitochondrial complex III deficiency and are associated with GRACILE and Bjrnstad syndromes. Here we describe a 4-year-old infant with hyperlactacidemia, mild liver dysfunction, hypotonia, growth and psychomotor retardation, dysmorphic features and mitochondrial complex III deficiency. Respiratory chain enzyme activities showed an isolated complex III defect in muscle and fibroblasts. Sequencing and polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) analysis revealed a novel homozygous BCS1L mutation, c.148A>G, which caused a p.T50A substitution at an evolutionarily conserved BCS1L region. The severity of the complex III enzyme defect correlated with decreased amounts of BCS1L and respiratory chain complex III in the affected tissues. Our findings support a pathogenic role for the novel BCS1L mutation in a patient with a singular clinical phenotype.\n"
     ]
    }
   ],
   "source": [
    "class PubMedAbstractParser(HTMLParser):\n",
    "    def _cleaner(self, s):\n",
    "        return (s.parent.name == 'abstracttext')\n",
    "\n",
    "dp = DocParser('gene_tag_example/data/', PubMedAbstractParser())\n",
    "docs = list(dp.parseDocs())\n",
    "print docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use CoreNLP via ddlite's SentenceParser to parse each sentence. **DocParser** can handle this too; we didn't really need that call above. This can take a little while, so if the example has already been run, we'll reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence(words=['Mutations', 'in', 'BCS1L', ',', 'a', 'respiratory', 'chain', 'complex', 'III', 'assembly', 'chaperone', ',', 'constitute', 'a', 'major', 'cause', 'of', 'mitochondrial', 'complex', 'III', 'deficiency', 'and', 'are', 'associated', 'with', 'GRACILE', 'and', 'Bjrnstad', 'syndromes', '.'], lemmas=['mutation', 'in', 'bcs1l', ',', 'a', 'respiratory', 'chain', 'complex', 'iii', 'assembly', 'chaperone', ',', 'constitute', 'a', 'major', 'cause', 'of', 'mitochondrial', 'complex', 'iii', 'deficiency', 'and', 'be', 'associate', 'with', 'gracile', 'and', 'bjrnstad', 'syndrome', '.'], poses=['NNS', 'IN', 'NN', ',', 'DT', 'JJ', 'NN', 'NN', 'CD', 'NN', 'NN', ',', 'VBP', 'DT', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'CD', 'NN', 'CC', 'VBP', 'VBN', 'IN', 'NN', 'CC', 'NN', 'NNS', '.'], dep_parents=[13, 3, 1, 3, 11, 11, 11, 11, 11, 11, 3, 3, 0, 16, 16, 13, 21, 21, 21, 21, 16, 13, 24, 13, 26, 24, 26, 29, 26, 13], dep_labels=['nsubj', 'case', 'nmod', 'punct', 'det', 'amod', 'compound', 'compound', 'nummod', 'compound', 'appos', 'punct', 'ROOT', 'det', 'amod', 'dobj', 'case', 'amod', 'compound', 'nummod', 'nmod', 'cc', 'auxpass', 'conj', 'case', 'nmod', 'cc', 'compound', 'conj', 'punct'], sent_id=0, doc_id=0)\n"
     ]
    }
   ],
   "source": [
    "docs = None\n",
    "\n",
    "pkl_f = 'gene_tag_example/saved_sents.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        sents = cPickle.load(f)\n",
    "except:\n",
    "    sents = dp.parseDocSentences()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(sents, f)\n",
    "\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting candidates\n",
    "Extracting candidates for mentions (or relations) is a one-liner in ddlite. We have access to a pretty comprehensive gene dictionary. This will give use high recall, so again, our objective is to cut down on false positives. Let's load in the dictionary and create our candidate mentions in an **Entities** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('gene_tag_example/dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 2, genes)\n",
    "\n",
    "ents = Entities(DictionaryMatch('Gene', genes, ignore_case=False), sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize contexts for our extractions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-7117257943788924579\"></div>\n",
       "<div id=\"raw-seq-7117257943788924579\">\n",
       "<span class=\"word-7117257943788924579-0\">Mutations</span> <span class=\"word-7117257943788924579-1\">in</span> <span class=\"word-7117257943788924579-2\">BCS1L</span> <span class=\"word-7117257943788924579-3\">,</span> <span class=\"word-7117257943788924579-4\">a</span> <span class=\"word-7117257943788924579-5\">respiratory</span> <span class=\"word-7117257943788924579-6\">chain</span> <span class=\"word-7117257943788924579-7\">complex</span> <span class=\"word-7117257943788924579-8\">III</span> <span class=\"word-7117257943788924579-9\">assembly</span> <span class=\"word-7117257943788924579-10\">chaperone</span> <span class=\"word-7117257943788924579-11\">,</span> <span class=\"word-7117257943788924579-12\">constitute</span> <span class=\"word-7117257943788924579-13\">a</span> <span class=\"word-7117257943788924579-14\">major</span> <span class=\"word-7117257943788924579-15\">cause</span> <span class=\"word-7117257943788924579-16\">of</span> <span class=\"word-7117257943788924579-17\">mitochondrial</span> <span class=\"word-7117257943788924579-18\">complex</span> <span class=\"word-7117257943788924579-19\">III</span> <span class=\"word-7117257943788924579-20\">deficiency</span> <span class=\"word-7117257943788924579-21\">and</span> <span class=\"word-7117257943788924579-22\">are</span> <span class=\"word-7117257943788924579-23\">associated</span> <span class=\"word-7117257943788924579-24\">with</span> <span class=\"word-7117257943788924579-25\">GRACILE</span> <span class=\"word-7117257943788924579-26\">and</span> <span class=\"word-7117257943788924579-27\">Bjrnstad</span> <span class=\"word-7117257943788924579-28\">syndromes</span> <span class=\"word-7117257943788924579-29\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"7117257943788924579\";\n",
       "var root = {\"attrib\": {\"word\": \"constitute\", \"dep_label\": \"ROOT\", \"pos\": \"VBP\", \"lemma\": \"constitute\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"Mutations\", \"dep_label\": \"nsubj\", \"pos\": \"NNS\", \"lemma\": \"mutation\", \"word_idx\": \"0\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"BCS1L\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"bcs1l\", \"word_idx\": \"2\", \"dep_parent\": \"1\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"1\", \"dep_parent\": \"3\"}, \"children\": []}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"3\", \"dep_parent\": \"3\"}, \"children\": []}, {\"attrib\": {\"word\": \"chaperone\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"chaperone\", \"word_idx\": \"10\", \"dep_parent\": \"3\"}, \"children\": [{\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"4\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"respiratory\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"respiratory\", \"word_idx\": \"5\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"chain\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"chain\", \"word_idx\": \"6\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"complex\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"complex\", \"word_idx\": \"7\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"III\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"iii\", \"word_idx\": \"8\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"assembly\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"assembly\", \"word_idx\": \"9\", \"dep_parent\": \"11\"}, \"children\": []}]}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"11\", \"dep_parent\": \"3\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \"cause\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"cause\", \"word_idx\": \"15\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"13\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"word\": \"major\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"major\", \"word_idx\": \"14\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"word\": \"deficiency\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"deficiency\", \"word_idx\": \"20\", \"dep_parent\": \"16\"}, \"children\": [{\"attrib\": {\"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"16\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"mitochondrial\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mitochondrial\", \"word_idx\": \"17\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"complex\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"complex\", \"word_idx\": \"18\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"III\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"iii\", \"word_idx\": \"19\", \"dep_parent\": \"21\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"21\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"associated\", \"dep_label\": \"conj\", \"pos\": \"VBN\", \"lemma\": \"associate\", \"word_idx\": \"23\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"are\", \"dep_label\": \"auxpass\", \"pos\": \"VBP\", \"lemma\": \"be\", \"word_idx\": \"22\", \"dep_parent\": \"24\"}, \"children\": []}, {\"attrib\": {\"word\": \"GRACILE\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"gracile\", \"word_idx\": \"25\", \"dep_parent\": \"24\"}, \"children\": [{\"attrib\": {\"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"24\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"26\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"syndromes\", \"dep_label\": \"conj\", \"pos\": \"NNS\", \"lemma\": \"syndrome\", \"word_idx\": \"28\", \"dep_parent\": \"26\"}, \"children\": [{\"attrib\": {\"word\": \"Bjrnstad\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bjrnstad\", \"word_idx\": \"27\", \"dep_parent\": \"29\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[2]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ents.entities[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating features\n",
    "Feature extraction is push-button in ddlite. We extract a number of generic features from the NLP markup and dependency tree in the vicinity of the mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 18025 features for each of 711 mentions\n"
     ]
    }
   ],
   "source": [
    "ents.extract_features()\n",
    "print \"Extracted {} features for each of {} mentions\".format(ents.num_feats(), ents.num_extractions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing distant supervision rules\n",
    "Candidate and feature extraction are really simple in ddlite. Writing distant supervision rules is where artistry comes in. One of ddlite's goals is to enable rapid prototyping and experimenting with distant supervision rules, either to create a simple standalone app, or to plug your findings into DeepDive. Rules must return 1 (for a positive label), 0 (for abstaining), or -1 (for a negative example). For now, we'll write a few simple rules to get started:\n",
    "\n",
    "* The first rule returns a positive label if the mention candiate contains the word \"gene\", and abstains otherwise\n",
    "* The second rule returns a positive label if the dependency parent of any of the words in the mention is \"mutation\", and abstains otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rule_1(m):\n",
    "    return 1 if 'gene' in [m.lemmas[i] for i in m.idxs] else 0\n",
    "def rule_2(m):\n",
    "    return 1 if 'mutation' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two rules given above won't yield a good model (especially since there are no negative examples). To create meaningful results, write more distant supervision rules! After writing the rules, we simply collect them and apply them to mentions. If we define more rules later, we can apply them incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 2 rules to 711 mentions with 39 positives, 1383 abstains, and 0 negatives.\n"
     ]
    }
   ],
   "source": [
    "rules = [rule_1, rule_2]\n",
    "ents.apply_rules(rules)\n",
    "print \"Applied {} rules to {} mentions with {} positives, {} abstains, and {} negatives.\".format(ents.num_rules(),\n",
    "        ents.num_extractions(), ents.num_rules('pos'), ents.num_rules('abs'), ents.num_rules('neg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning\n",
    "To learn weights for the features and rules, we use a simple, regularized logistic regression model. Again, the results won't be meaningful without more rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning epoch = 0\n",
      "Learning epoch = 100\n",
      "Learning epoch = 200\n",
      "Learning epoch = 300\n",
      "Learning epoch = 400\n",
      "Learning epoch = 500\n",
      "Learning epoch = 600\n",
      "Learning epoch = 700\n",
      "Learning epoch = 800\n",
      "Learning epoch = 900\n",
      "Learning epoch = 1000\n",
      "Learning epoch = 1100\n",
      "Learning epoch = 1200\n",
      "Learning epoch = 1300\n",
      "Learning epoch = 1400\n",
      "Learning epoch = 1500\n",
      "Learning epoch = 1600\n",
      "Learning epoch = 1700\n",
      "Learning epoch = 1800\n",
      "Learning epoch = 1900\n",
      "Learning epoch = 2000\n",
      "Learning epoch = 2100\n",
      "Learning epoch = 2200\n",
      "Learning epoch = 2300\n",
      "Learning epoch = 2400\n",
      "Learning epoch = 2500\n",
      "Learning epoch = 2600\n",
      "Learning epoch = 2700\n",
      "Learning epoch = 2800\n",
      "Learning epoch = 2900\n",
      "Learning epoch = 3000\n",
      "Learning epoch = 3100\n",
      "Learning epoch = 3200\n",
      "Learning epoch = 3300\n",
      "Learning epoch = 3400\n",
      "Learning epoch = 3500\n",
      "Learning epoch = 3600\n",
      "Learning epoch = 3700\n",
      "Learning epoch = 3800\n",
      "Learning epoch = 3900\n",
      "Learning epoch = 4000\n",
      "Learning epoch = 4100\n",
      "Learning epoch = 4200\n",
      "Learning epoch = 4300\n",
      "Learning epoch = 4400\n",
      "Learning epoch = 4500\n",
      "Learning epoch = 4600\n",
      "Learning epoch = 4700\n",
      "Learning epoch = 4800\n",
      "Learning epoch = 4900\n",
      "CPU times: user 11.8 s, sys: 128 ms, total: 11.9 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%time ents.learn_feats_and_weights(nSteps=5000, sample=False, mu=1e-6, holdout=0, use_sparse=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the learned weights for each feature and rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule weights: [ 0.99995     1.03414566]\n",
      "Some feature weights: [ 0.00065546  0.00040638  0.00060161  0.00093767  0.00102189  0.00079554\n",
      "  0.00056748  0.00216541  0.0013035   0.00092172]\n"
     ]
    }
   ],
   "source": [
    "print \"Rule weights: {}\".format(ents.w[:ents.num_rules()])\n",
    "print \"Some feature weights: {}\".format(ents.w[ents.num_rules():ents.num_rules()+10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or look at the predicted probability of each mention candidate being an actual gene mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some predicted mention probabilities: [ 0.96350683  0.97733847  0.91167675  0.90963345  0.97789141  0.90166807\n",
      "  0.94487487  0.85467558  0.89326303  0.89973452]\n"
     ]
    }
   ],
   "source": [
    "print \"Some predicted mention probabilities: {}\".format(ents.get_predicted_probability()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Error Analysis\n",
    "\n",
    "Now, let's look at a sample of extractions using [Mindtagger](http://deepdive.stanford.edu/labeling).  We can use a shorthand to create a Mindtagger task and launch it right from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"http://icme-Standard-PC-i440FX-PIIX-1996:8838/#/mindtagger/30d0848e036c6adc\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb1ca002410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents.open_mindtagger(num_sample=20, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'is_correct': True, u'sent_id': 3}, {u'is_correct': True, u'sent_id': 0}, {u'is_correct': False, u'sent_id': 5}, {u'sent_id': 8}, {u'sent_id': 1}, {u'sent_id': 1}, {u'is_correct': True, u'sent_id': 3}, {u'sent_id': 1}, {u'is_correct': False, u'sent_id': 5}, {u'sent_id': 1}, {u'sent_id': 4}, {u'sent_id': 4}, {u'sent_id': 9}, {u'is_correct': True, u'sent_id': 3}, {u'is_correct': False, u'sent_id': 5}, {u'is_correct': False, u'sent_id': 5}, {u'sent_id': 1}, {u'is_correct': True, u'sent_id': 0}, {u'is_correct': False, u'sent_id': 5}, {u'is_correct': True, u'sent_id': 3}]\n"
     ]
    }
   ],
   "source": [
    "tags = ents.get_mindtagger_tags()\n",
    "print tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precision =  55%'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_exts = [tag for tag in tags if u'is_correct' in tag]\n",
    "num_correct = sum(1 for tag in tagged_exts if tag[u'is_correct'])\n",
    "\"precision = %3.f%%\" % (100 * num_correct * 1.0 / len(tagged_exts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
