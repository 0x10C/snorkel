{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARDWARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sen/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1085: UserWarning: Duplicate key in file \"/Users/sen/.matplotlib/matplotlibrc\", line #467\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "To change attributes:\n",
    "1) Change ATTRIBUTE and you're good to go\n",
    "\"\"\"\n",
    "ATTRIBUTE = 'polarity'\n",
    "COUNTER = '_new'\n",
    "PARALLEL = 10\n",
    "PARALLEL_F = 10\n",
    "PARALLEL_EXTRACTION = 8\n",
    "TRAIN_SIZE = 25\n",
    "DEV_SIZE = 25\n",
    "TEST_SIZE = 25\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "os.environ['SNORKELDB'] = 'postgres://localhost:5432/'# + os.environ['SNORKELDBNAME']\n",
    "        \n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/')\n",
    "snorkel_postgres = os.environ['SNORKELDB'].startswith('postgres')\n",
    "print snorkel_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "SNORKELDBNAME = polarity_new2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "#     os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "    print os.system(\"dropdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print os.system(\"createdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print \"SNORKELDBNAME = %s\" % os.environ['SNORKELDBNAME']\n",
    "else:\n",
    "    try:\n",
    "        os.remove('snorkel.db')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "from fonduer import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async parse...\n",
      "[========================================] 100%\n",
      "CPU times: user 162 ms, sys: 73.8 ms, total: 236 ms\n",
      "Wall time: 26.2 s\n",
      "Corpus (Hardware Train) contains 25 documents\n",
      "[========================================] 100%\n",
      "CPU times: user 99.3 ms, sys: 63.9 ms, total: 163 ms\n",
      "Wall time: 58.1 s\n",
      "Corpus (Hardware Dev) contains 24 documents\n",
      "[========================================] 100%\n",
      "CPU times: user 97.6 ms, sys: 63.5 ms, total: 161 ms\n",
      "Wall time: 45.2 s\n",
      "Corpus (Hardware Test) contains 25 documents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_parser import parse_corpus, HTMLParser, AsyncOmniParser\n",
    "    print \"Starting async parse...\"\n",
    "    \n",
    "    # PARSE TRAIN\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_digikey/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_digikey/pdf/'\n",
    "    doc_parser = HTMLParser()\n",
    "    context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True, pdf_path=pdf_path)\n",
    "    %time corpus = parse_corpus(session, 'Hardware Train', docs_path,\\\n",
    "                                doc_parser, context_parser,\\\n",
    "                                max_docs=TRAIN_SIZE, parallel=PARALLEL)\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "    session.commit()\n",
    "    # PARSE DEV\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/pdf/'\n",
    "    context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True, pdf_path=pdf_path)\n",
    "    %time corpus = parse_corpus(session, 'Hardware Dev', docs_path,\\\n",
    "                                doc_parser, context_parser,\\\n",
    "                                max_docs=DEV_SIZE, parallel=PARALLEL)\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "    session.commit()\n",
    "    if TEST_SIZE:\n",
    "        # PARSE TEST\n",
    "        docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/html/'\n",
    "        pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/pdf/'\n",
    "        context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                         tabular=True, lingual=True,\n",
    "                                         visual=True, pdf_path=pdf_path)\n",
    "        %time corpus = parse_corpus(session, 'Hardware Test', docs_path,\\\n",
    "                                    doc_parser, context_parser,\\\n",
    "                                    max_docs=TEST_SIZE, parallel=PARALLEL)\n",
    "        print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "        session.commit()\n",
    "else:\n",
    "    from fonduer.parser import CorpusParser, HTMLParser, OmniParser\n",
    "    from fonduer.utils import get_ORM_instance\n",
    "    from fonduer.queries import split_corpus\n",
    "\n",
    "    print \"Starting sync parse...\"\n",
    "    # PARSE TRAIN\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_small/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_small/pdf/'\n",
    "    doc_parser = HTMLParser(path=docs_path)\n",
    "    context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True, pdf_path=pdf_path)\n",
    "    cp = CorpusParser(doc_parser, context_parser, max_docs=100)\n",
    "\n",
    "    %time corpus = cp.parse_corpus(name='Hardware Train', session=session)\n",
    "    print \"%s contains %d documents\" % corpus, len(corpus)\n",
    "\n",
    "    session.add(corpus)\n",
    "    session.commit()\n",
    "    \n",
    "    # PARSE DEV\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/pdf/'\n",
    "    doc_parser = HTMLParser(path=docs_path)\n",
    "    context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                 tabular=True, lingual=True,\n",
    "                                 visual=True, pdf_path=pdf_path)\n",
    "    cp = CorpusParser(doc_parser, context_parser, max_docs=125)\n",
    "\n",
    "    %time corpus = cp.parse_corpus(name='Hardware Dev', session=session)\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "    session.add(corpus)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import candidate_subclass\n",
    "\n",
    "Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# session.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using combined matcher.\n"
     ]
    }
   ],
   "source": [
    "from hardware_matchers import get_matcher\n",
    "\n",
    "dict_path = os.environ['SNORKELHOME'] +\\\n",
    "    '/fonduer_tutorials/tables/data/hardware/gold_raw/digikey_part_dictionary.csv'\n",
    "part_matcher = get_matcher('part', dict_path)\n",
    "attr_matcher = get_matcher(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_spaces import get_space\n",
    "    \n",
    "part_ngrams = get_space('part')\n",
    "attr_ngrams = get_space(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Candidate Throttler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function polarity_throttler at 0x10fa7a050>\n"
     ]
    }
   ],
   "source": [
    "from hardware_throttlers import get_throttler\n",
    "\n",
    "throttler = get_throttler(ATTRIBUTE)\n",
    "# throttler = None\n",
    "print throttler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Train)\n",
      "[========================================] 100%\n",
      "CPU times: user 72.4 ms, sys: 58.3 ms, total: 131 ms\n",
      "Wall time: 9.72 s\n",
      "Candidate Set (Hardware Train Candidates) contains 1375 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Dev)\n",
      "[========================================] 100%\n",
      "CPU times: user 114 ms, sys: 75.6 ms, total: 189 ms\n",
      "Wall time: 1min 7s\n",
      "Candidate Set (Hardware Dev Candidates) contains 4977 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Test)\n",
      "[========================================] 100%\n",
      "CPU times: user 94.4 ms, sys: 63.3 ms, total: 158 ms\n",
      "Wall time: 1min 5s\n",
      "Candidate Set (Hardware Test Candidates) contains 3490 Candidates\n"
     ]
    }
   ],
   "source": [
    "from fonduer.models import Corpus\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from fonduer.async_candidates import parallel_extract\n",
    "\n",
    "ce = CandidateExtractor(Part_Attr, \n",
    "                        [part_ngrams, attr_ngrams], \n",
    "                        [part_matcher, attr_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "corpus_names = ['Hardware Train', 'Hardware Dev']\n",
    "if TEST_SIZE:\n",
    "    corpus_names.append('Hardware Test')\n",
    "for corpus_name in corpus_names:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = parallel_extract(session, ce, corpus, \\\n",
    "                                        corpus_name + ' Candidates', \\\n",
    "                                        parallel=PARALLEL_EXTRACTION)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.models import Corpus\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "\n",
    "# # parts_by_doc = get_gold_parts_by_doc()\n",
    "# parts_by_doc = get_manual_parts_by_doc(corpus.documents.all())\n",
    "# # parts_by_doc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cPickle as pickle\n",
    "# pickle_file = os.environ['SNORKELHOME'] + '/tutorials/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "\n",
    "# with open(pickle_file, 'w') as f:\n",
    "#     pickle.dump(parts_by_doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "with open(pickle_file, 'r') as f:\n",
    "    parts_by_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.923\n",
      "Corpus Recall    0.978\n",
      "Corpus F1        0.949\n",
      "----------------------------------------\n",
      "TP: 310 | FP: 26 | FN: 7\n",
      "========================================\n",
      "\n",
      "CPU times: user 7.19 s, sys: 356 ms, total: 7.54 s\n",
      "Wall time: 8.82 s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.models import Corpus, CandidateSet\n",
    "from hardware_utils import entity_level_f1\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "candidates = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "gold_file = os.environ['SNORKELHOME'] + \\\n",
    "    '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "%time (ctp, cfp, cfn) = entity_level_f1(candidates, gold_file, ATTRIBUTE, corpus, parts_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'2N6427', u'MPSA14', u'NPN'),\n",
      " (u'BC337', u'BC33740BU', u'NPN'),\n",
      " (u'BC337', u'BC338-16', u'NPN'),\n",
      " (u'BC337', u'BC338-40', u'NPN'),\n",
      " (u'BC337-D', u'BC337-XX', u'NPN'),\n",
      " (u'BC546-BC548C(TO-92)', u'BC546-BC548C', u'NPN'),\n",
      " (u'BC546_DIOTEC', u'BC546', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC546A', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC546B', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC546C', u'NPN'),\n",
      " (u'BC546_DIOTEC', u'BC546C', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC547', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC547A', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC547B', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC547C', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC548', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC548A', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC548B', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC548C', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC549', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC549A', u'NPN'),\n",
      " (u'BC546_DIOTEC', u'BC549A', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC549B', u'PNP'),\n",
      " (u'BC546_DIOTEC', u'BC549C', u'PNP'),\n",
      " (u'BC547', u'BC548BU', u'NPN'),\n",
      " (u'BC818-40LT1-D', u'BC818-40LT1', u'NPN')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BOURNSINC_BD246BS', 'BD246', 'PNP'),\n",
      " ('BOURNSINC_BD246BS', 'BD246A', 'PNP'),\n",
      " ('BOURNSINC_BD246BS', 'BD246B', 'PNP'),\n",
      " ('BOURNSINC_BD246BS', 'BD246C', 'PNP'),\n",
      " ('BOURNSINC_TIP152S', 'TIP150', 'NPN'),\n",
      " ('BOURNSINC_TIP152S', 'TIP151', 'NPN'),\n",
      " ('BOURNSINC_TIP152S', 'TIP152', 'NPN')]\n"
     ]
    }
   ],
   "source": [
    "pprint(cfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 4977 candidate labels\n",
      "[========================================] 100%\n",
      "CPU times: user 12.1 s, sys: 602 ms, total: 12.7 s\n",
      "Wall time: 15.4 s\n",
      "4915/4977 Candidates in Candidate Set (Hardware Dev Candidates) have positive Labels\n",
      "Loading 3490 candidate labels\n",
      "[========================================] 100%\n",
      "CPU times: user 7.11 s, sys: 379 ms, total: 7.49 s\n",
      "Wall time: 9.05 s\n",
      "2961/3490 Candidates in Candidate Set (Hardware Test Candidates) have positive Labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fonduer.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "data_sets = ['Dev']\n",
    "gold_file = {}\n",
    "gold_file['Dev'] = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "if TEST_SIZE:\n",
    "    data_sets.append('Test')\n",
    "    gold_file['Test'] = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "for data_set in data_sets:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % data_set\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % data_set\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % data_set\n",
    "    %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file[data_set], \\\n",
    "                           ATTRIBUTE)\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# # os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async featurization...\n",
      "[========================================] 100%\n",
      "Copying hardware_train_candidates_features to postgres\n",
      "COPY 1375\n",
      "\n",
      "CPU times: user 5.89 s, sys: 275 ms, total: 6.17 s\n",
      "Wall time: 37.8 s\n",
      "[========================================] 100%\n",
      "Copying hardware_dev_candidates_features to postgres\n",
      "COPY 4977\n",
      "\n",
      "CPU times: user 4.87 s, sys: 249 ms, total: 5.12 s\n",
      "Wall time: 5min 38s\n",
      "[========================================] 100%\n",
      "Copying hardware_test_candidates_features to postgres\n",
      "COPY 3490\n",
      "\n",
      "CPU times: user 3.29 s, sys: 221 ms, total: 3.51 s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "from fonduer.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Train Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "test  = get_ORM_instance(CandidateSet, session, 'Hardware Test Candidates')\n",
    "\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_annotations import annotate\n",
    "    print \"Starting async featurization...\"\n",
    "    %time F_train = annotate(train, parallel=PARALLEL_F, dynamic_scheduling=False)\n",
    "    %time F_dev   = annotate(dev, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                             keyset = 'Hardware Train Candidates')\n",
    "    if TEST_SIZE:\n",
    "        %time F_test = annotate(test, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                                keyset = 'Hardware Train Candidates')\n",
    "    \n",
    "else:\n",
    "    from fonduer.models import CandidateSet\n",
    "    from fonduer.fast_annotations import FeatureManager\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "\n",
    "    print \"Starting sync featurization...\"\n",
    "    feature_manager = FeatureManager()\n",
    "    %time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "    %time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Train Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Dev Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_lfs import get_lfs\n",
    "\n",
    "LFs = get_lfs(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "Copying hardware_train_candidates_labels to postgres\n",
      "COPY 1375\n",
      "\n",
      "CPU times: user 477 ms, sys: 166 ms, total: 644 ms\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1375x12 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 3765 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if snorkel_postgres:\n",
    "    from fonduer.async_annotations import annotate\n",
    "    %time L_train = annotate(train, parallel=PARALLEL_F, lfs=LFs, dynamic_scheduling=False)\n",
    "else:\n",
    "    from fonduer.fast_annotations import LabelManager\n",
    "    label_manager = LabelManager()\n",
    "    %time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.51 ms, sys: 1.46 ms, total: 5.96 ms\n",
      "Wall time: 5.24 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflicts</th>\n",
       "      <th>coverage</th>\n",
       "      <th>j</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_part_complement</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_complement</th>\n",
       "      <td>0.142545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_transistor_type</th>\n",
       "      <td>0.142545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_many_p_siblings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_in_header_tag</th>\n",
       "      <td>0.142545</td>\n",
       "      <td>0.396364</td>\n",
       "      <td>4</td>\n",
       "      <td>0.396364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_right_of_part</th>\n",
       "      <td>0.030545</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_replacement_table</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_both_present</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_please_to_left</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_tabular_align</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_vert_align</th>\n",
       "      <td>0.051636</td>\n",
       "      <td>0.175273</td>\n",
       "      <td>10</td>\n",
       "      <td>0.175273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_polarity_part_horz_align</th>\n",
       "      <td>0.064727</td>\n",
       "      <td>0.066182</td>\n",
       "      <td>11</td>\n",
       "      <td>0.066182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                conflicts  coverage   j  overlaps\n",
       "LF_part_complement               0.000000  0.000000   0  0.000000\n",
       "LF_polarity_complement           0.142545  1.000000   1  1.000000\n",
       "LF_polarity_transistor_type      0.142545  1.000000   2  1.000000\n",
       "LF_many_p_siblings               0.000000  0.000000   3  0.000000\n",
       "LF_polarity_in_header_tag        0.142545  0.396364   4  0.396364\n",
       "LF_polarity_right_of_part        0.030545  0.100364   5  0.100364\n",
       "LF_replacement_table             0.000000  0.000000   6  0.000000\n",
       "LF_both_present                  0.000000  0.000000   7  0.000000\n",
       "LF_please_to_left                0.000000  0.000000   8  0.000000\n",
       "LF_polarity_part_tabular_align   0.000000  0.000000   9  0.000000\n",
       "LF_polarity_part_vert_align      0.051636  0.175273  10  0.175273\n",
       "LF_polarity_part_horz_align      0.064727  0.066182  11  0.066182"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "# label_manager = LabelManager()\n",
    "# %time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sen/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 264 ms, total: 25 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=500, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEh9JREFUeJzt3XGsnfV93/H3ZzYQIE0w486itle7mpXOoK5Jryhpuyga\nm3BDFKNpYp6W1s1oUFSaJd2kCBZprH94Yko1ZZFGJCtJ6ywZlkfJsNKmC3XTJdME9BIIYBuKE0Ow\na/Bto5SulUih3/1xfgmnN5hrn+f43kN+75d0dH7P7/k9z/M95557P+d5nvOcm6pCktSnv7XaBUiS\nVo8hIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSerY2tUuYDmXXXZZbd68ebXLkKTX\nlAcffPBPqmpuuXEzHwKbN29mYWFhtcuQpNeUJE+fyTgPB0lSx5YNgSSfSnIqyWNjfR9J8niSR5J8\nLsklY/NuTXI0yRNJrh3r/8kkj7Z5H0uS6T8cSdLZOJM9gd8Eti/puxe4sqp+HPgj4FaAJNuAncAV\nbZk7kqxpy3wceC+wtd2WrlOStMKWDYGq+jLwrSV9X6yqF9vkfcDG1t4B7KuqF6rqGHAUuCrJ5cAb\nquq+Gn139aeB66f1ICRJk5nGOYF/BXyhtTcAz4zNO976NrT20n5J0ioaFAJJPgy8CHx2OuV8b703\nJVlIsrC4uDjNVUuSxkwcAkl+EXgn8C/r5X9PdgLYNDZsY+s7wcuHjMb7X1FV7amq+aqan5tb9mOu\nkqQJTRQCSbYDHwLeVVV/OTbrALAzyQVJtjA6AfxAVZ0Enk9ydftU0C8A9wysXZI00LIXiyW5E3g7\ncFmS48BtjD4NdAFwb/uk531V9b6qOpRkP3CY0WGim6vqpbaqX2b0SaMLGZ1D+AKSpFWVWf9H8/Pz\n8+UVw5Jeizbf8tsTL/vU7dcN2naSB6tqfrlxXjEsSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYI\nSFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAk\ndcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY8uGQJJPJTmV5LGxvkuT3JvkyXa/bmze\nrUmOJnkiybVj/T+Z5NE272NJMv2HI0k6G2eyJ/CbwPYlfbcAB6tqK3CwTZNkG7ATuKItc0eSNW2Z\njwPvBba229J1SpJW2LIhUFVfBr61pHsHsLe19wLXj/Xvq6oXquoYcBS4KsnlwBuq6r6qKuDTY8tI\nklbJpOcE1lfVydZ+Fljf2huAZ8bGHW99G1p7ab8kaRUNPjHc3tnXFGr5niQ3JVlIsrC4uDjNVUuS\nxkwaAs+1Qzy0+1Ot/wSwaWzcxtZ3orWX9r+iqtpTVfNVNT83NzdhiZKk5UwaAgeAXa29C7hnrH9n\nkguSbGF0AviBdujo+SRXt08F/cLYMpKkVbJ2uQFJ7gTeDlyW5DhwG3A7sD/JjcDTwA0AVXUoyX7g\nMPAicHNVvdRW9cuMPml0IfCFdpMkraJlQ6Cq/sVpZl1zmvG7gd2v0L8AXHlW1UmSzimvGJakjhkC\nktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJ\nHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQx\nQ0CSOjYoBJL8apJDSR5LcmeS1yW5NMm9SZ5s9+vGxt+a5GiSJ5JcO7x8SdIQE4dAkg3Avwbmq+pK\nYA2wE7gFOFhVW4GDbZok29r8K4DtwB1J1gwrX5I0xNDDQWuBC5OsBS4C/hjYAext8/cC17f2DmBf\nVb1QVceAo8BVA7cvSRpg4hCoqhPArwPfBE4Cf1ZVXwTWV9XJNuxZYH1rbwCeGVvF8db3fZLclGQh\nycLi4uKkJUqSljHkcNA6Ru/utwA/DFyc5N3jY6qqgDrbdVfVnqqar6r5ubm5SUuUJC1jyOGgfwwc\nq6rFqvor4G7gp4HnklwO0O5PtfEngE1jy29sfZKkVTIkBL4JXJ3koiQBrgGOAAeAXW3MLuCe1j4A\n7ExyQZItwFbggQHblyQNtHbSBavq/iR3AV8FXgQeAvYArwf2J7kReBq4oY0/lGQ/cLiNv7mqXhpY\nvyRpgIlDAKCqbgNuW9L9AqO9glcavxvYPWSbkqTp8YphSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS\n1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkd\nMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHRsUAkkuSXJXkseTHEny1iSXJrk3\nyZPtft3Y+FuTHE3yRJJrh5cvSRpi6J7AfwF+t6p+DPgHwBHgFuBgVW0FDrZpkmwDdgJXANuBO5Ks\nGbh9SdIAE4dAkjcCbwM+CVBV36mqbwM7gL1t2F7g+tbeAeyrqheq6hhwFLhq0u1LkoYbsiewBVgE\nfiPJQ0k+keRiYH1VnWxjngXWt/YG4Jmx5Y+3vu+T5KYkC0kWFhcXB5QoSXo1Q0JgLfAW4ONV9Wbg\nL2iHfr6rqgqos11xVe2pqvmqmp+bmxtQoiTp1QwJgePA8aq6v03fxSgUnktyOUC7P9XmnwA2jS2/\nsfVJklbJxCFQVc8CzyR5U+u6BjgMHAB2tb5dwD2tfQDYmeSCJFuArcADk25fkjTc2oHLvx/4bJLz\ngW8A72EULPuT3Ag8DdwAUFWHkuxnFBQvAjdX1UsDty9JGmBQCFTVw8D8K8y65jTjdwO7h2xTkjQ9\nXjEsSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4Z\nApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEg\nSR0zBCSpY4NDIMmaJA8l+XybvjTJvUmebPfrxsbemuRokieSXDt025KkYaaxJ/AB4MjY9C3Awara\nChxs0yTZBuwErgC2A3ckWTOF7UuSJjQoBJJsBK4DPjHWvQPY29p7gevH+vdV1QtVdQw4Clw1ZPuS\npGGG7gl8FPgQ8Ndjfeur6mRrPwusb+0NwDNj4463PknSKpk4BJK8EzhVVQ+ebkxVFVATrPumJAtJ\nFhYXFyctUZK0jCF7Aj8DvCvJU8A+4B8l+QzwXJLLAdr9qTb+BLBpbPmNre/7VNWeqpqvqvm5ubkB\nJUqSXs3EIVBVt1bVxqrazOiE7+9X1buBA8CuNmwXcE9rHwB2JrkgyRZgK/DAxJVLkgZbew7WeTuw\nP8mNwNPADQBVdSjJfuAw8CJwc1W9dA62L0k6Q1MJgar6A+APWvtPgWtOM243sHsa25QkDecVw5LU\nMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0z\nBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNA\nkjo2cQgk2ZTkS0kOJzmU5AOt/9Ik9yZ5st2vG1vm1iRHkzyR5NppPABJ0uSG7Am8CPzbqtoGXA3c\nnGQbcAtwsKq2AgfbNG3eTuAKYDtwR5I1Q4qXJA0zcQhU1cmq+mpr/zlwBNgA7AD2tmF7getbewew\nr6peqKpjwFHgqkm3L0kabirnBJJsBt4M3A+sr6qTbdazwPrW3gA8M7bY8dYnSVolg0MgyeuB3wI+\nWFXPj8+rqgJqgnXelGQhycLi4uLQEiVJpzEoBJKcxygAPltVd7fu55Jc3uZfDpxq/SeATWOLb2x9\n36eq9lTVfFXNz83NDSlRkvQqhnw6KMAngSNV9Z/HZh0AdrX2LuCesf6dSS5IsgXYCjww6fYlScOt\nHbDszwA/Dzya5OHW9++A24H9SW4EngZuAKiqQ0n2A4cZfbLo5qp6acD2JUkDTRwCVfV/gJxm9jWn\nWWY3sHvSbUqSpssrhiWpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1\nzBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1LGJ/9H8a8HmW357\n4mWfuv26KVaiWeVrRL1zT0CSOvYDvScgnUvuRegHgXsCktQxQ0CSOubhIH2Phzek/qz4nkCS7Ume\nSHI0yS0rvX1J0stWdE8gyRrgvwL/BDgO/GGSA1V1eCXrkF7r3GvTtKz0nsBVwNGq+kZVfQfYB+xY\n4RokSc1Kh8AG4Jmx6eOtT5K0ClJVK7ex5J8B26vql9r0zwM/VVW/smTcTcBNbfJNwJ8Cf7JihZ69\ny7C+IaxvcrNcG1jfUEPq+5Gqmltu0Ep/OugEsGlsemPr+xuqag+w57vTSRaqav7clzcZ6xvG+iY3\ny7WB9Q21EvWt9OGgPwS2JtmS5HxgJ3BghWuQJDUruidQVS8m+RXgfwFrgE9V1aGVrEGS9LIVv1is\nqn4H+J2zXGzP8kNWlfUNY32Tm+XawPqGOuf1reiJYUnSbPG7gySpY6saAst9hUSSdUk+l+SRJA8k\nubL1b0rypSSHkxxK8oEZq+91bfprrb5fm6X6xuavSfJQks/PWn1JnkryaJKHkyzMYH2XJLkryeNJ\njiR566zUl+RN7Xn77u35JB+clfravF9tvxuPJbkzyetmrL4PtNoOnaPn7lNJTiV57DTzk+RjrfZH\nkrzlTB/XWauqVbkxOjH8deBHgfOBrwHbloz5CHBba/8YcLC1Lwfe0to/BPzR0mVXub4Ar2/t84D7\ngatnpb6x+f8G+O/A52fp59umnwIum8XXX5veC/xSa58PXDJL9S1Zz7OMPjM+E/UxukD0GHBhm94P\n/OIM1Xcl8BhwEaPzpr8H/L0p1/c24C3AY6eZ/w7gC+1vydXA/Wf6uM72tpp7AmfyFRLbgN8HqKrH\ngc1J1lfVyar6auv/c+AI07/yeEh9VVX/r405r92mffJl4voAkmwErgM+MeW6plLfCpi4viRvZPRL\n/Mk27ztV9e1ZqW/JmGuAr1fV0zNW31rgwiRrGf2x/eMZqu/vM/qj+5dV9SLwv4F/Os3iqurLwLde\nZcgO4NPtb8l9wCVJLj/Dx3VWVjMEzuQrJL5Ge/KTXAX8CKMLzL4nyWbgzYzebc9Mfe1Qy8PAKeDe\nqpqp+oCPAh8C/nrKdU2rvgJ+L8mDGV1BPkv1bQEWgd9oh9M+keTiGapv3E7gzinXNqi+qjoB/Drw\nTeAk8GdV9cVZqY/RXsA/TPK3k1zE6F35JlbW6eqf+lfvzPqJ4dsZJeDDwPuBh4CXvjszyeuB3wI+\nWFXPz1J9VfVSVf0EoxfVVUuPx69mfUneCZyqqgdXoaZxr/bz/dn2/P0ccHOSt81QfWsZ7cp/vKre\nDPwFsBpfi77c78f5wLuA/7EKtcHpX3/rGL173QL8MHBxknfPSn1VdQT4T8AXgd8FHmbsef1Bs5r/\nVGbZr5Bof9jfA6MTJYyOI36jTZ/HKAA+W1V3z1p9Y2O+neRLwHZG7zBmob5/DrwryTuA1wFvSPKZ\nqprmL+Kg56+9W6SqTiX5HKPd4C/PSH0XAcfH9u7uYvohMI3X388BX62q56Zc29D6rgWOVdVim3c3\n8NPAZ2akPqrqk7TDfUn+I6N33CvpdPWfd5r+yU3zZMdZnhhZy+gJ38LLJziuWDLmEuD81n4vo2Nk\nMDpZ8mngozNa3xztRCFwIfAV4J2zUt+SMW/n3JwYHvL8XQz80Fj7/zL64sGZqK9NfwV4U2v/B+Aj\ns1Rf69sHvGfaP9sp/Hx/CjjEKEzD6CT7+2elvjb9d9r93wUeZ8on/tu6N3P6E8PX8TdPDD9wpo/r\nrOs4Fy+Qs3gS3sHokz1fBz7c+t4HvK+139rmPwHcDaxr/T/L6JjxI4x21R4G3jFD9f04o13LRxi9\n+//3s/T8LVnH2zkHITDw+fvR9uL+Wvtj8eFZqq/N+wlgof2M/+crPberXN/FjL59943n4rmbQn2/\nxuiP62PAfwMumLH6vgIcbq/Ba85BbXcyOh/yV4z2Mm5cUlsY/QOurwOPAvOv9riG3LxiWJI6Nusn\nhiVJ55AhIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSx/4/8cT5qgWLlXIAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0dc850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51797211,  0.78335983,  0.86903497,  0.5182218 ,  0.65445035,\n",
       "        0.55320593,  0.51774836,  0.5200439 ,  0.52055698,  0.52039573,\n",
       "        0.58063741,  0.53931159])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import NaiveBayes\n",
    "\n",
    "# gen_model = NaiveBayes()\n",
    "# %time gen_model.train(L_train, n_iter=2000, rate=1e-3, mu=1e-6)\n",
    "# train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LF_replacement_table', 0.071919431126814079),\n",
      " ('LF_many_p_siblings', 1.2853543633418705),\n",
      " ('LF_part_complement', 1.8924530217959681),\n",
      " ('LF_please_to_left', 0.072919510469992524),\n",
      " ('LF_polarity_transistor_type', 0.63865938030891789),\n",
      " ('LF_polarity_part_tabular_align', 0.21363251726334218),\n",
      " ('LF_polarity_part_horz_align', 0.071023261257863513),\n",
      " ('LF_polarity_part_vert_align', 0.080218582487983039),\n",
      " ('LF_polarity_right_of_part', 0.082274295192983252),\n",
      " ('LF_polarity_in_header_tag', 0.08162820804597419),\n",
      " ('LF_polarity_complement', 0.32539056772145797),\n",
      " ('LF_both_present', 0.15757158391527457)]\n",
      "0.92354492119\n",
      "0.999747466648\n"
     ]
    }
   ],
   "source": [
    "pprint(zip([lf.__name__ for lf in LFs], gen_model.weights.lf_accuracy_log_odds))\n",
    "print min(train_marginals)\n",
    "print max(train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLR] lr=0.001 l1=0.0 l2=0.0\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=1375  #epochs=2000  batch size=100\n",
      "[SparseLR] Epoch 0 (0.51s)\tAvg. loss=0.372103\tNNZ=8442\n",
      "[SparseLR] Epoch 5 (1.64s)\tAvg. loss=0.053669\tNNZ=8442\n",
      "[SparseLR] Epoch 10 (2.77s)\tAvg. loss=0.046929\tNNZ=8442\n",
      "[SparseLR] Epoch 15 (3.90s)\tAvg. loss=0.044322\tNNZ=8442\n",
      "[SparseLR] Epoch 20 (5.15s)\tAvg. loss=0.042844\tNNZ=8442\n",
      "[SparseLR] Epoch 25 (6.30s)\tAvg. loss=0.041842\tNNZ=8442\n",
      "[SparseLR] Epoch 30 (7.46s)\tAvg. loss=0.041110\tNNZ=8442\n",
      "[SparseLR] Epoch 35 (8.74s)\tAvg. loss=0.040547\tNNZ=8442\n",
      "[SparseLR] Epoch 40 (9.91s)\tAvg. loss=0.040093\tNNZ=8442\n",
      "[SparseLR] Epoch 45 (11.11s)\tAvg. loss=0.039716\tNNZ=8442\n",
      "[SparseLR] Epoch 50 (12.29s)\tAvg. loss=0.039395\tNNZ=8442\n",
      "[SparseLR] Epoch 55 (13.57s)\tAvg. loss=0.039119\tNNZ=8442\n",
      "[SparseLR] Epoch 60 (14.72s)\tAvg. loss=0.038880\tNNZ=8442\n",
      "[SparseLR] Epoch 65 (15.88s)\tAvg. loss=0.038671\tNNZ=8442\n",
      "[SparseLR] Epoch 70 (17.17s)\tAvg. loss=0.038489\tNNZ=8442\n",
      "[SparseLR] Epoch 75 (18.35s)\tAvg. loss=0.038328\tNNZ=8442\n",
      "[SparseLR] Epoch 80 (19.58s)\tAvg. loss=0.038185\tNNZ=8442\n",
      "[SparseLR] Epoch 85 (20.82s)\tAvg. loss=0.038059\tNNZ=8442\n",
      "[SparseLR] Epoch 90 (22.14s)\tAvg. loss=0.037947\tNNZ=8442\n",
      "[SparseLR] Epoch 95 (23.31s)\tAvg. loss=0.037847\tNNZ=8442\n",
      "[SparseLR] Epoch 100 (24.50s)\tAvg. loss=0.037758\tNNZ=8442\n",
      "[SparseLR] Epoch 105 (25.77s)\tAvg. loss=0.037678\tNNZ=8442\n",
      "[SparseLR] Epoch 110 (26.93s)\tAvg. loss=0.037606\tNNZ=8442\n",
      "[SparseLR] Epoch 115 (28.09s)\tAvg. loss=0.037541\tNNZ=8442\n",
      "[SparseLR] Epoch 120 (29.30s)\tAvg. loss=0.037482\tNNZ=8442\n",
      "[SparseLR] Epoch 125 (30.65s)\tAvg. loss=0.037429\tNNZ=8442\n",
      "[SparseLR] Epoch 130 (31.91s)\tAvg. loss=0.037381\tNNZ=8442\n",
      "[SparseLR] Epoch 135 (33.14s)\tAvg. loss=0.037337\tNNZ=8442\n",
      "[SparseLR] Epoch 140 (34.35s)\tAvg. loss=0.037297\tNNZ=8442\n",
      "[SparseLR] Epoch 145 (35.68s)\tAvg. loss=0.037261\tNNZ=8442\n",
      "[SparseLR] Epoch 150 (36.87s)\tAvg. loss=0.037228\tNNZ=8442\n",
      "[SparseLR] Epoch 155 (38.06s)\tAvg. loss=0.037197\tNNZ=8442\n",
      "[SparseLR] Epoch 160 (39.35s)\tAvg. loss=0.037170\tNNZ=8442\n",
      "[SparseLR] Epoch 165 (40.55s)\tAvg. loss=0.037144\tNNZ=8442\n",
      "[SparseLR] Epoch 170 (41.76s)\tAvg. loss=0.037120\tNNZ=8442\n",
      "[SparseLR] Epoch 175 (42.97s)\tAvg. loss=0.037098\tNNZ=8442\n",
      "[SparseLR] Epoch 180 (44.29s)\tAvg. loss=0.037078\tNNZ=8442\n",
      "[SparseLR] Epoch 185 (45.52s)\tAvg. loss=0.037060\tNNZ=8442\n",
      "[SparseLR] Epoch 190 (46.72s)\tAvg. loss=0.037043\tNNZ=8442\n",
      "[SparseLR] Epoch 195 (48.02s)\tAvg. loss=0.037027\tNNZ=8442\n",
      "[SparseLR] Epoch 200 (49.19s)\tAvg. loss=0.037012\tNNZ=8442\n",
      "[SparseLR] Epoch 205 (50.36s)\tAvg. loss=0.036998\tNNZ=8442\n",
      "[SparseLR] Epoch 210 (51.52s)\tAvg. loss=0.036986\tNNZ=8442\n",
      "[SparseLR] Epoch 215 (52.79s)\tAvg. loss=0.036974\tNNZ=8442\n",
      "[SparseLR] Epoch 220 (54.00s)\tAvg. loss=0.036963\tNNZ=8442\n",
      "[SparseLR] Epoch 225 (55.20s)\tAvg. loss=0.036952\tNNZ=8442\n",
      "[SparseLR] Epoch 230 (56.49s)\tAvg. loss=0.036943\tNNZ=8442\n",
      "[SparseLR] Epoch 235 (57.72s)\tAvg. loss=0.036934\tNNZ=8442\n",
      "[SparseLR] Epoch 240 (58.95s)\tAvg. loss=0.036926\tNNZ=8442\n",
      "[SparseLR] Epoch 245 (60.16s)\tAvg. loss=0.036918\tNNZ=8442\n",
      "[SparseLR] Epoch 250 (61.42s)\tAvg. loss=0.036910\tNNZ=8442\n",
      "[SparseLR] Epoch 255 (62.59s)\tAvg. loss=0.036904\tNNZ=8442\n",
      "[SparseLR] Epoch 260 (63.76s)\tAvg. loss=0.036897\tNNZ=8442\n",
      "[SparseLR] Epoch 265 (65.03s)\tAvg. loss=0.036891\tNNZ=8442\n",
      "[SparseLR] Epoch 270 (66.24s)\tAvg. loss=0.036886\tNNZ=8442\n",
      "[SparseLR] Epoch 275 (67.42s)\tAvg. loss=0.036880\tNNZ=8442\n",
      "[SparseLR] Epoch 280 (68.60s)\tAvg. loss=0.036875\tNNZ=8442\n",
      "[SparseLR] Epoch 285 (69.89s)\tAvg. loss=0.036871\tNNZ=8442\n",
      "[SparseLR] Epoch 290 (71.04s)\tAvg. loss=0.036866\tNNZ=8442\n",
      "[SparseLR] Epoch 295 (72.19s)\tAvg. loss=0.036862\tNNZ=8442\n",
      "[SparseLR] Epoch 300 (73.47s)\tAvg. loss=0.036859\tNNZ=8442\n",
      "[SparseLR] Epoch 305 (74.65s)\tAvg. loss=0.036855\tNNZ=8442\n",
      "[SparseLR] Epoch 310 (75.86s)\tAvg. loss=0.036852\tNNZ=8442\n",
      "[SparseLR] Epoch 315 (77.06s)\tAvg. loss=0.036848\tNNZ=8442\n",
      "[SparseLR] Epoch 320 (78.37s)\tAvg. loss=0.036845\tNNZ=8442\n",
      "[SparseLR] Epoch 325 (79.57s)\tAvg. loss=0.036843\tNNZ=8442\n",
      "[SparseLR] Epoch 330 (80.76s)\tAvg. loss=0.036840\tNNZ=8442\n",
      "[SparseLR] Epoch 335 (82.06s)\tAvg. loss=0.036838\tNNZ=8442\n",
      "[SparseLR] Epoch 340 (83.29s)\tAvg. loss=0.036835\tNNZ=8442\n",
      "[SparseLR] Epoch 345 (84.52s)\tAvg. loss=0.036833\tNNZ=8442\n",
      "[SparseLR] Epoch 350 (85.73s)\tAvg. loss=0.036831\tNNZ=8442\n",
      "[SparseLR] Epoch 355 (87.04s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 360 (88.22s)\tAvg. loss=0.036828\tNNZ=8442\n",
      "[SparseLR] Epoch 365 (89.37s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 370 (90.64s)\tAvg. loss=0.036824\tNNZ=8442\n",
      "[SparseLR] Epoch 375 (91.81s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 380 (92.99s)\tAvg. loss=0.036821\tNNZ=8442\n",
      "[SparseLR] Epoch 385 (94.15s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 390 (95.44s)\tAvg. loss=0.036819\tNNZ=8442\n",
      "[SparseLR] Epoch 395 (96.64s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 400 (97.84s)\tAvg. loss=0.036817\tNNZ=8442\n",
      "[SparseLR] Epoch 405 (99.13s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 410 (100.33s)\tAvg. loss=0.036815\tNNZ=8442\n",
      "[SparseLR] Epoch 415 (101.53s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 420 (102.71s)\tAvg. loss=0.036813\tNNZ=8442\n",
      "[SparseLR] Epoch 425 (104.01s)\tAvg. loss=0.036812\tNNZ=8442\n",
      "[SparseLR] Epoch 430 (105.21s)\tAvg. loss=0.036811\tNNZ=8442\n",
      "[SparseLR] Epoch 435 (106.51s)\tAvg. loss=0.036810\tNNZ=8442\n",
      "[SparseLR] Epoch 440 (108.03s)\tAvg. loss=0.036810\tNNZ=8442\n",
      "[SparseLR] Epoch 445 (109.52s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 450 (111.04s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 455 (112.46s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 460 (113.88s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 465 (115.11s)\tAvg. loss=0.036846\tNNZ=8442\n",
      "[SparseLR] Epoch 470 (116.31s)\tAvg. loss=0.037170\tNNZ=8442\n",
      "[SparseLR] Epoch 475 (117.61s)\tAvg. loss=0.036838\tNNZ=8442\n",
      "[SparseLR] Epoch 480 (118.80s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 485 (119.99s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 490 (121.15s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 495 (122.42s)\tAvg. loss=0.036804\tNNZ=8442\n",
      "[SparseLR] Epoch 500 (123.63s)\tAvg. loss=0.036804\tNNZ=8442\n",
      "[SparseLR] Epoch 505 (124.82s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 510 (126.11s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 515 (127.33s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 520 (128.55s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 525 (129.78s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 530 (131.10s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 535 (132.30s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 540 (133.46s)\tAvg. loss=0.037150\tNNZ=8442\n",
      "[SparseLR] Epoch 545 (134.72s)\tAvg. loss=0.036883\tNNZ=8442\n",
      "[SparseLR] Epoch 550 (135.92s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 555 (137.11s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 560 (138.34s)\tAvg. loss=0.036800\tNNZ=8442\n",
      "[SparseLR] Epoch 565 (139.66s)\tAvg. loss=0.036800\tNNZ=8442\n",
      "[SparseLR] Epoch 570 (140.88s)\tAvg. loss=0.036800\tNNZ=8442\n",
      "[SparseLR] Epoch 575 (142.10s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 580 (143.40s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 585 (144.59s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 590 (145.79s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 595 (146.98s)\tAvg. loss=0.036813\tNNZ=8442\n",
      "[SparseLR] Epoch 600 (148.30s)\tAvg. loss=0.036921\tNNZ=8442\n",
      "[SparseLR] Epoch 605 (149.53s)\tAvg. loss=0.037130\tNNZ=8442\n",
      "[SparseLR] Epoch 610 (150.73s)\tAvg. loss=0.036842\tNNZ=8442\n",
      "[SparseLR] Epoch 615 (152.02s)\tAvg. loss=0.036804\tNNZ=8442\n",
      "[SparseLR] Epoch 620 (153.24s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 625 (154.46s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 630 (155.69s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 635 (157.00s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 640 (158.20s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 645 (159.40s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 650 (160.60s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 655 (161.89s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 660 (163.07s)\tAvg. loss=0.036939\tNNZ=8442\n",
      "[SparseLR] Epoch 665 (164.26s)\tAvg. loss=0.036999\tNNZ=8442\n",
      "[SparseLR] Epoch 670 (165.58s)\tAvg. loss=0.036854\tNNZ=8442\n",
      "[SparseLR] Epoch 675 (166.80s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 680 (168.01s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 685 (169.19s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 690 (170.49s)\tAvg. loss=0.036796\tNNZ=8442\n",
      "[SparseLR] Epoch 695 (171.68s)\tAvg. loss=0.036796\tNNZ=8442\n",
      "[SparseLR] Epoch 700 (172.87s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 705 (174.20s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 710 (175.50s)\tAvg. loss=0.036812\tNNZ=8442\n",
      "[SparseLR] Epoch 715 (176.82s)\tAvg. loss=0.036878\tNNZ=8442\n",
      "[SparseLR] Epoch 720 (178.14s)\tAvg. loss=0.037032\tNNZ=8442\n",
      "[SparseLR] Epoch 725 (179.49s)\tAvg. loss=0.036871\tNNZ=8442\n",
      "[SparseLR] Epoch 730 (180.69s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 735 (181.88s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 740 (183.22s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 745 (184.51s)\tAvg. loss=0.036796\tNNZ=8442\n",
      "[SparseLR] Epoch 750 (185.75s)\tAvg. loss=0.036796\tNNZ=8442\n",
      "[SparseLR] Epoch 755 (186.95s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 760 (188.29s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 765 (189.59s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 770 (190.88s)\tAvg. loss=0.036852\tNNZ=8442\n",
      "[SparseLR] Epoch 775 (192.26s)\tAvg. loss=0.037004\tNNZ=8442\n",
      "[SparseLR] Epoch 780 (193.57s)\tAvg. loss=0.036910\tNNZ=8442\n",
      "[SparseLR] Epoch 785 (194.86s)\tAvg. loss=0.036813\tNNZ=8442\n",
      "[SparseLR] Epoch 790 (196.11s)\tAvg. loss=0.036802\tNNZ=8442\n",
      "[SparseLR] Epoch 795 (197.41s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 800 (198.60s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 805 (199.83s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 810 (201.16s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 815 (202.38s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 820 (203.66s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 825 (204.92s)\tAvg. loss=0.036891\tNNZ=8442\n",
      "[SparseLR] Epoch 830 (206.27s)\tAvg. loss=0.036959\tNNZ=8442\n",
      "[SparseLR] Epoch 835 (207.48s)\tAvg. loss=0.036887\tNNZ=8442\n",
      "[SparseLR] Epoch 840 (208.67s)\tAvg. loss=0.036812\tNNZ=8442\n",
      "[SparseLR] Epoch 845 (209.94s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 850 (211.11s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 855 (212.30s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 860 (213.49s)\tAvg. loss=0.036796\tNNZ=8442\n",
      "[SparseLR] Epoch 865 (214.79s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 870 (215.98s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 875 (217.18s)\tAvg. loss=0.036830\tNNZ=8442\n",
      "[SparseLR] Epoch 880 (218.50s)\tAvg. loss=0.036923\tNNZ=8442\n",
      "[SparseLR] Epoch 885 (219.72s)\tAvg. loss=0.036938\tNNZ=8442\n",
      "[SparseLR] Epoch 890 (220.92s)\tAvg. loss=0.036821\tNNZ=8442\n",
      "[SparseLR] Epoch 895 (222.12s)\tAvg. loss=0.036806\tNNZ=8442\n",
      "[SparseLR] Epoch 900 (223.43s)\tAvg. loss=0.036800\tNNZ=8442\n",
      "[SparseLR] Epoch 905 (224.62s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 910 (225.81s)\tAvg. loss=0.036797\tNNZ=8442\n",
      "[SparseLR] Epoch 915 (227.09s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 920 (228.30s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 925 (229.51s)\tAvg. loss=0.036838\tNNZ=8442\n",
      "[SparseLR] Epoch 930 (230.74s)\tAvg. loss=0.036935\tNNZ=8442\n",
      "[SparseLR] Epoch 935 (232.07s)\tAvg. loss=0.036947\tNNZ=8442\n",
      "[SparseLR] Epoch 940 (233.28s)\tAvg. loss=0.036836\tNNZ=8442\n",
      "[SparseLR] Epoch 945 (234.49s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 950 (235.78s)\tAvg. loss=0.036800\tNNZ=8442\n",
      "[SparseLR] Epoch 955 (236.97s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 960 (238.18s)\tAvg. loss=0.036798\tNNZ=8442\n",
      "[SparseLR] Epoch 965 (239.36s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 970 (240.68s)\tAvg. loss=0.036811\tNNZ=8442\n",
      "[SparseLR] Epoch 975 (241.91s)\tAvg. loss=0.036844\tNNZ=8442\n",
      "[SparseLR] Epoch 980 (243.14s)\tAvg. loss=0.036924\tNNZ=8442\n",
      "[SparseLR] Epoch 985 (244.48s)\tAvg. loss=0.036919\tNNZ=8442\n",
      "[SparseLR] Epoch 990 (245.70s)\tAvg. loss=0.036851\tNNZ=8442\n",
      "[SparseLR] Epoch 995 (246.91s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1000 (248.11s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 1005 (249.43s)\tAvg. loss=0.036799\tNNZ=8442\n",
      "[SparseLR] Epoch 1010 (250.63s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 1015 (251.85s)\tAvg. loss=0.036806\tNNZ=8442\n",
      "[SparseLR] Epoch 1020 (253.15s)\tAvg. loss=0.036819\tNNZ=8442\n",
      "[SparseLR] Epoch 1025 (254.35s)\tAvg. loss=0.036855\tNNZ=8442\n",
      "[SparseLR] Epoch 1030 (255.56s)\tAvg. loss=0.036904\tNNZ=8442\n",
      "[SparseLR] Epoch 1035 (256.77s)\tAvg. loss=0.036879\tNNZ=8442\n",
      "[SparseLR] Epoch 1040 (258.07s)\tAvg. loss=0.036848\tNNZ=8442\n",
      "[SparseLR] Epoch 1045 (259.26s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 1050 (260.47s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 1055 (261.78s)\tAvg. loss=0.036801\tNNZ=8442\n",
      "[SparseLR] Epoch 1060 (262.95s)\tAvg. loss=0.036803\tNNZ=8442\n",
      "[SparseLR] Epoch 1065 (264.16s)\tAvg. loss=0.036810\tNNZ=8442\n",
      "[SparseLR] Epoch 1070 (265.37s)\tAvg. loss=0.036828\tNNZ=8442\n",
      "[SparseLR] Epoch 1075 (266.68s)\tAvg. loss=0.036868\tNNZ=8442\n",
      "[SparseLR] Epoch 1080 (267.87s)\tAvg. loss=0.036894\tNNZ=8442\n",
      "[SparseLR] Epoch 1085 (269.05s)\tAvg. loss=0.036883\tNNZ=8442\n",
      "[SparseLR] Epoch 1090 (270.34s)\tAvg. loss=0.036831\tNNZ=8442\n",
      "[SparseLR] Epoch 1095 (271.53s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 1100 (272.74s)\tAvg. loss=0.036802\tNNZ=8442\n",
      "[SparseLR] Epoch 1105 (273.96s)\tAvg. loss=0.036804\tNNZ=8442\n",
      "[SparseLR] Epoch 1110 (275.27s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 1115 (276.50s)\tAvg. loss=0.036819\tNNZ=8442\n",
      "[SparseLR] Epoch 1120 (277.73s)\tAvg. loss=0.036843\tNNZ=8442\n",
      "[SparseLR] Epoch 1125 (278.94s)\tAvg. loss=0.036873\tNNZ=8442\n",
      "[SparseLR] Epoch 1130 (280.23s)\tAvg. loss=0.036885\tNNZ=8442\n",
      "[SparseLR] Epoch 1135 (281.40s)\tAvg. loss=0.036854\tNNZ=8442\n",
      "[SparseLR] Epoch 1140 (282.61s)\tAvg. loss=0.036812\tNNZ=8442\n",
      "[SparseLR] Epoch 1145 (283.91s)\tAvg. loss=0.036804\tNNZ=8442\n",
      "[SparseLR] Epoch 1150 (285.13s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 1155 (286.33s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 1160 (287.54s)\tAvg. loss=0.036815\tNNZ=8442\n",
      "[SparseLR] Epoch 1165 (288.86s)\tAvg. loss=0.036832\tNNZ=8442\n",
      "[SparseLR] Epoch 1170 (290.07s)\tAvg. loss=0.036860\tNNZ=8442\n",
      "[SparseLR] Epoch 1175 (291.28s)\tAvg. loss=0.036881\tNNZ=8442\n",
      "[SparseLR] Epoch 1180 (292.56s)\tAvg. loss=0.036872\tNNZ=8442\n",
      "[SparseLR] Epoch 1185 (293.75s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1190 (294.97s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 1195 (296.25s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 1200 (297.62s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 1205 (298.87s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 1210 (300.10s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1215 (301.41s)\tAvg. loss=0.036857\tNNZ=8442\n",
      "[SparseLR] Epoch 1220 (302.62s)\tAvg. loss=0.036877\tNNZ=8442\n",
      "[SparseLR] Epoch 1225 (303.79s)\tAvg. loss=0.036890\tNNZ=8442\n",
      "[SparseLR] Epoch 1230 (304.98s)\tAvg. loss=0.036842\tNNZ=8442\n",
      "[SparseLR] Epoch 1235 (306.31s)\tAvg. loss=0.036810\tNNZ=8442\n",
      "[SparseLR] Epoch 1240 (307.52s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 1245 (308.73s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 1250 (310.08s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1255 (311.39s)\tAvg. loss=0.036833\tNNZ=8442\n",
      "[SparseLR] Epoch 1260 (312.65s)\tAvg. loss=0.036857\tNNZ=8442\n",
      "[SparseLR] Epoch 1265 (313.87s)\tAvg. loss=0.036864\tNNZ=8442\n",
      "[SparseLR] Epoch 1270 (315.17s)\tAvg. loss=0.036863\tNNZ=8442\n",
      "[SparseLR] Epoch 1275 (316.35s)\tAvg. loss=0.036840\tNNZ=8442\n",
      "[SparseLR] Epoch 1280 (317.56s)\tAvg. loss=0.036813\tNNZ=8442\n",
      "[SparseLR] Epoch 1285 (318.90s)\tAvg. loss=0.036805\tNNZ=8442\n",
      "[SparseLR] Epoch 1290 (320.15s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 1295 (321.38s)\tAvg. loss=0.036817\tNNZ=8442\n",
      "[SparseLR] Epoch 1300 (322.64s)\tAvg. loss=0.036836\tNNZ=8442\n",
      "[SparseLR] Epoch 1305 (324.01s)\tAvg. loss=0.036864\tNNZ=8442\n",
      "[SparseLR] Epoch 1310 (325.25s)\tAvg. loss=0.036869\tNNZ=8442\n",
      "[SparseLR] Epoch 1315 (326.52s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1320 (327.85s)\tAvg. loss=0.036843\tNNZ=8442\n",
      "[SparseLR] Epoch 1325 (329.08s)\tAvg. loss=0.036817\tNNZ=8442\n",
      "[SparseLR] Epoch 1330 (330.28s)\tAvg. loss=0.036806\tNNZ=8442\n",
      "[SparseLR] Epoch 1335 (331.48s)\tAvg. loss=0.036807\tNNZ=8442\n",
      "[SparseLR] Epoch 1340 (332.79s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1345 (334.00s)\tAvg. loss=0.036834\tNNZ=8442\n",
      "[SparseLR] Epoch 1350 (335.21s)\tAvg. loss=0.036861\tNNZ=8442\n",
      "[SparseLR] Epoch 1355 (336.53s)\tAvg. loss=0.036869\tNNZ=8442\n",
      "[SparseLR] Epoch 1360 (337.76s)\tAvg. loss=0.036849\tNNZ=8442\n",
      "[SparseLR] Epoch 1365 (339.03s)\tAvg. loss=0.036843\tNNZ=8442\n",
      "[SparseLR] Epoch 1370 (340.28s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1375 (341.62s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 1380 (342.85s)\tAvg. loss=0.036809\tNNZ=8442\n",
      "[SparseLR] Epoch 1385 (344.05s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1390 (345.38s)\tAvg. loss=0.036834\tNNZ=8442\n",
      "[SparseLR] Epoch 1395 (346.58s)\tAvg. loss=0.036865\tNNZ=8442\n",
      "[SparseLR] Epoch 1400 (347.80s)\tAvg. loss=0.036877\tNNZ=8442\n",
      "[SparseLR] Epoch 1405 (349.00s)\tAvg. loss=0.036852\tNNZ=8442\n",
      "[SparseLR] Epoch 1410 (350.32s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1415 (351.54s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1420 (352.74s)\tAvg. loss=0.036811\tNNZ=8442\n",
      "[SparseLR] Epoch 1425 (354.05s)\tAvg. loss=0.036808\tNNZ=8442\n",
      "[SparseLR] Epoch 1430 (355.26s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 1435 (356.48s)\tAvg. loss=0.036832\tNNZ=8442\n",
      "[SparseLR] Epoch 1440 (357.68s)\tAvg. loss=0.036863\tNNZ=8442\n",
      "[SparseLR] Epoch 1445 (358.99s)\tAvg. loss=0.036877\tNNZ=8442\n",
      "[SparseLR] Epoch 1450 (360.21s)\tAvg. loss=0.036845\tNNZ=8442\n",
      "[SparseLR] Epoch 1455 (361.43s)\tAvg. loss=0.036832\tNNZ=8442\n",
      "[SparseLR] Epoch 1460 (362.74s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1465 (363.90s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1470 (365.07s)\tAvg. loss=0.036811\tNNZ=8442\n",
      "[SparseLR] Epoch 1475 (366.27s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 1480 (367.59s)\tAvg. loss=0.036830\tNNZ=8442\n",
      "[SparseLR] Epoch 1485 (368.79s)\tAvg. loss=0.036860\tNNZ=8442\n",
      "[SparseLR] Epoch 1490 (370.00s)\tAvg. loss=0.036877\tNNZ=8442\n",
      "[SparseLR] Epoch 1495 (371.29s)\tAvg. loss=0.036848\tNNZ=8442\n",
      "[SparseLR] Epoch 1500 (372.50s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1505 (373.71s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1510 (374.91s)\tAvg. loss=0.036819\tNNZ=8442\n",
      "[SparseLR] Epoch 1515 (376.21s)\tAvg. loss=0.036814\tNNZ=8442\n",
      "[SparseLR] Epoch 1520 (377.43s)\tAvg. loss=0.036815\tNNZ=8442\n",
      "[SparseLR] Epoch 1525 (378.65s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1530 (379.96s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1535 (381.13s)\tAvg. loss=0.036878\tNNZ=8442\n",
      "[SparseLR] Epoch 1540 (382.30s)\tAvg. loss=0.036851\tNNZ=8442\n",
      "[SparseLR] Epoch 1545 (383.51s)\tAvg. loss=0.036824\tNNZ=8442\n",
      "[SparseLR] Epoch 1550 (384.83s)\tAvg. loss=0.036821\tNNZ=8442\n",
      "[SparseLR] Epoch 1555 (386.03s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 1560 (387.27s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 1565 (388.60s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 1570 (389.79s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1575 (390.97s)\tAvg. loss=0.036847\tNNZ=8442\n",
      "[SparseLR] Epoch 1580 (392.14s)\tAvg. loss=0.036873\tNNZ=8442\n",
      "[SparseLR] Epoch 1585 (393.42s)\tAvg. loss=0.036858\tNNZ=8442\n",
      "[SparseLR] Epoch 1590 (394.61s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1595 (395.81s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 1600 (397.11s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1605 (398.31s)\tAvg. loss=0.036824\tNNZ=8442\n",
      "[SparseLR] Epoch 1610 (399.53s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1615 (400.78s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1620 (402.10s)\tAvg. loss=0.036842\tNNZ=8442\n",
      "[SparseLR] Epoch 1625 (403.32s)\tAvg. loss=0.036862\tNNZ=8442\n",
      "[SparseLR] Epoch 1630 (404.53s)\tAvg. loss=0.036855\tNNZ=8442\n",
      "[SparseLR] Epoch 1635 (405.73s)\tAvg. loss=0.036827\tNNZ=8442\n",
      "[SparseLR] Epoch 1640 (407.01s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1645 (408.21s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 1650 (409.40s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1655 (410.68s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1660 (411.88s)\tAvg. loss=0.036834\tNNZ=8442\n",
      "[SparseLR] Epoch 1665 (413.08s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1670 (414.32s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1675 (415.65s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1680 (417.12s)\tAvg. loss=0.036828\tNNZ=8442\n",
      "[SparseLR] Epoch 1685 (418.95s)\tAvg. loss=0.036815\tNNZ=8442\n",
      "[SparseLR] Epoch 1690 (420.58s)\tAvg. loss=0.036817\tNNZ=8442\n",
      "[SparseLR] Epoch 1695 (421.94s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1700 (423.21s)\tAvg. loss=0.036837\tNNZ=8442\n",
      "[SparseLR] Epoch 1705 (424.41s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1710 (425.70s)\tAvg. loss=0.036845\tNNZ=8442\n",
      "[SparseLR] Epoch 1715 (426.93s)\tAvg. loss=0.036846\tNNZ=8442\n",
      "[SparseLR] Epoch 1720 (428.20s)\tAvg. loss=0.036850\tNNZ=8442\n",
      "[SparseLR] Epoch 1725 (429.57s)\tAvg. loss=0.036830\tNNZ=8442\n",
      "[SparseLR] Epoch 1730 (430.82s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1735 (432.06s)\tAvg. loss=0.036816\tNNZ=8442\n",
      "[SparseLR] Epoch 1740 (433.26s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1745 (434.54s)\tAvg. loss=0.036840\tNNZ=8442\n",
      "[SparseLR] Epoch 1750 (435.72s)\tAvg. loss=0.036850\tNNZ=8442\n",
      "[SparseLR] Epoch 1755 (436.91s)\tAvg. loss=0.036846\tNNZ=8442\n",
      "[SparseLR] Epoch 1760 (438.26s)\tAvg. loss=0.036840\tNNZ=8442\n",
      "[SparseLR] Epoch 1765 (439.50s)\tAvg. loss=0.036842\tNNZ=8442\n",
      "[SparseLR] Epoch 1770 (440.75s)\tAvg. loss=0.036832\tNNZ=8442\n",
      "[SparseLR] Epoch 1775 (441.95s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 1780 (443.27s)\tAvg. loss=0.036815\tNNZ=8442\n",
      "[SparseLR] Epoch 1785 (444.50s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1790 (445.71s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1795 (447.01s)\tAvg. loss=0.036858\tNNZ=8442\n",
      "[SparseLR] Epoch 1800 (448.20s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1805 (449.37s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1810 (450.56s)\tAvg. loss=0.036835\tNNZ=8442\n",
      "[SparseLR] Epoch 1815 (451.88s)\tAvg. loss=0.036833\tNNZ=8442\n",
      "[SparseLR] Epoch 1820 (453.08s)\tAvg. loss=0.036822\tNNZ=8442\n",
      "[SparseLR] Epoch 1825 (454.28s)\tAvg. loss=0.036817\tNNZ=8442\n",
      "[SparseLR] Epoch 1830 (455.58s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 1835 (456.78s)\tAvg. loss=0.036838\tNNZ=8442\n",
      "[SparseLR] Epoch 1840 (457.97s)\tAvg. loss=0.036859\tNNZ=8442\n",
      "[SparseLR] Epoch 1845 (459.17s)\tAvg. loss=0.036857\tNNZ=8442\n",
      "[SparseLR] Epoch 1850 (460.47s)\tAvg. loss=0.036837\tNNZ=8442\n",
      "[SparseLR] Epoch 1855 (461.67s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1860 (462.84s)\tAvg. loss=0.036831\tNNZ=8442\n",
      "[SparseLR] Epoch 1865 (464.10s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1870 (465.28s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Epoch 1875 (466.49s)\tAvg. loss=0.036820\tNNZ=8442\n",
      "[SparseLR] Epoch 1880 (467.70s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1885 (469.03s)\tAvg. loss=0.036866\tNNZ=8442\n",
      "[SparseLR] Epoch 1890 (470.24s)\tAvg. loss=0.036873\tNNZ=8442\n",
      "[SparseLR] Epoch 1895 (471.42s)\tAvg. loss=0.036836\tNNZ=8442\n",
      "[SparseLR] Epoch 1900 (472.70s)\tAvg. loss=0.036824\tNNZ=8442\n",
      "[SparseLR] Epoch 1905 (473.88s)\tAvg. loss=0.036826\tNNZ=8442\n",
      "[SparseLR] Epoch 1910 (475.06s)\tAvg. loss=0.036828\tNNZ=8442\n",
      "[SparseLR] Epoch 1915 (476.26s)\tAvg. loss=0.036825\tNNZ=8442\n",
      "[SparseLR] Epoch 1920 (477.64s)\tAvg. loss=0.036823\tNNZ=8442\n",
      "[SparseLR] Epoch 1925 (478.89s)\tAvg. loss=0.036832\tNNZ=8442\n",
      "[SparseLR] Epoch 1930 (480.10s)\tAvg. loss=0.036853\tNNZ=8442\n",
      "[SparseLR] Epoch 1935 (481.41s)\tAvg. loss=0.036860\tNNZ=8442\n",
      "[SparseLR] Epoch 1940 (482.63s)\tAvg. loss=0.036838\tNNZ=8442\n",
      "[SparseLR] Epoch 1945 (483.98s)\tAvg. loss=0.036822\tNNZ=8442\n",
      "[SparseLR] Epoch 1950 (485.30s)\tAvg. loss=0.036824\tNNZ=8442\n",
      "[SparseLR] Epoch 1955 (486.66s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1960 (487.86s)\tAvg. loss=0.036829\tNNZ=8442\n",
      "[SparseLR] Epoch 1965 (489.03s)\tAvg. loss=0.036827\tNNZ=8442\n",
      "[SparseLR] Epoch 1970 (490.32s)\tAvg. loss=0.036830\tNNZ=8442\n",
      "[SparseLR] Epoch 1975 (491.49s)\tAvg. loss=0.036847\tNNZ=8442\n",
      "[SparseLR] Epoch 1980 (492.67s)\tAvg. loss=0.036859\tNNZ=8442\n",
      "[SparseLR] Epoch 1985 (493.86s)\tAvg. loss=0.036841\tNNZ=8442\n",
      "[SparseLR] Epoch 1990 (495.16s)\tAvg. loss=0.036822\tNNZ=8442\n",
      "[SparseLR] Epoch 1995 (496.38s)\tAvg. loss=0.036821\tNNZ=8442\n",
      "[SparseLR] Epoch 1999 (497.35s)\tAvg. loss=0.036818\tNNZ=8442\n",
      "[SparseLR] Training done (497.35s)\n",
      "CPU times: user 9min 22s, sys: 45.4 s, total: 10min 7s\n",
      "Wall time: 8min 17s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=2000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import LogReg\n",
    "\n",
    "# disc_model = LogReg()\n",
    "# %time disc_model.train(F_train, train_marginals, n_iter=10000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Dev Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4977, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fonduer.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Dev Labels -- Gold')\n",
    "L_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.988\n",
      "Recall               1.0\n",
      "F1                   0.994\n",
      "----------------------------------------\n",
      "TP: 4915 | FP: 62 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(session, F_dev, L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.965\n",
      "Corpus Recall    0.868\n",
      "Corpus F1        0.914\n",
      "----------------------------------------\n",
      "TP: 275 | FP: 10 | FN: 42\n",
      "========================================\n",
      "\n",
      "CPU times: user 7.2 s, sys: 367 ms, total: 7.57 s\n",
      "Wall time: 8.86 s\n",
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.923\n",
      "Corpus Recall    0.978\n",
      "Corpus F1        0.949\n",
      "----------------------------------------\n",
      "TP: 310 | FP: 26 | FN: 7\n",
      "========================================\n",
      "\n",
      "CPU times: user 391 ms, sys: 120 ms, total: 512 ms\n",
      "Wall time: 450 ms\n"
     ]
    }
   ],
   "source": [
    "from fonduer.models import Corpus\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Dev').one()\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=None)\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.939\n",
      "Corpus Recall    0.978\n",
      "Corpus F1        0.958\n",
      "----------------------------------------\n",
      "TP: 310 | FP: 20 | FN: 7\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from fonduer.models import Corpus\n",
    "\n",
    "parts_by_doc = get_gold_parts_by_doc()\n",
    "(TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.412\n",
      "Neg. class accuracy: 0.594\n",
      "Precision            0.85\n",
      "Recall               0.412\n",
      "F1                   0.555\n",
      "----------------------------------------\n",
      "TP: 1220 | FP: 215 | TN: 314 | FN: 1741\n",
      "========================================\n",
      "\n",
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.573\n",
      "Corpus Recall    0.869\n",
      "Corpus F1        0.691\n",
      "----------------------------------------\n",
      "TP: 106 | FP: 79 | FN: 16\n",
      "========================================\n",
      "\n",
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.58\n",
      "Corpus Recall    0.893\n",
      "Corpus F1        0.703\n",
      "----------------------------------------\n",
      "TP: 109 | FP: 79 | FN: 13\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TEST_SIZE:\n",
    "    from fonduer.annotations import LabelManager\n",
    "    label_manager = LabelManager()\n",
    "    L_test = label_manager.load(session, test, 'Hardware Test Labels -- Gold')\n",
    "    L_test.shape\n",
    "    \n",
    "    tp, fp, tn, fn = disc_model.score(session, F_test, L_test, b=0.91)\n",
    "    \n",
    "    from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "    from fonduer.models import Corpus\n",
    "\n",
    "    corpus = get_ORM_instance(Corpus, session, 'Hardware Test')\n",
    "\n",
    "    # parts_by_doc_test = get_manual_parts_by_doc(corpus.documents.all())\n",
    "    # parts_by_doc_test = None\n",
    "    import cPickle as pickle\n",
    "    pickle_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/sandbox/parts_by_doc_test.pkl'\n",
    "    with open(pickle_file, 'r') as f:\n",
    "        parts_by_doc_test = pickle.load(f)\n",
    "\n",
    "    from hardware_utils import entity_level_f1\n",
    "\n",
    "    gold_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus)\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
