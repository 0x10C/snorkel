{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARDWARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "To change attributes:\n",
    "1) Change ATTRIBUTE and you're good to go\n",
    "\"\"\"\n",
    "ATTRIBUTE = 'polarity'\n",
    "COUNTER = '_new'\n",
    "PARALLEL = 4\n",
    "PARALLEL_F = 10\n",
    "PARALLEL_EXTRACTION = 8\n",
    "TRAIN_SIZE = 25\n",
    "DEV_SIZE = 25\n",
    "TEST_SIZE = 25\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "os.environ['SNORKELDB'] = 'postgres://localhost:5432/'# + os.environ['SNORKELDBNAME']\n",
    "        \n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/')\n",
    "snorkel_postgres = os.environ['SNORKELDB'].startswith('postgres')\n",
    "print snorkel_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "0\n",
      "SNORKELDBNAME = polarity_new2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "#     os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER) +'2'\n",
    "    print os.system(\"dropdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print os.system(\"createdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print \"SNORKELDBNAME = %s\" % os.environ['SNORKELDBNAME']\n",
    "else:\n",
    "    try:\n",
    "        os.remove('snorkel.db')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "from fonduer import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async parse...\n",
      "[========================================] 100%\n",
      "CPU times: user 88 ms, sys: 20 ms, total: 108 ms\n",
      "Wall time: 15.1 s\n",
      "Corpus (Hardware Train) contains 25 documents\n",
      "[========================================] 100%\n",
      "CPU times: user 36 ms, sys: 8 ms, total: 44 ms\n",
      "Wall time: 6 s\n",
      "Corpus (Hardware Dev) contains 25 documents\n",
      "[========================================] 100%\n",
      "CPU times: user 40 ms, sys: 8 ms, total: 48 ms\n",
      "Wall time: 6.22 s\n",
      "Corpus (Hardware Test) contains 25 documents\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_parser import parse_corpus, HTMLParser, AsyncOmniParser\n",
    "    print \"Starting async parse...\"\n",
    "    \n",
    "    # PARSE TRAIN\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_digikey/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/train_digikey/pdf/'\n",
    "    doc_preprocessor = HTMLParser()\n",
    "    corpus_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True)\n",
    "    %time corpus = corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, 'Hardware Train',\\\n",
    "                                max_docs=TRAIN_SIZE, parallel=PARALLEL)\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "    session.commit()\n",
    "    # PARSE DEV\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/pdf/'\n",
    "    %time corpus = corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, 'Hardware Dev',\\\n",
    "                                max_docs=DEV_SIZE, parallel=PARALLEL)\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "    session.commit()\n",
    "    if TEST_SIZE:\n",
    "        # PARSE TEST\n",
    "        docs_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/html/'\n",
    "        pdf_path = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/pdf/'\n",
    "        %time corpus = corpus_parser.apply(doc_preprocessor, docs_path, pdf_path, session, 'Hardware Test',\\\n",
    "                                    max_docs=TEST_SIZE, parallel=PARALLEL)\n",
    "        print \"%s contains %d documents\" % (corpus, len(corpus))\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import candidate_subclass\n",
    "\n",
    "Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# session.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using combined matcher.\n"
     ]
    }
   ],
   "source": [
    "from hardware_matchers import get_matcher\n",
    "\n",
    "dict_path = os.environ['SNORKELHOME'] +\\\n",
    "    '/fonduer_tutorials/tables/data/hardware/gold_raw/digikey_part_dictionary.csv'\n",
    "part_matcher = get_matcher('part', dict_path)\n",
    "attr_matcher = get_matcher(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_spaces import get_space\n",
    "    \n",
    "part_ngrams = get_space('part')\n",
    "attr_ngrams = get_space(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Candidate Throttler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function polarity_throttler at 0x7f0b87762d70>\n"
     ]
    }
   ],
   "source": [
    "from hardware_throttlers import get_throttler\n",
    "\n",
    "throttler = get_throttler(ATTRIBUTE)\n",
    "# throttler = None\n",
    "print throttler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Train)\n",
      "[========================================] 100%\n",
      "CPU times: user 24 ms, sys: 44 ms, total: 68 ms\n",
      "Wall time: 1.86 s\n",
      "Candidate Set (Hardware Train Candidates) contains 422 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Dev)\n",
      "[========================================] 100%\n",
      "CPU times: user 32 ms, sys: 36 ms, total: 68 ms\n",
      "Wall time: 1.91 s\n",
      "Candidate Set (Hardware Dev Candidates) contains 730 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Test)\n",
      "[=====================================   ] 92%"
     ]
    }
   ],
   "source": [
    "from fonduer.models import Corpus\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from fonduer.async_candidates import parallel_extract\n",
    "\n",
    "candidate_extractor = CandidateExtractor(Part_Attr, \n",
    "                        [part_ngrams, attr_ngrams], \n",
    "                        [part_matcher, attr_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "corpus_names = ['Hardware Train', 'Hardware Dev']\n",
    "if TEST_SIZE:\n",
    "    corpus_names.append('Hardware Test')\n",
    "for corpus_name in corpus_names:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = parallel_extract(session, candidate_extractor, corpus, \\\n",
    "                                        corpus_name + ' Candidates', \\\n",
    "                                        parallel=PARALLEL_EXTRACTION)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.models import Corpus\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "\n",
    "# # parts_by_doc = get_gold_parts_by_doc()\n",
    "# parts_by_doc = get_manual_parts_by_doc(corpus.documents.all())\n",
    "# # parts_by_doc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cPickle as pickle\n",
    "# pickle_file = os.environ['SNORKELHOME'] + '/tutorials/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "\n",
    "# with open(pickle_file, 'w') as f:\n",
    "#     pickle.dump(parts_by_doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "pickle_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/sandbox/parts_by_doc_dev.pkl'\n",
    "with open(pickle_file, 'r') as f:\n",
    "    parts_by_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import Corpus, CandidateSet\n",
    "from hardware_utils import entity_level_f1\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Dev')\n",
    "candidates = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "gold_file = os.environ['SNORKELHOME'] + \\\n",
    "    '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "%time (ctp, cfp, cfn) = entity_level_f1(candidates, gold_file, ATTRIBUTE, corpus, parts_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(cfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(cfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from fonduer.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "data_sets = ['Dev']\n",
    "gold_file = {}\n",
    "gold_file['Dev'] = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "if TEST_SIZE:\n",
    "    data_sets.append('Test')\n",
    "    gold_file['Test'] = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "for data_set in data_sets:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % data_set\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % data_set\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % data_set\n",
    "    %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file[data_set], \\\n",
    "                           ATTRIBUTE)\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# # os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Train Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Dev Candidates')\n",
    "test  = get_ORM_instance(CandidateSet, session, 'Hardware Test Candidates')\n",
    "\n",
    "if snorkel_postgres:\n",
    "    from fonduer.async_annotations import annotate\n",
    "    print \"Starting async featurization...\"\n",
    "    %time F_train = annotate(train, parallel=PARALLEL_F, dynamic_scheduling=False)\n",
    "    %time F_dev   = annotate(dev, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                             keyset = 'Hardware Train Candidates')\n",
    "    if TEST_SIZE:\n",
    "        %time F_test = annotate(test, parallel=PARALLEL_F, dynamic_scheduling=False,\\\n",
    "                                keyset = 'Hardware Train Candidates')\n",
    "    \n",
    "else:\n",
    "    from fonduer.models import CandidateSet\n",
    "    from fonduer.fast_annotations import FeatureManager\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "\n",
    "    print \"Starting sync featurization...\"\n",
    "    feature_manager = FeatureManager()\n",
    "    %time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "    %time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Train Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Dev Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_lfs import get_lfs\n",
    "\n",
    "LFs = get_lfs(ATTRIBUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if snorkel_postgres:\n",
    "    from fonduer.async_annotations import annotate\n",
    "    %time L_train = annotate(train, parallel=PARALLEL_F, lfs=LFs, dynamic_scheduling=False)\n",
    "else:\n",
    "    from fonduer.fast_annotations import LabelManager\n",
    "    label_manager = LabelManager()\n",
    "    %time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "if not snorkel_postgres:\n",
    "    import os\n",
    "    os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager, LabelManager\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "# label_manager = LabelManager()\n",
    "# %time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "%time gen_model.train(L_train, epochs=500, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.weights.lf_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import NaiveBayes\n",
    "\n",
    "# gen_model = NaiveBayes()\n",
    "# %time gen_model.train(L_train, n_iter=2000, rate=1e-3, mu=1e-6)\n",
    "# train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(zip([lf.__name__ for lf in LFs], gen_model.weights.lf_accuracy_log_odds))\n",
    "print min(train_marginals)\n",
    "print max(train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "disc_model = SparseLogisticRegression()\n",
    "%time disc_model.train(F_train, train_marginals, n_epochs=2000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.learning import LogReg\n",
    "\n",
    "# disc_model = LogReg()\n",
    "# %time disc_model.train(F_train, train_marginals, n_iter=10000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Dev Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Dev Labels -- Gold')\n",
    "L_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(session, F_dev, L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fonduer.models import Corpus\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Dev').one()\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=None)\n",
    "%time (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc=parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from fonduer.models import Corpus\n",
    "\n",
    "parts_by_doc = get_gold_parts_by_doc()\n",
    "(TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TEST_SIZE:\n",
    "    from fonduer.annotations import LabelManager\n",
    "    label_manager = LabelManager()\n",
    "    L_test = label_manager.load(session, test, 'Hardware Test Labels -- Gold')\n",
    "    L_test.shape\n",
    "    \n",
    "    tp, fp, tn, fn = disc_model.score(session, F_test, L_test, b=0.91)\n",
    "    \n",
    "    from hardware_utils import get_gold_parts_by_doc, get_manual_parts_by_doc\n",
    "    from snorkel.utils import get_ORM_instance\n",
    "    from fonduer.models import Corpus\n",
    "\n",
    "    corpus = get_ORM_instance(Corpus, session, 'Hardware Test')\n",
    "\n",
    "    # parts_by_doc_test = get_manual_parts_by_doc(corpus.documents.all())\n",
    "    # parts_by_doc_test = None\n",
    "    import cPickle as pickle\n",
    "    pickle_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/sandbox/parts_by_doc_test.pkl'\n",
    "    with open(pickle_file, 'r') as f:\n",
    "        parts_by_doc_test = pickle.load(f)\n",
    "\n",
    "    from hardware_utils import entity_level_f1\n",
    "\n",
    "    gold_file = os.environ['SNORKELHOME'] + '/fonduer_tutorials/tables/data/hardware/test/hardware_test_gold.csv'\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus)\n",
    "    (TP, FP, FN) = entity_level_f1(tp.union(fp), gold_file, ATTRIBUTE, corpus, parts_by_doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
