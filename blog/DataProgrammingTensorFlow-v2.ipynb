{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming in TensorFlow\n",
    "\n",
    "### TensorFlow\n",
    "\n",
    "In recent years, _deep learning_ models have become some of the most popular choices in machine learning for a variety of problems, in large part because they greatly reduce (or eliminate) the need for manual feature engineering.\n",
    "\n",
    "In turn, TensorFlow has quicky become one of the most popular frameworks for training said _deep learning_ models. TensorFlow's symbolic execution engine makes it easy to simply define an arbitary loss function--whether for a deep model or something more traditional--and then just call a favorite optimizer of choice to minimize the function using gradient descent. In this way, the barrier to deep learning has never been lower!\n",
    "\n",
    "### Data Programming\n",
    "One of the biggest impediments to actually using deep learning in practice, however, is the requirement of **_large hand-labeled training sets_**. Increasingly, one approach has been to use [weaker forms of supervision](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html), i.e. programmatic or heuristic generation of training set labels which are often noisy and give conflicting signals.\n",
    "\n",
    "Whichever way you label your training set, however, there is _some_ process that you follow.  The core idea in **data programming ([NIPS 2016](https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly))** is that by modeling this training set creation process, you can improve quality.  Right now, we're working on using this to power a new information extraction framework, [Snorkel](snorkel.stanford.edu), but the concept of data programming is much more general.\n",
    "\n",
    "\n",
    "### This tutorial\n",
    "In this tutorial, we'll walk through a simple toy example with synthetic data, showing how you can use data programming with TensorFlow to train arbitrary models like neural networks with only weak supervision.  We'll walk through the three high-level steps of data programming:\n",
    "\n",
    "1. Creating a noisy training set by writing _labeling functions_\n",
    "\n",
    "2. Modeling this training set to _denoise it_\n",
    "\n",
    "3. Training a _noise-aware_ discriminative model\n",
    "\n",
    "We note that for the most part, this is a tutorial on data programming, not deep learning.  In fact, we won't use any neural networks or \"deep\" models in this tutorial--but everything here will be easily extendable to such models within TensorFlow! As you'll see below, step 3 can easily use a neural network but simply apply a different loss function after the top layer.\n",
    "\n",
    "\n",
    "### Who this is for\n",
    "The goal of this tutorial is to go through a simple but end-to-end example of data programming, along with enough math to understand the basics, e.g. what objectives are we optimizing, how do they tie together, etc.  If you are comfortable setting up and training machine learning models in a framework like TensorFlow, this tutorial should set you up to try out data programming with your favorite models!  Other resources:\n",
    "\n",
    "* For a more detailed treatment, especially on the theory side, see our [NIPS 2016 paper](https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly)\n",
    "\n",
    "* To see how we use this technique on real information extraction problems, check out [Snorkel](http://snorkel.stanford.edu), in particular [the intro tutorial](https://github.com/HazyResearch/snorkel/tree/master/tutorials/intro)\n",
    "\n",
    "* For a slightly higher-level overview, see [this blog post](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _STEP 0:_ Set up\n",
    "---\n",
    "\n",
    "Here we'll load the necessary libraries and generate some synthetic data, which we'll store as an $n \\times d$ matrix $X_s$, where each row represents a data point $x \\in \\{0,1\\}^d$.\n",
    "\n",
    "We'll also generate a vector of ground-truth labels $Y_s \\in \\{-1,1\\}^n$; we'll henceforth consider all but a small set of these labels _unseen_, as the whole point of our approach is to make do without labeled training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# n is the number of data points, and d is the dimension of the feature vector\n",
    "# that we represent each of them as\n",
    "n  = 10000\n",
    "d  = 100\n",
    "Ys = 2 * np.random.randint(2, size=(n,)) - 1\n",
    "\n",
    "# We think of the binary features as functions each having some (unknown)\n",
    "# correlation with the target label, which we'll set randomly in [0.4,0.6]\n",
    "feature_accs = 0.2 * np.random.random((d,)) + 0.4\n",
    "Xs           = np.zeros((n, d))\n",
    "for i in range(n):\n",
    "    for j in range(d):\n",
    "        if np.random.random() > feature_accs[j]:\n",
    "            Xs[i,j] = 1 if Ys[i] == 1 else 0\n",
    "        else:\n",
    "            Xs[i,j] = 0 if Ys[i] == 1 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _STEP 1:_ Creating a noisy training set by writing _labeling functions_\n",
    "---\n",
    "\n",
    "In this tutorial our goal is to train a _classification model_ that when given an unseen data point $x$, will predict a correct label $y$.  Here, we'll consider the binary clasification setting ($y\\in\\{-1,1\\}$) for simplicity.\n",
    "\n",
    "The most important part about our setup is that we'll assume we **don't have access to any ground truth training labels**; instead, we'll use noisy labeling functions to approximate these training labels.\n",
    "\n",
    "In this step, we'll:\n",
    "\n",
    "i. Explain the concept of _labeling functions_\n",
    "\n",
    "ii. Make some synthetic toy labeling functions, and generate a noisy label matrix $L$\n",
    "\n",
    "Recall that we already generated some synthetic data, which we stores as an $n \\times d$ matrix $X_s$, where each row represents a data point $x \\in \\{0,1\\}^d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.i) Labeling functions (LFs): A unifying framework for weak supervision\n",
    "\n",
    "In most cases, we do not have access to more than a small number of the ground truth labels, and it is not feasible to get these labels. However, there are often many ways that we can provide _weaker_ supervision- in other words, noisy and possibly conflicting approximations of subsets of $Y_s$.  Data programming provides a simple, unifying framework for such strategies: namely, we express them as _labeling functions_, which simply take in a data point $x$ and either abstain or return a label.\n",
    "\n",
    "In other words, instead of hand-labeling data to create a training set for our model, we write functions that look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positive_heuristic(x):\n",
    "    \"\"\"Label points as true if they match some heuristic value\"\"\"\n",
    "    return 1 if match(pattern, x) else 0\n",
    "\n",
    "def negative_distant_supervision(x):\n",
    "    \"\"\"Label as false if they are in a certain set of examples\"\"\"\n",
    "    return -1 if x in noisy_set else 0\n",
    "\n",
    "def weak_classifier_1(x):\n",
    "    \"\"\"Use a weak or biased classifier of unknown accuracy / relevance.\"\"\"\n",
    "    return weak_classifier_1.predict(x)\n",
    "\n",
    "def crowd_worker_1(x):\n",
    "    \"\"\"Represent a crowdsourcer as an LF.\"\"\"\n",
    "    return crowd_labels[0][x.id] if x.id in crowd_labels[0] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.ii) Using synthetic (toy) LFs\n",
    "\n",
    "We won't actually use the above LFs in this tutorial, but they serve to show some of the expressive range that labeling functions can capture.  If you're interested in more on this sort of task--tutorials, results, etc.--check out [Snorkel](http://snorkel.stanford.edu)!\n",
    "\n",
    "Writing and iterating on labeling functions is the core development task in a data programming-based ML pipeline; for this tutorial though, we'll just use synthetic labeling functions which have random accuracies between 45% and 75%, and coverage of 25%, generating a _noisy label matrix_ $L_s$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m           = 20\n",
    "lf_accs     = 0.3 * np.random.random((m,)) + 0.45\n",
    "LF_COVERAGE = 0.25\n",
    "Ls          = np.zeros((n, m))\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        if np.random.random() < LF_COVERAGE:\n",
    "            Ls[i,j] = Ys[i] if np.random.random() < lf_accs[j] else -Ys[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _STEP 2:_ Modeling our noisy training set\n",
    "---\n",
    "\n",
    "The problem with the labels $L_s$ that we generated above is, of course, that they're noisy, and conflict on certain examples. The key technical idea in our data programming approach is that we can automatically model and denoise them!\n",
    "\n",
    "In this step, we'll:\n",
    "1. Explain the idea of expressing our noisy training set as a _generative model_ $\\pi_\\theta(L, Y)$\n",
    "\n",
    "2. Solve this, as a matrix completion problemn in TensorFlow, to learn the accuracies of our labeling functions\n",
    "\n",
    "3. Produce our \"denoised\" training set: the predictions of this generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2.i) Defining a generative model of our noisy labeling process\n",
    "\n",
    "We can see that our label matrix $L_s$ is considerably noisier than the actual ground truth labels $Y_s$; for example, if we take the majority vote of the labeling functions and compare to $Y_s$, we get the following pretty poor accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.693\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: %0.3f\" % (np.sum(0.5 * (np.sign(Ls.sum(1)) * Ys + 1)) / n,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key insights in the data programming approach is that instead of trying to directly use our noisy training set $L_s$ as supervision for our model, we will first _model it_ as a **generative model**.\n",
    "\n",
    "Here, we'll consider the simplest possible version of such a model, where we (correctly) assume that our LFs $\\lambda_i$ are conditionally independent and have a probability of generating a non-zero label that is independent of $y$. For simplicity we'll also assume balanced classes. We are then just learning the standard model:\n",
    "$$\n",
    "P(\\vec{\\lambda}(x), y) = \\prod_{i=1}^m P(\\lambda_i(x)|y)\n",
    "$$\n",
    "\n",
    "Note that we can relax these assumptions, ending up with more complex generative models (as in the [paper](https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly)). Here, however, we'll stick with the simple model defined above, and express this modeling task as a matrix completion / low-rank matrix approximation one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2.ii) The labeling function model as a matrix completion problem\n",
    "\n",
    "The way that we learn the accuracies of the labeling functions is by learning from the overlaps between them. Concretely, given our conditional indpendnce assumptions, we learn the accuracies of the labeling functions that best explain the empirical overlaps we see between them.\n",
    "\n",
    "We start by building an empirical \"overlaps matrix\" $Z\\in [-1,1]^{m\\times m}$ where $Z_{i,j} = 2\\hat{p}_{i,j} - 1$, with $\\hat{p}_{i,j}$ being the empirical probability of labeling functions $i$ and $j$ agreeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = np.dot(Ls.T, Ls) / (np.dot(np.abs(Ls).T, np.abs(Ls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If labeling functions $\\lambda_i$ and $\\lambda_j$ are conditionally independent (as we have assumed here), then letting $p_{i,j}$ be the probability of them agreeing, and $p_i,p_j$ be their respective accuracies, the true probability of them agreeing on a given example should be\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p_{i,j} &= p_ip_j + (1-p_i)(1-p_j)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "However, if you take the dot product of the $\\vec{\\lambda}$ with its transpose, you get the sum of its agreements minus the sum of its disagreements. If we write those out with the above probabilities and simplify, we see that we can represent the above $Z$ matrix by doing a dot product of the below $q$ vector with its transpose.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Z_{i,j} &= (2p_i-1)(2p_j-1) = q_iq_j\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where we have defined the rescaled LF accuracies $q_i=2p_i-1$.  So, our objective is now to find the LF accuracies that best match the data, in other words, the low rank approximation problem:\n",
    "\n",
    "$$\n",
    "\\min_q ||Z-qq^T||_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set up TF placeholder variables for Z and q\n",
    "z = tf.placeholder(tf.float32, Z.shape)\n",
    "q = tf.Variable(tf.random_normal([ Z.shape[0],1], mean=0.5, stddev=.15))\n",
    "\n",
    "# y = qq^T\n",
    "y = q * tf.transpose(q)\n",
    "\n",
    "# Here we just zero-out the diagonals, because we don't care about learning \n",
    "# them (they are always 1 since an LF will always agree with itself!)\n",
    "diag  = tf.zeros((Z.shape[0]))\n",
    "mask  = tf.ones((Z.shape))\n",
    "mask  = tf.matrix_set_diag(mask, diag)\n",
    "y_aug = tf.multiply(y, mask)\n",
    "z_aug = tf.multiply(z, mask)\n",
    "\n",
    "# Our loss function: sum((Z - qq^T)^2)\n",
    "loss = tf.reduce_sum((z_aug - y_aug) * (z_aug - y_aug))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.0005).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we actually don't want to include the diagonal of $Z$ since it is always all ones, so we do a small trick to mask out the diagonals.\n",
    "\n",
    "Now, we just run gradient descent to learn the LF accuracies which minimize our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(5000):\n",
    "    sess.run(train_step, feed_dict={z : Z})\n",
    "q_final  = sess.run(q)\n",
    "est_accs = (q_final+1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, despite the low coverage and accuracies of the labeling functions, **and despite that we do not use any ground truth in this step**, we do pretty decently in recovering the accuracies of the labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>Est. Acc.</th>\n",
       "      <th>True Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.576521</td>\n",
       "      <td>0.572382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.734905</td>\n",
       "      <td>0.733639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018826</td>\n",
       "      <td>0.720113</td>\n",
       "      <td>0.701287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.695316</td>\n",
       "      <td>0.691973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.495499</td>\n",
       "      <td>0.503481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.587892</td>\n",
       "      <td>0.596091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024090</td>\n",
       "      <td>0.561517</td>\n",
       "      <td>0.585607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.528726</td>\n",
       "      <td>0.547026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.562733</td>\n",
       "      <td>0.556805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.597528</td>\n",
       "      <td>0.611776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.708596</td>\n",
       "      <td>0.703478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.521921</td>\n",
       "      <td>0.546256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.661807</td>\n",
       "      <td>0.680540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.538604</td>\n",
       "      <td>0.509671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.042563</td>\n",
       "      <td>0.617966</td>\n",
       "      <td>0.660529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.543253</td>\n",
       "      <td>0.527191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.035134</td>\n",
       "      <td>0.530542</td>\n",
       "      <td>0.565676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.023854</td>\n",
       "      <td>0.761859</td>\n",
       "      <td>0.738005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.025054</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>0.610434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.647492</td>\n",
       "      <td>0.664736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Error  Est. Acc.  True Acc.\n",
       "0   0.004139   0.576521   0.572382\n",
       "1   0.001266   0.734905   0.733639\n",
       "2   0.018826   0.720113   0.701287\n",
       "3   0.003343   0.695316   0.691973\n",
       "4   0.007981   0.495499   0.503481\n",
       "5   0.008199   0.587892   0.596091\n",
       "6   0.024090   0.561517   0.585607\n",
       "7   0.018300   0.528726   0.547026\n",
       "8   0.005928   0.562733   0.556805\n",
       "9   0.014248   0.597528   0.611776\n",
       "10  0.005118   0.708596   0.703478\n",
       "11  0.024335   0.521921   0.546256\n",
       "12  0.018733   0.661807   0.680540\n",
       "13  0.028933   0.538604   0.509671\n",
       "14  0.042563   0.617966   0.660529\n",
       "15  0.016062   0.543253   0.527191\n",
       "16  0.035134   0.530542   0.565676\n",
       "17  0.023854   0.761859   0.738005\n",
       "18  0.025054   0.585379   0.610434\n",
       "19  0.017244   0.647492   0.664736"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, Series\n",
    "data = {\n",
    "    'Error'     : Series(abs(est_accs[:,0] - lf_accs)),\n",
    "    'True Acc.' : Series(lf_accs),\n",
    "    'Est. Acc.' : Series(est_accs[:,0])\n",
    "}\n",
    "DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2.iii) Getting our denoised training set\n",
    "\n",
    "But how do we use this as a training set?  Basically, we now want to plug the accuracies we just estimated into our simple generative model, and use it to produce the probability that each data point is true, $P(y=1|\\lambda(x))$.  We'll then use _these probabilities_ as our training labels!\n",
    "\n",
    "We'll now quickly go through the math to do this; you can also feel free to skip this section!  First, we'll express our labeling functions' conditional probabilities in the following standard form:\n",
    "\n",
    "$$\n",
    "P(\\lambda_i(x)|y) = \\frac{1}{Z}\\exp(\\frac12w_i\\lambda_i(x)y)\n",
    "$$\n",
    "\n",
    "Thus, we have re-expressed our labeling functions' accuracies $p_i$ (where we calculate accuracy over non-zero labels) in terms of the _log odds accuracy_ $w$:\n",
    "\n",
    "$$\n",
    "p_i = P(\\lambda_i(x)=1|y=1,\\lambda_i(x)\\neq0)\n",
    "= \\frac{\\exp\\left(\\frac{w_i}{2}\\right)}{\\exp\\left(-\\frac{w_i}{2}\\right) + \\exp\\left(\\frac{w_i}{2}\\right)}\n",
    "$$\n",
    "\n",
    "Then, recalling the simple generative model we defined earlier, we just have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(y=1|\\lambda(x)) &= \\frac{P(y=1)P(\\lambda(x)|y=1)}{\\sum_{y'\\in\\{-1,1\\}}P(y=y') P(\\lambda(x)|y=y')}\\\\\n",
    "&= \\frac{\\prod_{i=1}^mP(\\lambda_i(x)|y=1)}{\\sum_{y'\\in\\{-1,1\\}} \\prod_{i=1}^mP(\\lambda_i(x)|y=y')}\\\\\n",
    "&= \\frac{\\exp\\left(\\frac12w^T\\lambda(x)\\right)}{\\exp\\left(\\frac12w^T\\lambda(x)\\right) + \\exp\\left(-\\frac12w^T\\lambda(x)\\right)}\\\\\n",
    "&= \\frac{1}{1 + \\exp(-w^T\\lambda(x))}\\\\\n",
    "&= \\sigma(w^T\\lambda(x))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where to convert our accuracies to log odds, we just do:\n",
    "\n",
    "$$\n",
    "w_i = \\log\\left(\\frac{p_i}{1-p_i}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lo = np.log( est_accs / (1.0 - est_accs))\n",
    "Yp = 1 / (1 + np.exp(-np.ravel(Ls.dot(lo))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our training set labels $P(y=1|\\lambda)$, and see that they're more accurate than a simple majority vote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.727\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: %0.3f\" % (np.sum(0.5 * ((np.sign(2*Yp - 1) * Ys) + 1)) / n,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the point here was just to model our noisy training set **_so that we could use it to train a higher-performance discriminative model_**.  On to that now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _STEP 3:_ Training a _noise-aware_ discriminative model\n",
    "---\n",
    "\n",
    "In this step, we'll:\n",
    "\n",
    "1. Set up a _noise-aware_ variant of our favorite discriminative model\n",
    "\n",
    "2. Train our model in TensorFlow\n",
    "\n",
    "3. See how close we come to the fully supervised version!\n",
    "\n",
    "We'll start by splitting our data into a train and test set; note we'll use the ground-truth labels only in the test set for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert Y to correct format\n",
    "Yc = 0.5 * (Ys + 1)\n",
    "\n",
    "# Split into training and test set\n",
    "N_split = int(0.8*n)\n",
    "X_train = Xs[:N_split, :]\n",
    "X_test  = Xs[N_split:, :]\n",
    "\n",
    "# Note we *DO NOT* use the training set labels\n",
    "Y_train = Yp[:N_split].reshape((-1,1))\n",
    "Y_test  = Yc[N_split:].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3.i) Setting up a noise-aware discriminative model\n",
    "\n",
    "We're now right back to the standard old goal in machine learning- train a discriminative model that learns to _generalize_ beyond the training set, and thus get high performance on the test set.\n",
    "\n",
    "Our only difference is that now we have a set of values $P(y=1|\\lambda) \\in [0,1]$ as our training labels, where these values express the varying degrees of confidence in our training labels, or alternatively, the amount of _noise_ in our training set.  Rather than naively treat these noisy training labels as ground truth, we want our discriminative model to be _noise-aware_, i.e. to learn more from high-confidence training labels.  This is actually a quite simple tweak that's well supported 'right out of the box' in TensorFlow!\n",
    "\n",
    "In this tutorial, we will just use a **linear model** over the $d$-dimensional feature vectors $x$, $h_{w,b}(x) = w^Tx + b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, d])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "w = tf.Variable(tf.random_normal([d, 1], mean=0, stddev=(np.sqrt(6/d + 2)), name=\"weights\"))\n",
    "b = tf.Variable(tf.random_normal([1, 1], mean=0, stddev=(np.sqrt(6/d + 2)), name=\"bias\"))\n",
    "\n",
    "# Defining our predictive model h\n",
    "h = tf.add(tf.matmul(X, w), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we'll use a **logistic loss**.  In other words, we'll end up with our old friend logistic regression (dissapointed that we're not at least using a single-layer neural net?  Algebra will make you feel better!)\n",
    "\n",
    "Now, our _noise-aware loss_ is just the expected loss with respect to this noisy training set model\n",
    "\n",
    "$$\n",
    "l(w,b) = \\mathbb{E}_{(x,y)\\sim \\pi_\\theta}\\left[ l(h_{w,b}(x), y) \\right]\n",
    "$$\n",
    "\n",
    "If we do out the algebra,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "l(w,b) &= \\mathbb{E}_{(x,y)\\sim \\pi_\\theta}\\left[ l(h_{w,b}(x), y) \\right]\\\\\n",
    "&= \\sum_{x\\in T} P(y=1)l(h_{w,b}(x),1) + (1-P(y=1))l(h_{w,b}(x),-1)\\\\\n",
    "&= \\sum_{x\\in T} P(y=1)\\log(1 + \\exp(h_{w,b}(x))) + (1-P(y=1))\\log(1 + \\exp(-h_{w,b}(x)))\\\\\n",
    "&= \\sum_{x\\in T} -P(y=1)\\log(\\sigma(h_{w,b}(x))) - (1-P(y=1))\\log(\\sigma(h_{w,b}(x)))\\\\\n",
    "&= H_{x\\in T}\\left(p, q\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "we see that our noise-aware loss function is actually just the _cross-entropy_ between our training set predictions $p(x) = P_{\\pi}(y=1|\\lambda(x))$, and our logistic function $q(x) = \\sigma(h_{w,b}(x)) = \\frac{1}{Z}\\exp(w^Tx+b)$.\n",
    "\n",
    "In TensorFlow, this loss function (`sigmoid_cross_entropy_with_logits`) comes included right out of the box.  **This means that we can use data programming for _any_ model by just swapping it in for h in the code below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the noise-aware logistic loss function\n",
    "loss_fn = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(h, Y))\n",
    "\n",
    "# Some setup for computing test set accuracy, setting learning rate, etc.\n",
    "correct_OP   = tf.equal(tf.greater(h, 0), tf.equal(Y, 1))\n",
    "accuracy_OP  = tf.reduce_mean(tf.cast(correct_OP, \"float\"))\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.00001,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=X_train.shape[0],\n",
    "                                          decay_rate=0.95,\n",
    "                                          staircase=True)\n",
    "\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3.ii) Training our model in TensorFlow\n",
    "\n",
    "Now, finally, we'll train our noise aware model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(X_t, Y_t, n_epochs=5000, display=False):\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Train the model\n",
    "    prev_loss = 0\n",
    "    diff      = 1\n",
    "    for i in range(n_epochs):\n",
    "        if i > 1 and diff < .0001:\n",
    "            print(\"Change in loss = %g; done!\" % diff)\n",
    "            break\n",
    "        else:    \n",
    "            step = sess.run(training_OP, feed_dict={X: X_t, Y: Y_t})\n",
    "        \n",
    "        # Report occasional stats\n",
    "        if display and i % 500 == 0:\n",
    "            loss      = sess.run(loss_fn, feed_dict={X: X_t, Y: Y_t})\n",
    "            diff      = abs(loss - prev_loss)\n",
    "            prev_loss = loss\n",
    "            print(\"Step %0.4d \\tLoss %0.2f\" % (i, loss))\n",
    "    print(\"Final accuracy on test set: %s\" %str(sess.run(accuracy_OP, feed_dict={X: X_test, Y: Y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 0.8545\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3.iii) Comparing to supervised learning\n",
    "\n",
    "Ok, we've been able to achieve **much higher accuracy** on the test set with our newly-trained discriminative model, than we had before with our heuristic labeling functions. But how far are we from what we could have accomplished with supervised learning, if we had ground truth labels? Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 0.869\n"
     ]
    }
   ],
   "source": [
    "Y_train_supervised = Yc[:N_split].reshape((-1,1))\n",
    "train_model(X_train, Y_train_supervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the final accuracy for the fully supervised training with ground truth labels is remarkably close to the data programming model accuracy; and we could close this gap further by iterating further on our labeling functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "\n",
    "Let's quickly recap what we did: \n",
    "1. We created a dataset $X_s$ and generated noisy and conflicting labels for it ($L_s$) by writing _labeling functions_\n",
    "\n",
    "2. We _modeled_ this noisy training set generation process by learning a generative model, i.e. learning our labeling functions' accuracies by observing their overlaps (using a matrix completion objective)\n",
    "\n",
    "3. We trained a _noise-aware_ discriminative model using our denoised labels, and showed that the performance was close to that of a directly-supervised model!\n",
    "\n",
    "Key takeaways:\n",
    "* You can use data programming to weakly supervise machine learning models--i.e. to train them without large hand-labeled training sets--and still get strong end performance.\n",
    "* You can prototype these models quickly and efficiently with TensorFlow. \n",
    "\n",
    "For more, check out the [NIPS 2016 data programming paper](https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly) and our system using data programming for information extraction, [Snorkel](http://snorkel.stanford.edu)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
