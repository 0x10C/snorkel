<!DOCTYPE html><html>

<head>
<meta charset="utf-8">
<title>Babble Labble</title>
<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}

.top-banner {
    position: absolute;
    top: 0;
    left: 0;
    z-index: 0;
    width: 100%;
}

#top-banner-img {
    opacity: 0.5;
    width: 100%;
    max-height: 350px;
}

#main-title {
    position: relative;
    margin-top: 100px;
    margin-bottom: 100px;
    padding: 10px;
    font-size: 40px;
    background: #333333;
    color: #f8f8f8;
    z-index: 10;
}

blockquote {
    font-size: large;
    font-weight: 300;
}

p.img {
    text-align: center;
}
</style>
</head>
<body>
<span class="top-banner">
    <img id="top-banner-img" src="img_babble/boggle_banner.jpeg" alt="image alt text">
</span>

<p id="main-title">Babble Labble:<br />Learning from Natural Language Explanations</p>

<p>Post by Braden Hancock, Percy Liang and Chris RÃ©</p>

<p><em>And referencing work by many other <a href="http://cs.stanford.edu/people/chrismre/#students">members of Hazy Research</a></em></p>

<!--<blockquote>
<p>Powerful machine learning models that automate feature extraction (such as deep neural nets) need <em>lots</em> of training data, but labeling training examples one by one is expensive and slow. <a href="http://hazyresearch.github.io/snorkel/blog/weak_supervision.html">Data programming</a> allows training data to be created programmatically, but requires the user to write simple programs, which many would-be labelers (e.g., Mechanical Turkers or domain experts) cannot do. We describe the <b>Babble Labble</b> approach, which allows labelers to supervise complex machine learning models using <i>natural language</i>. 
<ul>
  <li><p> Instead of providing many labels on individual training examples, labelers give <em>explanations</em> for why they would label certain examples one way or another.</p></li>
  <li><p> Natural language explanations are automatically semantically parsed into executable functions, which feed a data programming application and ultimately train a powerful downstream classifier for a given task.</p></li>
  <li><p>By learning from natural language explanations of labeling decisions, we achieve comparable quality to fully supervised approaches while using 30x less labeled data.</p></li>
</ul>
</blockquote>-->

<!--(Take your pick from these <a href=https://medium.com/intuitionmachine/the-ultimate-deep-learning-applications-list-434d1425da1d#.mhlnixpk1>40 examples</a>)-->

<blockquote>
<p>
Modern machine learning models that automate feature extraction (such as deep neural nets) can do incredible things with enough labeled training data! The hard part is <em>getting</em> enough labeled training data to properly train their thousands (or millions!) of parameters. And in the age where "<a href=https://www.domo.com/blog/data-never-sleeps-4-0/>data never sleeps</a>", the bottleneck isnât getting the data&mdash; itâs getting the labels.
</p>

<p>
We propose <b>Babble Labble</b>, a framework for generating labels for large training sets from <em>natural language explanations</em>. In this framework, a semantic parser converts explanations into executable functions, which feed a <a href="http://hazyresearch.github.io/snorkel/blog/weak_supervision.html">data programming</a> application and ultimately train a powerful downstream classifier for a given task. By learning from natural language explanations of labeling decisions, we achieve comparable quality to fully supervised approaches with a fraction of the data.
</blockquote>

<!--<p>Labeling examples one by one is expensive and slow. Previous work from our lab introduced the data programming paradigm, which allows for the programmatic generation of large training sets using user-provided functions, but this requires -->

<center><p><img src="img_babble/explain_yourself.png" alt="image alt text" width=400px></p></center>

<h2 id="toc_0">How Should I Label My Data?</h2>
<p>
Imagine youâre building a classifier to predict whether or not two people mentioned in a sentence are married. You've collected a few million sentences to draw from, and you've hired some Mechanical Turkers (humans online who perform simple tasks for money) to help you collect some labels. How you should have them label your data?
</p>

<h3>Option 1: With Labels (One by One)</h3>
<blockquote>
<p>In traditional supervision, labelers find reasons for giving certain labels, return only the labels, then make algorithms work to rediscover the reasons.</p>
</blockquote>

Imagine a Turker (let's call him Joe) who sees the following example:

<center><p><img src="img_babble/hit_supervised.png" alt="image alt text" width=600px></p></center>

<p>Joe reads the sentence. He looks at the words Barack and Michelle, and the words around them. He decides that because Barack and Michelle have the word âandâ between them, and the words âtheir daughterâ occur later in the sentence, theyâre likely married. Having found a solid reason for labeling True, Joe marks âTrueâ. As Joe goes through the data set, specific reasons for labeling examples one way or another come up over and over again, but all we ever collect is the binary label âTrueâ or âFalseâ.</p>

<p>Downstream, you'd like your classifier to look at this example and others like it and learn to use some of the same reasons--or *features*--that Joe found, but instead of conveying these reasons directly, we expect the classifier to learn them from scratch using nothing but "True"s and "False"s. (Itâs like the classifier keeps asking for directions and instead of pointing exactly where to go, the Turkers just tease it with a vague âyouâre getting warmerâ or âyouâre getting colderâ!). Especially in situations where large sets of labels aren't readily available, this seems like an incredibly wasteful process!</p>

<!--Youâve set up a HIT on Mechanical Turk and your Turker (letâs name him Joe) sees the following:

Now consider with us the tragedy that is the wastefulness in the way we currently tend to gather labels:

<p>
Joe reads the sentence. He looks at the words Barack and Michelle, and the words around them. He decides that because Barack and Michelle have the word âandâ between them, and theyâre visiting some place together, and the words âtheir daughterâ occur later in the sentence, theyâre likely married. Having found his reasons for labeling True, Joe marks âTrueâ. Downstream, youâd like your classifier thatâs using these labels to look at this labeled example and many others and eventually learn things like âwhen two people have the word âandâ between them and the words âtheir daughterâ after them, thatâs a good indicator that theyâre married.â As Joe (and other Turkers) go through the data set, their reasons for labeling examples one way or another will come up over and over again, but all weâll ever collect is the binary label âTrueâ or âFalseâ, and then hope that our classifier can re-learn these reasons on its own. (Itâs like our classifier keeps asking for directions and instead of pointing exactly where to go, the Turkers just tease it with a vague âyouâre getting warmerâ or âyouâre getting colderâ!).
</p>-->

<center><p><img src="img_babble/blindfolded.jpg" alt="image alt text" width=500px></p></center>

<!--<p>
âBut wouldnât using heuristics like Joeâs result in a relatively brittle rule-based system that doesnât generalize well to new examples?â Weâre glad you asked. This is where data programming comes in! 
</p>-->

<h3 id="toc_1">Option 2: With Labeling Functions (via Data Programming)</h3>

<blockquote>
<p>In data programming, users write labeling functions that are used to assign noise-aware labels to unlabeled data.</p>
</blockquote>

<p>
In a <a href="http://hazyresearch.github.io/snorkel/blog/weak_supervision.html">data programming</a> approach, instead of providing binary labels, Joe writes functions (called "labeling functions" or LFs) that label data "accurately enough". These functions don't necessarily have perfect recall or precision, and they are allowed to overlap and conflict with one another.
</p>

<center><p><img src="img_babble/hit_dp.png" alt="image alt text" width=600px></p></center>

<p>
By looking at how often the labeling functions agree or disagree with one another, we learn estimated accuracies for each supervision source (e.g., an LF that all the other LFs tend to agree with will have a high learned accuracy, whereas an LF that seems to be disagreeing with all the others whenever they vote on the same example will have a low learned accuracy). And by combining the votes of all the labeling functions (weighted by their estimated accuracies), weâre able to assign each example a fuzzy "noise-aware" label (between 0 and 1) instead of a hard label (either 0 or 1).
</p>

<!--, (with 0 meaning âThis is definitely a negative example,â 1 meaning âThis is definitely a positive exampleâ, and 0.5 meaning âI have no idea, so donât waste too much time trying to label me correctly, Mr. Classifierâ). Additionally, recent work from our lab has shown that we can also <a href="https://arxiv.org/abs/1703.00854">learn the structure of the generative model</a> (i.e., the dependencies between LFs) without any labeled data, which improves our modelâs accuracy further.-->

<p class="img"><img src="img_babble/majority_vote.png" width="500px" /></p>

<!--The data programming approach leverages a variety of sources of weak supervision (supervision signals that donât necessarily have perfect recall or precision, and which may overlap and conflict with one another), to apply noise-aware labels to unlabeled training examples. Basically, we interpret our collection of supervision sources (called â<em>labeling functions</em>â or LFs) as implicitly describing a generative model for assigning labels to training examples. -->

<p>
Three big pros of this approach are:
<ol>
<li><p>We've improved the scalability of our labeling approach: each LF can contribute label information to tens, hundreds, or thousands of examples--not just one.</p></li>
<li><p>We now have a use for unlabeled data. We can apply our LFs on all the unlabeled examples to create a whole lot of not perfect, but âgood enoughâ labels for a potentially huge training data set.</p></li> 
<li><p>These labels can be used to train a powerful discriminative classifier with a large feature set that generalizes beyond the reasons directly addressed by the LFs. (So even if we only use 100 LFs, the examples they label may each have thousands of features whose weights are learned by the discriminative classifier).</p></li> 
</ol>
</p>

<p>
One big con of this approach is:
<ol>
<li> Joe can't program! He is, after all, just your average Joe.</li>
</ol>

<!--<p>
âBut wait,â you say, âyou promised I could use natural language and data programming uses functions! What gives?â Read on, gentle reader!
</p>-->

<!--<h2 id="toc_2">Babble Labble</h2>-->

<h3 id="toc_1">Option 3: With Explanations (via Babble Labble)</h3>
<blockquote>
<p>The Babble Labble approach uses a semantic parser to convert natural language explanations into âaccurate enoughâ labeling functions for use with data programming.</p>
</blockquote>

<p>Babble Labble converts natural language (babble) into labels (or labbles&mdash;we've heard it both ways). Now, Joe's labeling interface looks like this: </p> 
<p class="img"><img src="img_babble/hit_babble.png" width=600px/></p>

What are the benefits of having a natural language interface? Here are a few:
<ol>
<li>Ease of use
  <p>The world is moving to conversational interfaces. Sure, I can type, but sometimes I prefer to just say âHey Google/Siri/Alexaâ and talk to my computer/phone/television/toaster.</p></li>
<li>Faster supervision
  <p>Even if you could count on all Turkers being able to code, you can be fairly certain it would take them longer to write small programs than it would for them type a sentence or two.</p>
</li>
<li>More sources of supervision
  <p>Thereâs a <em>lot</em> of natural language in the world. In its current relative infancy, Babble Labble works with explanations that were meant to be used for supervision. But imagine a future where your virtual assistant can learn how to classify certain things in the world just by reading what people say about them in subreddits and blog comments!</p>  
</li>
</ol>

<p class="img"><img src="img_babble/robot_reading.jpg" width="300px" /></p>

<h2>Babble Labble</h2>
<p>The core component of Babble Labble is a semantic parser. Semantic parsers convert natural language explanations into formal programs (or in our case, labeling functions). Part of the reason why programs are written in programming languages instead of natural languages is because natural language can be ambiguous. This means that a single explanation often maps to many different possible LFs&mdash;one that was intended and others that are spurious (but which may also be factually correct).</p>

<p class="img"><img src="img_babble/semantic_parser.png" width="700px" /></p>

In a traditional approach, one might use a bunch of labeled data to âtrainâ the semantic parser and learn which of the generated LFs is most likely to be the correct one. But fortunately, in this framework with a downstream application that was made to handle noise, we don't need a perfect parser to still get great results!

Just like how we found that we can use a larger set of âaccurate enoughâ labels to train the discriminative model in data programming, we propose that we can use a larger set of âaccurate enoughâ labeling functions to train the generative model in data programming. This may seem a little cavalier of us, but there are reasons for believing this just might work:

<p><b>Reason #1.</b> Common sense filters catch many spurious LFs</p>
<ul>
<li> Filter 1: example contradiction
  <p>With the labeling interface Joe used, each LF comes from an explanation that is tied to a specific example. If the LFâs explanation doesnât agree with the label given to its own corresponding example, then we can confidently toss it.</p>
<li> Filter 2: uniform labels
  <p> If an LF does correctly label its corresponding example, but it does so by naively labeling all examples as True or all as False, then it provides no useful signal and can also be tossed.</p>
<li> Filter 3: redundant signature
  <p> Suppose one explanation yielded three LFs that label identically every single example in the large training set extracted from the unlabeled data. While the three LFs may in fact be unique in some way, their semantic difference is small enough that they provide redundant information for our application, and all but one can be tossed.</p>
</ul>

<p><b>Reason #2.</b> Data programming mitigates the negative effects of spurious LFs</p>
<ul>
<li> Model the LFs' accuracies
  <p>In the data programming paradigm, labeling functions donât need to be perfectly accurate to be useful. If a mistake in the semantic parser results in a labeling function that is less accurate than it was intended to be, the generative model will have the opportunity to recognize this when it sees its disagreement with other LFs and reduce its estimated accuracy accordingly.
<li> Model the LFs' dependencies
  <p>What if one particularly ambiguous explanation generates a whole bunch of LFs that pass the filters and all agree with each other despite being wrong&mdash;wonât that falsely boost their learned accuracies? It would...if we believed that all LFs label independently. But because we are able to automatically <a href=https://arxiv.org/abs/1703.00854>learn the dependencies</a> between the LFs in data programming, this mob behavior can be recognized for what it is and voting power of all the LFs participating in this âecho chamberâ can be reduced accordingly.
</ul>

<p><b>Reason #3.</b> Spurious LFs can be sometimes even helpful!</p>
The labelerâs explanation describes a very specific signal for the learner to pay attention to. In the extremely high dimensional space of all possible features, minor parsing inaccuracies may still result in a relevant signal making it through. For example, the latter half of Joeâs explanation may be misinterpreted by the semantic parser as âthe words âtheir daughterâ occur anywhere in the sentenceâ. While not as specific as the intended explanation, it may end up correctly labeling all of the same examples as the intended function as well as new examples such as âFollowing the birth of their daughter, BeyoncÃ© and Jay-Z took to Twitter to celebrate.â The key here is that most of what Joe was trying to convey in this case is captured in the string "their daughter"; many imperfect parses will still result in that most important signal getting through just fine.

<h2>Case Study: Classifying Disease-Causing Chemicals</h2>

Consider the task of extracting chemical-disease pairs from the scientific literature where a chemical is reported to cause a certain disease. Since this task requires domain-specific knowledge that the average Turker lacks, we took 30 labeling functions that were first written by a biomedical researcher and had them paraphrased into natural language by someone completely unfamiliar with our system. The paraphraser was also given dictionaries that were assembled by the researcher, such as a dictionary of âtreatmentâ words and a dictionary of chemical-disease pairs where the chemical is known to be used for therapy of the disease. Examples of the resulting explanations include:

<p class="img"><img src="img_babble/cdr_explanations.png" width=600px/></p>

Using beam search, the 30 explanations were parsed into 61 LFs. Applying the example contradiction filter (using example/explanation pairs) removed 18 of these, the uniform labels filter removed 1, and the redundant signature filter removed 6, resulting in 36 LFs (a âspurious LFâ rate of only 17%). The data programming platform, Snorkel, identified 11 dependencies among the LFs, and in one case, a spurious LF ended up having a higher empirical accuracy than the intended one. On this very difficult task:
<ul> 
  <li>Traditional supervision with 1k gold labels achieves an F1 score of 0.53.</li> 
  <li>Data programming with 30 programmed LFs and a training set of 8k unlabeled examples achieves an F1 score of 0.54.</li>
  <li>Babble Labble with 30 explanation/example pairs (resulting in 36 natural-language-based LFs) and the same unlabeled training set achieves an F1 score of 0.53.
</ul>
That is, by utilizing natural language explanations corresponding to 30 labeled examples, we were able to achieve the same quality as a fully supervised system on this task while using <b>33x fewer gold training examples</b>.

<p class="img"><img src="img_babble/cdr_results.png" width=500px/></p>

<h2>Next Steps</h2>
We are very excited about our initial results! Next up:
<ul>
<li> We want to run tests over more domains to really tease out under what conditions Babble Labble excels.</li>
<li>We would like to explore whether a feedback loop can be incorporated from the downstream task back to the semantic parser: the semantic parser generates functions, the top k of which we use to generate approximate labels for a bunch of training examples, which are used to train the semantic parser, allowing us to select a better top k labeling functions, from which we get more accurate approximate labels...</li>
</ul>

</body>
</html>
