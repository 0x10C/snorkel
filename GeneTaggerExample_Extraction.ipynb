{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging genes with ddlite: candidate extraction\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a gene tagger from scratch. Here's why we developed ddlite:\n",
    "\n",
    "* To provide a lighter-weight interface to structured information extraction for new DeepDive users\n",
    "* To help advanced DeepDive rapidly develop and prototype applications and labeling functions/labelers\n",
    "* To investigate DeepDive's data programming approach to building inference systems\n",
    "\n",
    "This example is centered around the second item. Domain-specific tagging systems take months or years to develop. They use hand-crafted model circuitry and accurate, hand-labeled training data. We're going to try to build a pretty good one in a few minutes with none of those things. The generalized extraction and learning utilities provided by ddlite will allow us to turn a sampling of article abstracts and some basic domain knowledge into an automated tagging system. Specifically, we want an accurate tagger for genes in academic articles. We have comprehensive dictionaries of genes, but applying a simple matching rule might yield a lot of false positives. For example, \"p53\" might get tagged as a gene if it refers to a page number. Our goal is to use distant supervision to improve precision.\n",
    "\n",
    "Here's the pipeline we'll follow:\n",
    "\n",
    "1. Obtain and parse input data (relevant article abstracts from PubMed)\n",
    "2. Extract candidates for tagging\n",
    "3. Generate features\n",
    "4. Write labeling functions\n",
    "5. Learn the tagging model\n",
    "6. Iterate on labeling functions\n",
    "\n",
    "Parts 1 and 2 are covered in this notebook, and parts 3 through 6 are covered in `GeneTaggerExample_Learning.ipynb`. Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input data\n",
    "We already downloaded the raw HTML for 150 gene-related article pages from PubMed using the `pubmed_gene_html.py` script. These can be found in the `data` folder. We can use ddlite's `DocParser` to read in the article text. There's a general HTML parser which finds visible text, but we can do better by writing a more specific version to just grab the abstract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By constructing DNA probes we have identified and cloned a human PtdIns 4-kinase, PI4K230, corresponding to a mRNA of 7.0 kb. The cDNA encodes a protein of 2044 amino acids. The C-terminal part of ca. 260 amino acids represents the catalytic domain which is highly conserved in all recently cloned PtdIns 4-kinases. N-terminal motifs indicate multiple heterologous protein interactions. Human PtdIns 4-kinase PI4K230 expressed in vitro exhibits a specific activity of 58 micromol mg-1min-1. The enzyme expressed in Sf9 cells is essentially not inhibited by adenosine, it shows a high Km for ATP of about 300 microM and it is half-maximally inactivated by approximately 200 nM wortmannin. These data classify this enzyme as type 3 PtdIns 4-kinase. Antibodies raised against the N-terminal part moderately activate and those raised against the C-terminal catalytic domain inhibit the enzymatic activity. The coexistence of two different type 3 PtdIns 4-kinases, PI4K92 and PI4K230, in several human tissues, including brain, suggests that these enzymes are involved in distinct basic cellular functions.\n"
     ]
    }
   ],
   "source": [
    "class PubMedAbstractParser(HTMLParser):\n",
    "    def _cleaner(self, s):\n",
    "        return (s.parent.name == 'abstracttext')\n",
    "\n",
    "dp = DocParser('gene_tag_example/data/', PubMedAbstractParser())\n",
    "docs = list(dp.parseDocs())\n",
    "print docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use CoreNLP via ddlite's `SentenceParser` to parse each sentence. `DocParser` can handle this too; we didn't really need that call above. This can take a little while, so if the example has already been run, we'll reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.01 s, sys: 126 ms, total: 5.14 s\n",
      "Wall time: 18.7 s\n",
      "Sentence(words=['By', 'constructing', 'DNA', 'probes', 'we', 'have', 'identified', 'and', 'cloned', 'a', 'human', 'PtdIns', '4-kinase', ',', 'PI4K230', ',', 'corresponding', 'to', 'a', 'mRNA', 'of', '7.0', 'kb', '.'], lemmas=['by', 'construct', 'dna', 'probe', 'we', 'have', 'identify', 'and', 'clone', 'a', 'human', 'ptdins', '4-kinase', ',', 'pi4k230', ',', 'correspond', 'to', 'a', 'mrna', 'of', '7.0', 'kb', '.'], poses=['IN', 'VBG', 'NN', 'NNS', 'PRP', 'VBP', 'VBN', 'CC', 'VBN', 'DT', 'JJ', 'NN', 'NN', ',', 'NN', ',', 'VBG', 'TO', 'DT', 'NN', 'IN', 'CD', 'NN', '.'], dep_parents=[2, 7, 4, 2, 7, 7, 0, 7, 7, 13, 13, 13, 9, 13, 13, 13, 13, 20, 20, 17, 23, 23, 20, 7], dep_labels=['mark', 'advcl', 'compound', 'dobj', 'nsubj', 'aux', 'ROOT', 'cc', 'conj', 'det', 'amod', 'compound', 'dobj', 'punct', 'appos', 'punct', 'acl', 'case', 'det', 'nmod', 'case', 'nummod', 'nmod', 'punct'], sent_id=0, doc_id=0)\n"
     ]
    }
   ],
   "source": [
    "docs = None\n",
    "\n",
    "pkl_f = 'gene_tag_example/gene_tag_saved_sents_v2.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        sents = cPickle.load(f)\n",
    "except:\n",
    "    %time sents = dp.parseDocSentences()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(sents, f)\n",
    "\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting candidates with matchers\n",
    "Extracting candidates for mentions (or relations) in ddlite is done with `Matcher` objects. First, we'll use a `DictionaryMatcher`. We have access to a pretty comprehensive gene dictionary. Let's load it in and create the `DictionaryMatcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('gene_tag_example/dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 2, genes)\n",
    "\n",
    "dm = DictionaryMatch('GeneName', genes, ignore_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary match should provide fairly high recall, but we may still miss some candidates. We know that gene names are named nouns and are often all uppercase. Let's write our own matcher to catch all-uppercase named nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AllUpperNounsMatcher(Matcher):\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        # Regex matcher to find named nouns in part-of-speech tags\n",
    "        self._re_comp = re.compile(\"[A-Z]?NN[A-Z]?\", flags=re.I)\n",
    "    def apply(self, s):\n",
    "        # Get parts-of-speech and words\n",
    "        words = s.__dict__['words']\n",
    "        pos = s.__dict__['poses']\n",
    "        # Get all-cap words\n",
    "        caps = set(idx for idx, w in enumerate(words) if w.upper() == w)\n",
    "        # Convert character index to token index\n",
    "        start_c_idx = [0]\n",
    "        for s in pos:\n",
    "            start_c_idx.append(start_c_idx[-1]+len(s)+1)\n",
    "        # Find regex matches over phrase\n",
    "        phrase = ' '.join(pos)\n",
    "        for match in self._re_comp.finditer(phrase):\n",
    "            # Get start index for tokens\n",
    "            start = bisect.bisect(start_c_idx, match.start())-1\n",
    "            # Check if word is capital, has more than two characters, and has a letter\n",
    "            if start in caps and len(words[start]) > 2 and any(c.isalpha() for c in words[start]):\n",
    "                yield [start], self.label\n",
    "\n",
    "up = AllUpperNounsMatcher('UpNoun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the candidates\n",
    "To use candidates from both `Matcher` objects, we can use a `MultiMatcher`. We'll use this to extract our candidate entities from the sentences into an `Entities` object. Using both matchers together will provide very high recall, but may have poor precision. In the next demo notebook (`GeneTaggerExample_Learning.ipynb`), we'll write distant supervision rules and learn a model to improve precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = MultiMatcher(dm, up)\n",
    "E = Entities(sents, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize contexts for our extractions too. This may help in writing distant supervision rules in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-7883565999024874210\"></div>\n",
       "<div id=\"raw-seq-7883565999024874210\">\n",
       "<span class=\"word-7883565999024874210-0\">By</span> <span class=\"word-7883565999024874210-1\">constructing</span> <span class=\"word-7883565999024874210-2\">DNA</span> <span class=\"word-7883565999024874210-3\">probes</span> <span class=\"word-7883565999024874210-4\">we</span> <span class=\"word-7883565999024874210-5\">have</span> <span class=\"word-7883565999024874210-6\">identified</span> <span class=\"word-7883565999024874210-7\">and</span> <span class=\"word-7883565999024874210-8\">cloned</span> <span class=\"word-7883565999024874210-9\">a</span> <span class=\"word-7883565999024874210-10\">human</span> <span class=\"word-7883565999024874210-11\">PtdIns</span> <span class=\"word-7883565999024874210-12\">4-kinase</span> <span class=\"word-7883565999024874210-13\">,</span> <span class=\"word-7883565999024874210-14\">PI4K230</span> <span class=\"word-7883565999024874210-15\">,</span> <span class=\"word-7883565999024874210-16\">corresponding</span> <span class=\"word-7883565999024874210-17\">to</span> <span class=\"word-7883565999024874210-18\">a</span> <span class=\"word-7883565999024874210-19\">mRNA</span> <span class=\"word-7883565999024874210-20\">of</span> <span class=\"word-7883565999024874210-21\">7.0</span> <span class=\"word-7883565999024874210-22\">kb</span> <span class=\"word-7883565999024874210-23\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"7883565999024874210\";\n",
       "var root = {\"attrib\": {\"word\": \"identified\", \"dep_label\": \"ROOT\", \"pos\": \"VBN\", \"lemma\": \"identify\", \"word_idx\": \"6\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"constructing\", \"dep_label\": \"advcl\", \"pos\": \"VBG\", \"lemma\": \"construct\", \"word_idx\": \"1\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"By\", \"dep_label\": \"mark\", \"pos\": \"IN\", \"lemma\": \"by\", \"word_idx\": \"0\", \"dep_parent\": \"2\"}, \"children\": []}, {\"attrib\": {\"word\": \"probes\", \"dep_label\": \"dobj\", \"pos\": \"NNS\", \"lemma\": \"probe\", \"word_idx\": \"3\", \"dep_parent\": \"2\"}, \"children\": [{\"attrib\": {\"word\": \"DNA\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"dna\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \"we\", \"dep_label\": \"nsubj\", \"pos\": \"PRP\", \"lemma\": \"we\", \"word_idx\": \"4\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"have\", \"dep_label\": \"aux\", \"pos\": \"VBP\", \"lemma\": \"have\", \"word_idx\": \"5\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"7\", \"dep_parent\": \"7\"}, \"children\": []}, {\"attrib\": {\"word\": \"cloned\", \"dep_label\": \"conj\", \"pos\": \"VBN\", \"lemma\": \"clone\", \"word_idx\": \"8\", \"dep_parent\": \"7\"}, \"children\": [{\"attrib\": {\"word\": \"4-kinase\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"4-kinase\", \"word_idx\": \"12\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"9\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"human\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"human\", \"word_idx\": \"10\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"PtdIns\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"ptdins\", \"word_idx\": \"11\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"13\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"PI4K230\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"pi4k230\", \"word_idx\": \"14\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"15\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"corresponding\", \"dep_label\": \"acl\", \"pos\": \"VBG\", \"lemma\": \"correspond\", \"word_idx\": \"16\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"mRNA\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"mrna\", \"word_idx\": \"19\", \"dep_parent\": \"17\"}, \"children\": [{\"attrib\": {\"word\": \"to\", \"dep_label\": \"case\", \"pos\": \"TO\", \"lemma\": \"to\", \"word_idx\": \"17\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"18\", \"dep_parent\": \"20\"}, \"children\": []}, {\"attrib\": {\"word\": \"kb\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"kb\", \"word_idx\": \"22\", \"dep_parent\": \"20\"}, \"children\": [{\"attrib\": {\"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"20\", \"dep_parent\": \"23\"}, \"children\": []}, {\"attrib\": {\"word\": \"7.0\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"7.0\", \"word_idx\": \"21\", \"dep_parent\": \"23\"}, \"children\": []}]}]}]}]}]}, {\"attrib\": {\"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"23\", \"dep_parent\": \"7\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[2]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll pickle the extracted candidates from our `Entities` object for use in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E.dump_candidates('gene_tag_example/gene_tag_saved_entities.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
